{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n",
      "CONTRASTIUVEEEEEEE False\n",
      "VISUAL: True\n",
      "PAST_STATE: True\n",
      "256 2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/19/2023 22:16:08 - INFO - neuroformer.model_neuroformer_2 -   number of parameters: 2.877057e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ///// <=----- Loading model from ./models/NF.15/Visnav_VR_Expt/lateral/Neuroformer/pos_emb/Neuroformer/1_new/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25 -----=> \\\\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "from neuroformer.model_neuroformer_2 import Neuroformer, NeuroformerConfig, load_model_and_tokenizer\n",
    "from neuroformer.utils import get_attr\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils_2 import (set_seed, update_object, running_jupyter, \n",
    "                                 all_device, load_config, \n",
    "                                 dict_to_object, object_to_dict, recursive_print,\n",
    "                                 create_modalities_dict)\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.SpikeVidUtils import make_intervals, round_n, SpikeTimeVidData2\n",
    "from neuroformer.DataUtils import round_n, Tokenizer\n",
    "from neuroformer.datasets import load_visnav, load_V1AL\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "import wandb\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "from neuroformer.default_args import DefaultArgs, parse_args\n",
    "\n",
    "if running_jupyter(): # or __name__ == \"__main__\":\n",
    "    print(\"Running in Jupyter\")\n",
    "    args = DefaultArgs()\n",
    "    args.ckpt_path = \"./models/NF.15/Visnav_VR_Expt/lateral/Neuroformer/pos_emb/Neuroformer/1_new/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25\"\n",
    "    args.dataset = \"lateral\"\n",
    "    args.config = \"./models/NF.15/Visnav_VR_Expt/lateral/Neuroformer/1_new/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/25/mconf_finetune_gaze.yaml\"\n",
    "    args.finetune = True\n",
    "    args.loss_bprop = [\"phi\", \"th\"]\n",
    "else:\n",
    "    print(\"Running in terminal\")\n",
    "    args = parse_args()\n",
    "\n",
    "# SET SEED - VERY IMPORTANT\n",
    "set_seed(args.seed)\n",
    "\n",
    "print(f\"CONTRASTIUVEEEEEEE {args.contrastive}\")\n",
    "print(f\"VISUAL: {args.visual}\")\n",
    "print(f\"PAST_STATE: {args.past_state}\")\n",
    "\n",
    "# Use the function\n",
    "if args.config is None:\n",
    "    config_path = \"./configs/NF_1.5/VisNav_VR_Expt/gru2_only_cls/mconf.yaml\"\n",
    "else:\n",
    "    config = load_config(args.config)\n",
    "\n",
    "base_config, base_tokenizer, model = load_model_and_tokenizer(args.ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if args.dataset in [\"lateral\", \"medial\"]:\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_visnav(args.dataset, config, \n",
    "                           selection=config.selection if hasattr(config, \"selection\") else None)\n",
    "elif args.dataset == \"V1AL\":\n",
    "    data, intervals, train_intervals, \\\n",
    "    test_intervals, finetune_intervals, \\\n",
    "    callback = load_V1AL(config)\n",
    "\n",
    "spikes = data['spikes']\n",
    "stimulus = data['stimulus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 5.0000e-02, 1.0000e-01, ..., 7.5275e+02, 7.5280e+02,\n",
       "       7.5285e+02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spikes (2023, 150578)\n",
      "speed (30117,)\n",
      "stimulus (30117, 30, 100)\n",
      "phi (30117,)\n",
      "th (30117,)\n"
     ]
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    print(key, data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID vocab size: 2026\n",
      "dt vocab size: 14\n"
     ]
    }
   ],
   "source": [
    "window = config.window.curr\n",
    "window_prev = config.window.prev\n",
    "dt = config.resolution.dt\n",
    "\n",
    "# -------- #\n",
    "\n",
    "spikes_dict = {\n",
    "    \"ID\": data['spikes'],\n",
    "    \"Frames\": data['stimulus'],\n",
    "    \"Interval\": intervals,\n",
    "    \"dt\": config.resolution.dt,\n",
    "    \"id_block_size\": config.block_size.id,\n",
    "    \"prev_id_block_size\": config.block_size.prev_id,\n",
    "    \"frame_block_size\": config.block_size.frame,\n",
    "    \"window\": config.window.curr,\n",
    "    \"window_prev\": config.window.prev,\n",
    "    \"frame_window\": config.window.frame,\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    " - see mconf.yaml \"modalities\" structure:\n",
    "\n",
    "modalities:\n",
    "  behavior:\n",
    "    n_layers: 4\n",
    "    window: 0.05\n",
    "    variables:\n",
    "      speed:\n",
    "        data: speed\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "      phi:\n",
    "        data: phi\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "      th:\n",
    "        data: th\n",
    "        dt: 0.05\n",
    "        predict: true\n",
    "        objective: regression\n",
    "\n",
    "\n",
    "Modalities: any additional modalities other than spikes and frames\n",
    "    Behavior: the name of the <modality type>\n",
    "        Variables: the name of the <modality>\n",
    "            Data: the data of the <modality> in shape (n_samples, n_features)\n",
    "            dt: the time resolution of the <modality>, used to index n_samples\n",
    "            Predict: whether to predict this modality or not.\n",
    "                     If you set predict to false, then it will \n",
    "                     not be used as an input in the model,\n",
    "                     but rather to be predicted as an output. \n",
    "            Objective: regression or classification\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "frames = {'feats': stimulus, 'callback': callback, 'window': config.window.frame, 'dt': config.resolution.dt}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "callback: this function is used to get the frame at a given time point\n",
    "given your specific stimulus/video data structure and resolution.\n",
    "See neuroformer.visnav_callback / combo3_V1AL_callback\n",
    "\"\"\"\n",
    "\n",
    "modalities = create_modalities_dict(data, config.modalities) if get_attr(config, 'modalities', None) else None\n",
    "\n",
    "max_window = max(config.window.curr, config.window.prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1\n",
    "n_dt = [round_n(x, dt) for x in np.arange(0, max_window + dt, dt)]\n",
    "\n",
    "token_types = {\n",
    "    'ID': {'tokens': list(np.arange(0, data['spikes'].shape[0] if isinstance(data['spikes'], np.ndarray) \\\n",
    "                                  else data['spikes'][1].shape[0]))},\n",
    "    'dt': {'tokens': n_dt, 'resolution': dt},\n",
    "    **({\n",
    "        modality: {\n",
    "            'tokens': sorted(list(set(eval(modality)))),\n",
    "            'resolution': details.get('resolution')\n",
    "        }\n",
    "        # if we have to classify the modality, \n",
    "        # then we need to tokenize it\n",
    "        for modality, details in modalities.items()\n",
    "        if details.get('predict', False) and details.get('objective', '') == 'classification'\n",
    "    } if modalities is not None else {})\n",
    "}\n",
    "tokenizer = Tokenizer(token_types, max_window, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modalities is not None:\n",
    "    for modality_type, modality in modalities.items():\n",
    "        for variable_type, variable in modality.items():\n",
    "            print(variable_type, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : namespace(dropout=namespace(attn=0.2, embd=0.2, pos=0.2, resid=0.2, temp=0.2, b=0.45, id=0.35, im=0.35), block_size=namespace(behavior=15, frame=446, id=100, prev_id=700), layers=namespace(state_history=6, state=6, stimulus=6, behavior=6, self_att=6, modalities=namespace(n_behavior=25)), sparse=namespace(p=None, mask=False, topk=None, topk_frame=None, topk_id=None, topk_prev_id=None), window=namespace(frame=None, curr=0.05, prev=0.05, speed=0.05), modalities=namespace(behavior=namespace(n_layers=4, window=0.05, variables=namespace(speed=namespace(data='speed', dt=0.05, predict=True, objective='regression'), phi=namespace(data='phi', dt=0.05, predict=True, objective='regression'), th=namespace(data='th', dt=0.05, predict=True, objective='regression')))), predict=None, frame_encoder=namespace(conv_layer=True, kernel_size=[4, 5, 5], n_embd=256, n_embd_frames=64, resnet_backbone=False), contrastive=namespace(contrastive=False, vars=['id', 'frames', 'speed'], clip_embd=1024, clip_temp=0.5), resolution=namespace(dt=0.005, speed=0.2, frames=0.05), mlp_only=False, gru_only=False, gru2_only=False, class_weights=None, epoch=758, freeze_weights=None, n_head=8, n_embd=256, pos_emb=False, pretrain=False, start_prune=30, temp_emb=True, vit_encoder=True, vocab_size=2204, ingore_index_pad=True) != namespace(dropout=namespace(attn=0.2, embd=0.2, pos=0.2, resid=0.2, temp=0.2, b=0.45, id=0.35, im=0.35), block_size=namespace(behavior=15, frame=446, id=100, prev_id=700), layers=namespace(state_history=6, state=6, stimulus=6, behavior=6, self_att=6, modalities=namespace(n_behavior=25)), sparse=namespace(p=None, mask=False, topk=None, topk_frame=None, topk_id=None, topk_prev_id=None), window=namespace(frame=None, curr=0.05, prev=0.05, speed=0.05), modalities=namespace(behavior=namespace(n_layers=4, window=0.05, variables=namespace(speed=namespace(data='speed', dt=0.05, predict=True, objective='regression'), phi=namespace(data='phi', dt=0.05, predict=False, objective=None), th=namespace(data='th', dt=0.05, predict=False, objective=None)))), predict=None, frame_encoder=namespace(conv_layer=True, kernel_size=[4, 5, 5], n_embd=256, n_embd_frames=64, resnet_backbone=False), contrastive=namespace(contrastive=False, vars=['id', 'frames', 'speed'], clip_embd=1024, clip_temp=0.5), resolution=namespace(dt=0.005, speed=0.2, frames=0.05), mlp_only=False, gru_only=False, gru2_only=False, class_weights=None, epoch=757, freeze_weights=None, n_head=8, n_embd=256, pos_emb=True, pretrain=False, start_prune=30, temp_emb=True, vit_encoder=True, vocab_size=2204, ingore_index_pad=True)\n"
     ]
    }
   ],
   "source": [
    "def compare_configs(config1, config2, path=''):\n",
    "    if isinstance(config1, dict) and isinstance(config2, dict):\n",
    "        for key in set(config1.keys()).union(config2.keys()):\n",
    "            if key in config1 and key in config2:\n",
    "                compare_configs(config1[key], config2[key], path + str(key) + '.')\n",
    "            elif key in config1:\n",
    "                print(f'Key {path + str(key)}: present in first config, missing in second config.')\n",
    "            else:\n",
    "                print(f'Key {path + str(key)}: missing in first config, present in second config.')\n",
    "    elif isinstance(config1, list) and isinstance(config2, list):\n",
    "        if config1 != config2:\n",
    "            print(f'Key {path}: {config1} != {config2}')\n",
    "    else:\n",
    "        if config1 != config2:\n",
    "            print(f'Key {path}: {config1} != {config2}')\n",
    "\n",
    "compare_configs(config, base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Interval: 0.1\n",
      "Intervals:  12046\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  2026\n",
      "ID Population Size:  2026\n",
      "DT Population Size:  14\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.1\n",
      "Intervals:  12046\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  2026\n",
      "ID Population Size:  2026\n",
      "DT Population Size:  14\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.1\n",
      "Intervals:  120\n",
      "Window:  0.05\n",
      "Window Prev:  0.05\n",
      "Population Size:  2026\n",
      "ID Population Size:  2026\n",
      "DT Population Size:  14\n",
      "Using explicitly passed intervals\n",
      "id_prev torch.Size([700]) torch.int64\n",
      "dt_prev torch.Size([700]) torch.float32\n",
      "pad_prev torch.Size([]) torch.int64\n",
      "id torch.Size([100]) torch.int64\n",
      "dt torch.Size([100]) torch.float32\n",
      "pad torch.Size([]) torch.int64\n",
      "interval torch.Size([]) torch.float32\n",
      "trial torch.Size([]) torch.int64\n",
      "cid torch.Size([2]) torch.float32\n",
      "pid torch.Size([2]) torch.float32\n",
      "256 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/19/2023 15:03:56 - INFO - neuroformer.model_neuroformer_2 -   number of parameters: 2.800590e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id torch.Size([2, 100]) torch.int64\n",
      "dt torch.Size([2, 100]) torch.int64\n",
      "modalities_behavior_speed_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_speed_dt torch.Size([2]) torch.float32\n",
      "modalities_behavior_phi_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_phi_dt torch.Size([2]) torch.float32\n",
      "modalities_behavior_th_value torch.Size([2, 1]) torch.float32\n",
      "modalities_behavior_th_dt torch.Size([2]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.DataUtils import NFDataloader\n",
    "\n",
    "train_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                             frames=frames, intervals=train_intervals, modalities=modalities)\n",
    "test_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                            frames=frames, intervals=test_intervals, modalities=modalities)\n",
    "finetune_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=args.dataset, \n",
    "                                frames=frames, intervals=finetune_intervals, modalities=modalities)\n",
    "\n",
    "    \n",
    "# print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "iterable = iter(train_dataset)\n",
    "x, y = next(iterable)\n",
    "recursive_print(x)\n",
    "\n",
    "# Update the config\n",
    "model = Neuroformer(config, tokenizer)\n",
    "\n",
    "# Create a DataLoader\n",
    "loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "iterable = iter(loader)\n",
    "x, y = next(iterable)\n",
    "recursive_print(y)\n",
    "preds, features, loss = model(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// FINETUNING... //\n",
      "-- USE WANDB: False --\n",
      "not decaying: temp_emb.temp_emb.0.weight\n",
      "not decaying: temp_emb.temp_emb.0.bias\n",
      "not decaying: temp_emb.temp_emb.2.weight\n",
      "not decaying: temp_emb.temp_emb.2.bias\n",
      "not decaying: temp_emb_prev.temp_emb.0.weight\n",
      "not decaying: temp_emb_prev.temp_emb.0.bias\n",
      "not decaying: temp_emb_prev.temp_emb.2.weight\n",
      "not decaying: temp_emb_prev.temp_emb.2.bias\n",
      "weight_decay: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1  speed_train: 0.83709  phi_train: 0.44549  th_train: 0.60861  id_train: 4.61476  time_train: 0.39752  total_loss: 1.05410 lr 1.200000e-08 precision: 0.00219: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
      "10/19/2023 15:03:46 - INFO - neuroformer.trainer -   saving ./models/NF.15/Visnav_VR_Expt/lateral/Neuroformer/None/finetune/(state_history=6,_state=6,_stimulus=6,_behavior=6,_self_att=6,_modalities=(n_behavior=25))/69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(dropout=namespace(attn=0.2, embd=0.2, pos=0.2, resid=0.2, temp=0.2, b=0.45, id=0.35, im=0.35), block_size=namespace(behavior=15, frame=446, id=100, prev_id=700), layers=namespace(state_history=6, state=6, stimulus=6, behavior=6, self_att=6, modalities=namespace(n_behavior=25)), sparse=namespace(p=None, mask=False, topk=None, topk_frame=None, topk_id=None, topk_prev_id=None), window=namespace(frame=None, curr=0.05, prev=0.05, speed=0.05), modalities=namespace(behavior=namespace(n_layers=4, window=0.05, variables=namespace(speed=namespace(data='speed', dt=0.05, predict=True, objective='regression'), phi=namespace(data='phi', dt=0.05, predict=True, objective='regression'), th=namespace(data='th', dt=0.05, predict=True, objective='regression')))), predict=None, frame_encoder=namespace(conv_layer=True, kernel_size=[4, 5, 5], n_embd=256, n_embd_frames=64, resnet_backbone=False), contrastive=namespace(contrastive=False, vars=['id', 'frames', 'speed'], clip_embd=1024, clip_temp=0.5), resolution=namespace(dt=0.005, speed=0.2, frames=0.05), mlp_only=False, gru_only=False, gru2_only=False, class_weights=None, epoch=760, freeze_weights=None, n_head=8, n_embd=256, pos_emb=False, pretrain=False, start_prune=30, temp_emb=True, vit_encoder=True, vocab_size=2204, ingore_index_pad=True)\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "MAX_EPOCHS = args.epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "SHUFFLE = True\n",
    "\n",
    "if config.gru_only:\n",
    "    model_name = \"GRU\"\n",
    "elif config.mlp_only:\n",
    "    model_name = \"MLP\"\n",
    "elif config.gru2_only:\n",
    "    model_name = \"GRU_2.0\"\n",
    "else:\n",
    "    model_name = \"Neuroformer\"\n",
    "\n",
    "MODE = \"finetune\" if args.finetune else \"train\"\n",
    "CKPT_PATH = f\"./models/NF.15/Visnav_VR_Expt/{args.dataset}/{model_name}/{args.title}/{MODE}/{str(config.layers)}/{args.seed}\".replace(\"namespace\", \"\").replace(\" \", \"_\")\n",
    "\n",
    "if args.sweep_id is not None:\n",
    "    from neuroformer.hparam_sweep import train_sweep\n",
    "    print(f\"-- SWEEP_ID -- {args.sweep_id}\")\n",
    "    wandb.agent(args.sweep_id, function=train_sweep)\n",
    "else:\n",
    "    # Create a TrainerConfig and Trainer\n",
    "    tconf = TrainerConfig(max_epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, learning_rate=1e-4, \n",
    "                          num_workers=16, lr_decay=True, patience=3, warmup_tokens=8e7, \n",
    "                          decay_weights=True, weight_decay=1.0, shuffle=SHUFFLE,\n",
    "                          final_tokens=len(train_dataset)*(config.block_size.id) * (MAX_EPOCHS),\n",
    "                          clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                          show_grads=False,\n",
    "                          ckpt_path=CKPT_PATH, no_pbar=False, \n",
    "                          dist=args.dist, save_every=0, eval_every=5, min_eval_epoch=50,\n",
    "                          use_wandb=False, wandb_project=\"neuroformer\", \n",
    "                          wandb_group=f\"1.5.1_visnav_{args.dataset}\", wandb_name=args.title,\n",
    "                          loss_bprop=args.loss_bprop)\n",
    "\n",
    "    # finetuning to a new task use the finetuning holdout dataset\n",
    "    if args.finetune:\n",
    "        print(f\"// FINETUNING... //\")\n",
    "        # update model with weights\n",
    "        # model.load_state_dict(torch.load(os.path.join(args.ckpt_path, \"model.pt\"),\n",
    "        #                                   map_location=\"cpu\"), strict=False)\n",
    "        trainer = Trainer(model, finetune_dataset, None, tconf, config)\n",
    "    else:\n",
    "        trainer = Trainer(model, train_dataset, test_dataset, tconf, config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
