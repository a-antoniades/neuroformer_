{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "from neuroformer.model_neuroformer import GPT, GPTConfig\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils_2 import (set_seed, update_object, \n",
    "                                 check_common_attrs, running_jupyter, \n",
    "                                 all_device, load_config, update_config, \n",
    "                                 dict_to_object, object_to_dict, recursive_print)\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.SpikeVidUtils import make_intervals, round_n, SpikeTimeVidData2\n",
    "import gdown\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "import argparse\n",
    "from neuroformer.SpikeVidUtils import round_n\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_jupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = 0.05\n",
    "\n",
    "import argparse\n",
    "\n",
    "# Create the parser\n",
    "parser = argparse.ArgumentParser(description='Specify the dataset')\n",
    "\n",
    "# Add an argument\n",
    "parser.add_argument('--dataset', type=str, required=True, help='Dataset to use')\n",
    "\n",
    "# Parse the arguments\n",
    "if running_jupyter():\n",
    "    #namespace\n",
    "    args = argparse.Namespace(dataset='medial')\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Use the argument\n",
    "DATASET = args.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spikes: (32614, 1906), speed: (32614,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from neuroformer.prepare_data import DataLinks\n",
    "from neuroformer.DataUtils import round_n, get_frame_idx\n",
    "from neuroformer.DataUtils import resample_spikes\n",
    "\n",
    "\n",
    "if DATASET in [\"first\", \"visnav\"]:\n",
    "    data_path = \"./data/VisNav_VR_Expt\"\n",
    "elif DATASET == \"medial\":\n",
    "    data_path = \"./data/VisNav_VR_Expt/MedialVRDataset/\"\n",
    "elif DATASET == \"lateral\":\n",
    "    data_path = \"./data/VisNav_VR_Expt/LateralVRDataset\"\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_path, \"train_data.csv\"))\n",
    "\n",
    "spikes_path = f\"{data_path}/NF_1.5/spikerates_dt_0.01.npy\"\n",
    "speed_path = f\"{data_path}/NF_1.5/behavior_speed_dt_0.05.npy\"\n",
    "stim_path = f\"{data_path}/NF_1.5/stimulus.npy\"\n",
    "\n",
    "spikes = resample_spikes(np.load(spikes_path), 0.01, DT).transpose()\n",
    "speed = np.round(np.load(speed_path), 3).transpose()\n",
    "stimulus = np.load(stim_path)\n",
    "\n",
    "frame_feats = None\n",
    "print(f\"spikes: {spikes.shape}, speed: {speed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 32612\n",
      "(32614, 1906)\n",
      "spikes_train: (293, 1906), spikes_test: (32320, 1906)\n"
     ]
    }
   ],
   "source": [
    "train_indexes = set([get_frame_idx(value, DT) for value in train_data['Interval']])\n",
    "test_indexes = set(range(len(speed) - 1)) - train_indexes\n",
    "\n",
    "print(max(train_indexes), max(test_indexes))\n",
    "\n",
    "spikes_train = spikes[list(train_indexes)]\n",
    "print(spikes.shape)\n",
    "spikes_test = spikes[list(test_indexes)]\n",
    "\n",
    "speed_train = speed[list(train_indexes)]\n",
    "speed_test = speed[list(test_indexes)]\n",
    "\n",
    "print(f\"spikes_train: {spikes_train.shape}, spikes_test: {spikes_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iterations: [ 100 1000 1900 2800 3700 4600 5500 6400 7300 8200 9100], output_dimension: [2, 3, 8, 16, 32]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_iterations = np.arange(100, 10000, 900) #default is 5000.\n",
    "output_dimension = [2, 3, 8, 16, 32] #here, we set as a variable for hypothesis testing below.\n",
    "\n",
    "print(f\"max_iterations: {max_iterations}, output_dimension: {output_dimension}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra\n",
    "from cebra import CEBRA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "max_iterations = np.arange(100, 10000, 1900) #default is 5000.\n",
    "output_dimension = [2, 3, 8, 16, 32] #here, we set as a variable for hypothesis testing below.\n",
    "OFFSET = 1\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "\n",
    "\n",
    "# load results\n",
    "if DATASET == \"medial\":\n",
    "    save_dir = \"/share/edc/home/antonis/neuroformer/results/behavior/Medial\"\n",
    "elif DATASET == \"lateral\":\n",
    "    save_dir = \"/share/edc/home/antonis/neuroformer/results/behavior/Lateral\"\n",
    "\n",
    "with open(os.path.join(save_dir, \"cebra_results_1.pkl\"), \"rb\") as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['max_iterations', 'output_dimension', 'embedding', 'embedding_test', 'prediction', 'pearson_correlation'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3938572889229721, 0)\n"
     ]
    }
   ],
   "source": [
    "max_corr = (0, 0)\n",
    "for n, result in enumerate(results):\n",
    "    corr = result['pearson_correlation']\n",
    "    if corr > max_corr[0]:\n",
    "        max_corr = (corr, n)\n",
    "print(max_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3938572889229721, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
