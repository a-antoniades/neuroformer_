{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter notebook\n",
      " // CONTRASTIVE: True //\n",
      " // VISUAL: True //\n",
      " // PAST_STATE: True //\n",
      " // PREDICT_BEHAVIOR: False //\n",
      " // BEHAVIOR: True //\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from neuroformer.model_neuroformer import GPT, GPTConfig, neuralGPTConfig\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import set_seed, update_object\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.SpikeVidUtils import round_n, set_intervals\n",
    "set_plot_params()\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--infer\", action=\"store_true\", help=\"Inference mode\")\n",
    "    parser.add_argument(\"--train\", action=\"store_true\", default=False, help=\"Train mode\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"first\", help=\"Dataset\")\n",
    "    parser.add_argument(\"--dist\", action=\"store_true\", default=False, help=\"Distrinuted training\")\n",
    "    parser.add_argument(\"--resume\", type=str, default=None, help=\"Resume from checkpoint\")\n",
    "    parser.add_argument(\"--rand_perm\", action=\"store_true\", default=False, help=\"Randomly permute the ID column\")\n",
    "    parser.add_argument(\"--mconf\", type=str, default=None, help=\"Path to model config file\")\n",
    "    parser.add_argument(\"--downstream\", action=\"store_true\", default=False, help=\"Downstream task\")\n",
    "    parser.add_argument(\"--freeze_model\", action=\"store_true\", default=False, help=\"Freeze model\")\n",
    "    parser.add_argument(\"--title\", type=str, default=None)\n",
    "    parser.add_argument(\"--seed\", type=int, default=25)\n",
    "    parser.add_argument(\"--behavior\", action=\"store_true\", default=False, help=\"Behavior task\")\n",
    "    parser.add_argument(\"--predict_behavior\", action=\"store_true\", default=False, help=\"Predict behavior\")\n",
    "    # parser.add_argument(\"--behavior_vars\", type=str, default=None, help=\"Behavior variables\")\n",
    "    parser.add_argument(\"--behavior_vars\", nargs='+', default=None, help=\"Behavior variables\")\n",
    "    parser.add_argument(\"--past_state\", action=\"store_true\", default=False, help=\"Input past state\")\n",
    "    parser.add_argument(\"--visual\", action=\"store_true\", default=False, help=\"Visualize\")\n",
    "    parser.add_argument(\"--contrastive\", action=\"store_true\", default=False, help=\"Contrastive\")\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "    return parser.parse_args()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     args = parse_args()\n",
    "#     INFERENCE = not args.train\n",
    "# else:\n",
    "#     INFERENCE = True\n",
    "\n",
    "# check if jupyter notebook\n",
    "try:\n",
    "    shell = get_ipython().__class__.__name__\n",
    "    print(\"Running in Jupyter notebook\")\n",
    "    INFERENCE = True\n",
    "    DATASET = \"visnav\"\n",
    "    DIST = False\n",
    "    DOWNSTREAM = False\n",
    "    RESUME = None# \"./models/tensorboard/visnav/behavior_pred_exp/classification/window:0.05_prev:0.25/sparse_f:None_id:None/w:0.05_wp:0.25/6_Cont:False_window:0.05_f_window:0.2_df:0.005_blocksize:100_conv_True_shuffle:True_batch:224_sparse_(None_None)_blocksz446_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_52_max0.005_(8, 8, 8)_8_256.pt\"\n",
    "    RAND_PERM = False\n",
    "    MCONF = \"./configs/visnav/predict_behavior/behavior_exp/mconf.yaml\"\n",
    "    # MCONF = \"./configs/visnav/lateral_phi_th/mconf.yaml\"\n",
    "    FREEZE_MODEL = False\n",
    "    TITLE = None\n",
    "    SEED = 25\n",
    "    BEHAVIOR = True\n",
    "    PREDICT_BEHAVIOR = False\n",
    "    BEHAVIOR_VARS = ['speed']\n",
    "    PAST_STATE = True\n",
    "    VISUAL = True\n",
    "    CONTRASTIVE = True\n",
    "except:\n",
    "    print(\"Running in terminal\")\n",
    "    args = parse_args()\n",
    "    INFERENCE = not args.train\n",
    "    DATASET = args.dataset\n",
    "    DIST = args.dist\n",
    "    DOWNSTREAM = args.downstream\n",
    "    RESUME = args.resume\n",
    "    RAND_PERM = args.rand_perm\n",
    "    MCONF = args.mconf\n",
    "    FREEZE_MODEL = args.freeze_model\n",
    "    TITLE = args.title\n",
    "    SEED = args.seed\n",
    "    BEHAVIOR = args.behavior\n",
    "    PREDICT_BEHAVIOR = args.predict_behavior\n",
    "    BEHAVIOR_VARS = args.behavior_vars\n",
    "    PAST_STATE = args.past_state\n",
    "    VISUAL = args.visual\n",
    "    CONTRASTIVE = args.contrastive\n",
    "\n",
    "set_seed(25)\n",
    "\n",
    "print(f\" // CONTRASTIVE: {CONTRASTIVE} //\")\n",
    "print(f\" // VISUAL: {VISUAL} //\")\n",
    "print(f\" // PAST_STATE: {PAST_STATE} //\")\n",
    "print(f\" // PREDICT_BEHAVIOR: {PREDICT_BEHAVIOR} //\")\n",
    "print(f\" // BEHAVIOR: {BEHAVIOR} //\")\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.prepare_data import DataLinks\n",
    "\n",
    "ds = \"LateralVRDataset\"\n",
    "ds = \"MedialVRDataset\"\n",
    "ds = \"VisNav_VR_Expt\"\n",
    "data_dir = f\"data/VisNav_VR_Expt/\"\n",
    "DATA_POINTERS = getattr(DataLinks, ds)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading data...\")\n",
    "    import gdown\n",
    "    url = DATA_POINTERS['url']\n",
    "    gdown.download_folder(id=url, quiet=False, use_cookies=False, output=DATA_POINTERS['DIRECTORY'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config files\n",
    "import yaml\n",
    "\n",
    "# base_path = \"configs/visnav/predict_behavior\"\n",
    "base_path = \"./models/tensorboard/visnav_medial\" if MCONF is None else os.path.dirname(MCONF)\n",
    "\n",
    "with open(os.path.join(base_path, 'mconf.yaml'), 'r') as stream:\n",
    "    mconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'tconf.yaml'), 'r') as stream:\n",
    "    tconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'dconf.yaml'), 'r') as stream:\n",
    "    dconf = yaml.full_load(stream)\n",
    "\n",
    "# open yaml as omegacong\n",
    "mconf = OmegaConf.create(mconf)\n",
    "tconf = OmegaConf.create(tconf)\n",
    "dconf = OmegaConf.create(dconf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./data/VisNav_VR_Expt\n"
     ]
    }
   ],
   "source": [
    "import mat73\n",
    "\n",
    "# data_path = DATA_POINTERS['RESPONSE_PATH']\n",
    "if DATASET in [\"first\", \"visnav\"]:\n",
    "    data_path = \"./data/VisNav_VR_Expt\"\n",
    "elif DATASET == \"medial\":\n",
    "    data_path = \"./data/VisNav_VR_Expt/MedialVRDataset/\"\n",
    "elif DATASET == \"lateral\":\n",
    "    data_path = \"./data/VisNav_VR_Expt/LateralVRDataset\"\n",
    "\n",
    "print(f\"Loading data from {data_path}\")\n",
    "# stimulus = np.load(os.path.join(data_path, \"stimulus.npy\"), allow_pickle=True)\n",
    "# response = np.load(os.path.join(data_path, \"response.npy\"), allow_pickle=True)\n",
    "# trial_data = np.load(os.path.join(data_path, \"trial_data.npy\"), allow_pickle=True)\n",
    "data = mat73.loadmat(os.path.join(data_path, \"experiment_data.mat\"))['neuroformer']\n",
    "\n",
    "# data_response_path = \"/data5/antonis/neuroformer/data/VisNav_VR_Expt/yiyi/experiment_data_selected.mat\"\n",
    "# data_response = scipy.io.loadmat(data_response_path)\n",
    "# neurons_sel1 = \"./data/VisNav_VR_Expt/yiyi/sel1.csv\"\n",
    "# neurons_sel1 = pd.read_csv(neurons_sel1)\n",
    "# neurons_sel1 = np.array(neurons_sel1).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INFERENCE:\n",
    "    window = mconf.window\n",
    "    window_prev = mconf.window_prev\n",
    "    frame_window = mconf.frame_window\n",
    "    window_behavior = mconf.window_behavior if hasattr(mconf, 'window_behavior') else None\n",
    "    dt = mconf.dt\n",
    "    dt_frames = mconf.dt_frames if hasattr(mconf, 'dt_frames') else 0.05\n",
    "    dt_vars = mconf.dt_vars if hasattr(mconf, 'dt_vars') else 0.05\n",
    "    dt_speed = mconf.dt_speed if hasattr(mconf, 'dt_speed') else 0.2\n",
    "    intervals = None\n",
    "else:\n",
    "    window = 0.05\n",
    "    window_prev = 0.25\n",
    "    frame_window = window + window_prev\n",
    "    window_behavior = window\n",
    "    dt = 0.005\n",
    "    dt_frames = 0.05\n",
    "    dt_vars = 0.05\n",
    "    dt_speed = 0.2\n",
    "    intervals = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " // using behavior vars: ['speed'] //\n"
     ]
    }
   ],
   "source": [
    "## choose modalities ##\n",
    "\n",
    "# behavior\n",
    "behavior = BEHAVIOR\n",
    "# behavior_vars = ['t', 'eyerad', 'phi', 'speed', 'th']\n",
    "behavior_vars = ['speed'] if BEHAVIOR_VARS is None else BEHAVIOR_VARS\n",
    "n_behavior = len(behavior_vars)\n",
    "predict_behavior = PREDICT_BEHAVIOR\n",
    "# stimulus\n",
    "visual_stim = VISUAL\n",
    "\n",
    "print(f\" // using behavior vars: {BEHAVIOR_VARS} //\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eyerad', 'phi', 'speed', 'spiketimes', 't', 'th', 'trialsummary', 'vid_sm'])\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.SpikeVidUtils import trial_df, get_df_visnav, make_intervals, set_trials\n",
    "\n",
    "stimulus = data['vid_sm']\n",
    "response = data['spiketimes']['spks']\n",
    "trial_data = data['trialsummary']\n",
    "# response = data_response['spiketime_sel2']['spks']\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "df = get_df_visnav(response, trial_data, dt_vars)\n",
    "# df = df[df['ID'].isin(neurons_sel1)].reset_index(drop=True)\n",
    "\n",
    "if behavior or predict_behavior is True:\n",
    "    df_behavior = pd.DataFrame({k: data[k] for k in behavior_vars + ['t']})\n",
    "    # rename t to time\n",
    "    df_behavior = df_behavior.rename(columns={'t': 'Time'}) if df_behavior is not None else None\n",
    "    df_behavior = set_trials(df_behavior, trial_data) \n",
    "    df_behavior['Interval'] = make_intervals(df_behavior, window)\n",
    "    df_behavior['Interval_2'] = make_intervals(df_behavior, window_prev)\n",
    "\n",
    "    # prepare speed variables\n",
    "    if 'speed' in df_behavior.columns:\n",
    "        df_behavior['speed'] = df_behavior['speed'].apply(lambda x: round_n(x, dt_speed))\n",
    "        dt_range_speed = df_behavior['speed'].min(), df_behavior['speed'].max()\n",
    "        dt_range_speed = np.arange(dt_range_speed[0], dt_range_speed[1] + dt_speed, dt_speed)\n",
    "        n_behavior = len(dt_range_speed)\n",
    "        stoi_speed = { round_n(ch, dt_speed):i for i,ch in enumerate(dt_range_speed) }\n",
    "        itos_speed = { i:round_n(ch, dt_speed) for i,ch in enumerate(dt_range_speed) }\n",
    "    else:\n",
    "        n_behavior = None\n",
    "        stoi_speed = None\n",
    "        itos_speed = None\n",
    "        assert predict_behavior is False\n",
    "\n",
    "    # assert (window_behavior) % dt_vars < 1e-5, \"window + window_prev must be divisible by dt_vars\"\n",
    "    samples_per_behavior = int((window + window_prev) // dt_vars)\n",
    "    behavior_block_size = int((window + window_prev) // dt_vars) * (len(df_behavior.columns) - 1)\n",
    "else:\n",
    "    behavior = False \n",
    "    df_behavior = None\n",
    "    behavior_vars = None\n",
    "    behavior_block_size = 0\n",
    "    samples_per_behavior = 0\n",
    "    stoi_speed = None\n",
    "    itos_speed = None\n",
    "    dt_range_speed = None\n",
    "    n_behavior = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.SpikeVidUtils import make_intervals\n",
    "\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['real_interval'] = make_intervals(df, 0.05)\n",
    "df['Interval_2'] = make_intervals(df, window_prev)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1  # add first / last interval for SOS / EOS'\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)] + ['EOS'] + ['PAD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique groups: 32689\n",
      "Top 0.05 groups: Interval  Trial\n",
      "1.95      271      123\n",
      "1.35      215      120\n",
      "1.60      149      110\n",
      "4.80      297      110\n",
      "3.25      285      107\n",
      "                  ... \n",
      "4.35      215       37\n",
      "4.40      279       37\n",
      "4.50      261       37\n",
      "4.55      128       37\n",
      "          204       37\n",
      "Length: 1634, dtype: int64\n",
      "Mean groups: 18.78922573342715\n"
     ]
    }
   ],
   "source": [
    "var_group = 'Interval'\n",
    "groups = df.groupby([var_group, 'Trial']).size()\n",
    "n_unique = len(groups)\n",
    "top_p = 0.05\n",
    "top_k_groups = groups.nlargest(int(top_p * n_unique))\n",
    "mean_groups = groups.mean()\n",
    "\n",
    "print(f\"Unique groups: {n_unique}\")\n",
    "print(f\"Top {top_p} groups: {top_k_groups}\")\n",
    "print(f\"Mean groups: {mean_groups}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique groups: 6650\n",
      "Top 0.2 groups: Interval_2  Trial\n",
      "13.75       296      378\n",
      "0.50        1        374\n",
      "14.00       296      364\n",
      "0.75        186      347\n",
      "6.50        160      347\n",
      "                    ... \n",
      "0.75        86       117\n",
      "1.25        115      117\n",
      "1.50        274      117\n",
      "1.75        111      117\n",
      "2.25        164      117\n",
      "Length: 1330, dtype: int64\n",
      "Mean groups: 92.36105263157894\n"
     ]
    }
   ],
   "source": [
    "var_group = 'Interval_2'\n",
    "groups = df.groupby([var_group, 'Trial']).size()\n",
    "n_unique = len(groups)\n",
    "top_p = 0.2\n",
    "top_k_groups = groups.nlargest(int(top_p * n_unique))\n",
    "mean_groups = groups.mean()\n",
    "\n",
    "print(f\"Unique groups: {n_unique}\")\n",
    "print(f\"Top {top_p} groups: {top_k_groups}\")\n",
    "print(f\"Mean groups: {mean_groups}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "## resnet3d feats\n",
    "n_frames = round(frame_window * 1/dt_frames)\n",
    "kernel_size = (n_frames, 5, 5)\n",
    "n_embd = 256\n",
    "n_embd_frames = 64\n",
    "frame_feats = stimulus\n",
    "frame_block_size = ((n_frames // kernel_size[0] * 30 * 100) // (n_embd_frames))\n",
    "frame_feats = torch.tensor(stimulus, dtype=torch.float32)\n",
    "conv_layer = True\n",
    "\n",
    "prev_id_block_size = 350\n",
    "id_block_size = 125   #\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size\n",
    "frame_memory = frame_window // dt_frames\n",
    "window = window\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "trial_tokens = [f\"Trial {n}\" for n in df['Trial'].unique()]\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "r_split = 0.8\n",
    "all_trials = sorted(df['Trial'].unique())\n",
    "train_trials = random.sample(all_trials, int(len(all_trials) * r_split))\n",
    "\n",
    "train_data = df[df['Trial'].isin(train_trials)]\n",
    "test_data = df[~df['Trial'].isin(train_trials)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Size:  2204\n",
      "ID Population Size:  2204\n",
      "DT Population Size:  28\n",
      "Population Size:  2204\n",
      "ID Population Size:  2204\n",
      "DT Population Size:  28\n",
      "train: 24727, test: 6477\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=None, dataset='visnav',\n",
    "                                  behavior=df_behavior, behavior_vars=behavior_vars, dt_vars=dt_vars,\n",
    "                                  behavior_block_size=behavior_block_size, samples_per_behavior=samples_per_behavior,\n",
    "                                  window_behavior=window_behavior, predict_behavior=predict_behavior,\n",
    "                                  stoi_speed=stoi_speed, itos_speed=itos_speed, dt_speed=dt_speed)\n",
    "\n",
    "# update_object(train_dataset, dconf)\n",
    "train_dataset = train_dataset.copy(train_data)\n",
    "test_dataset = train_dataset.copy(test_data)\n",
    "\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=None, dataset='visnav',\n",
    "                                  behavior=df_behavior, behavior_vars=behavior_vars, dt_vars=dt_vars,\n",
    "                                  behavior_block_size=behavior_block_size, samples_per_behavior=samples_per_behavior,\n",
    "                                  window_behavior=window_behavior, predict_behavior=predict_behavior,\n",
    "                                  stoi_speed=stoi_speed, itos_speed=itos_speed, dt_speed=dt_speed)\n",
    "# update_object(test_dataset, dconf)\n",
    "test_dataset = test_dataset.copy(test_data)\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.predict_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_prev torch.Size([2, 350])\n",
      "dt_prev torch.Size([2, 350])\n",
      "pad_prev torch.Size([2])\n",
      "id torch.Size([2, 125])\n",
      "dt torch.Size([2, 125])\n",
      "pad torch.Size([2])\n",
      "interval torch.Size([2])\n",
      "trial torch.Size([2])\n",
      "behavior torch.Size([2, 1, 5, 1])\n",
      "behavior_dt torch.Size([2, 5])\n",
      "frames torch.Size([2, 1, 4, 30, 100])\n",
      "cid torch.Size([2, 2])\n",
      "pid torch.Size([2, 2])\n",
      "f_idx torch.Size([2, 2])\n",
      "y: id, torch.Size([2, 125])\n",
      "y: dt, torch.Size([2, 125])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iterable)\n",
    "# print(x['behavior'].shape, x['behavior_dt'].shape)\n",
    "for k in x.keys():\n",
    "    print(k, x[k].shape)\n",
    "for k in y.keys():\n",
    "    print(f\"y: {k}, {y[k].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)   \n",
    "max_epochs = 2500\n",
    "batch_size = round((32 * 6))\n",
    "shuffle = True\n",
    "\n",
    "model_conf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                        id_vocab_size=train_dataset.id_population_size,\n",
    "                        frame_block_size=frame_block_size,\n",
    "                        id_block_size=id_block_size,  # frame_block_size\n",
    "                        prev_id_block_size=prev_id_block_size,\n",
    "                        behavior_block_size=behavior_block_size,\n",
    "                        sparse_mask=False, p_sparse=None, \n",
    "                        sparse_topk_frame=None, sparse_topk_id=None, sparse_topk_prev_id=None,\n",
    "                        n_dt=len(n_dt),\n",
    "                        class_weights=None,\n",
    "                        pretrain=False,\n",
    "                        n_state_layers=mconf.n_state_layers, n_state_history_layers=mconf.n_state_history_layers,\n",
    "                        n_stimulus_layers=mconf.n_stimulus_layers, self_att_layers=mconf.self_att_layers,\n",
    "                        n_behavior_layers=mconf.n_behavior_layers, predict_behavior=predict_behavior, n_behavior=n_behavior,\n",
    "                        n_head=mconf.n_head, n_embd=mconf.n_embd, \n",
    "                        contrastive=mconf.contrastive, clip_emb=mconf.clip_emb, clip_temp=mconf.clip_temp, clip_loss=False,\n",
    "                        conv_layer=conv_layer, kernel_size=kernel_size,\n",
    "                        temp_emb=mconf.temp_emb, pos_emb=False, wave_emb=True,\n",
    "                        id_drop=0.35, im_drop=0.35, b_drop=0.45,\n",
    "                        window=window, window_prev=window_prev, frame_window=frame_window, dt=dt,\n",
    "                        neurons=neurons, stoi_dt=stoi_dt, itos_dt=itos_dt, n_embd_frames=n_embd_frames,\n",
    "                        ignore_index_id=stoi['PAD'], ignore_index_dt=stoi_dt['PAD'])  # 0.35\n",
    "\n",
    "# update_object(model_conf, mconf)\n",
    "model_conf.contrastive_vars = ['id', 'frames']\n",
    "\n",
    "if INFERENCE or MCONF is not None:\n",
    "    update_object(model_conf, mconf)\n",
    "\n",
    "if not INFERENCE:\n",
    "\n",
    "    if BEHAVIOR and not PREDICT_BEHAVIOR:\n",
    "        model_conf.contrastive_vars += ['behavior_mean']\n",
    "        \n",
    "    if PREDICT_BEHAVIOR is True:\n",
    "        print(f\"// Predict behavior: n_behavior_layers = 0 //\")\n",
    "        model_conf.n_behavior_layers = 0\n",
    "\n",
    "    if PAST_STATE is False:\n",
    "        print(f\"// -- No past state, layers=0 -- //\")\n",
    "        model_conf.n_state_history_layers = 0\n",
    "\n",
    "    if CONTRASTIVE is True:\n",
    "        print(f\"// -- contrastive objective -- //\")\n",
    "        model_conf.contrastive = True\n",
    "    else:\n",
    "        print(f\"// -- NOOO cross entropy objective -- //\")\n",
    "        model_conf.contrastive = False\n",
    "\n",
    "    if VISUAL is False:\n",
    "        print(f\"// -- No visual, layers=0 -- //\")\n",
    "        model_conf.n_stimulus_layers = 0\n",
    "\n",
    "    if MCONF is not None:\n",
    "        print(f\"// -- updating model conf -- //\")\n",
    "        update_object(model_conf, mconf)\n",
    "\n",
    "model = GPT(model_conf)\n",
    "\n",
    "if RESUME:\n",
    "    print(f\"// -- Resuming model -- //\")\n",
    "    model.load_state_dict(torch.load(RESUME), strict=True)\n",
    "\n",
    "title =  f'first/RESUME{RESUME != None}_paststate{PAST_STATE}_method_behavior_{behavior}_{behavior_vars}_predictbehavior{PREDICT_BEHAVIOR}_visual{VISUAL}_contrastive{model_conf.contrastive}_{model_conf.contrastive_vars}'\n",
    "# model_path = f\"\"\"./models/tensorboard/visnav_medial/{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\"\n",
    "model_path = f\"\"\"./models/tensorboard/visnav_{DATASET}/behavior_pred_exp/classification/{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\n",
    "\n",
    "# # %%\n",
    "# model.cpu()\n",
    "# preds, features, loss = model(x, y)\n",
    "# for key in loss.keys():\n",
    "#     print(key, loss[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(F\"DIST: {DIST}\")\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=2e-4, \n",
    "                    num_workers=4, lr_decay=True, patience=3, warmup_tokens=8e7, \n",
    "                    decay_weights=True, weight_decay=1.0, shuffle=shuffle,\n",
    "                    final_tokens=len(train_dataset)*(id_block_size) * (max_epochs),\n",
    "                    clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                    dataset='higher_order', mode='predict',\n",
    "                    block_size=train_dataset.block_size,\n",
    "                    id_block_size=train_dataset.id_block_size,\n",
    "                    show_grads=False, plot_raster=False,\n",
    "                    ckpt_path=model_path, no_pbar=False, \n",
    "                    dist=DIST, save_every=50)\n",
    "\n",
    "if not INFERENCE:\n",
    "    # trainer = Trainer(model, train_dataset, test_dataset, tconf, model_conf)\n",
    "    # if DOWNSTREAM:\n",
    "    #     mconf.__setattr__('freeze_model', FREEZE_MODEL)\n",
    "    #     trainer.config.__setattr__('warmup_tokens', 100)\n",
    "    #     N_CLASSES = 2\n",
    "    #     classifier = ClassifierWrapper(model, mconf, N_CLASSES)\n",
    "    #     train_model = classifier\n",
    "\n",
    "    # else:\n",
    "    #     train_model = model\n",
    "    train_model = model\n",
    "    trainer = Trainer(train_model, train_dataset, test_dataset, tconf, model_conf)\n",
    "    trainer.train()\n",
    "else:\n",
    "    model_path = glob.glob(os.path.join(base_path, '**.pt'), recursive=True)[0]\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path), strict=True)\n",
    "\n",
    "# loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# iterable = iter(loader)\n",
    "# x, y = next(iterable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, features, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.utils import predict_raster_recursive_time_auto, process_predictions\n",
    "\n",
    "PARALLEL = True\n",
    "df_pred_path = None\n",
    "\n",
    "results_dict = dict()\n",
    "df_pred = None if df_pred_path is None else pd.read_csv(df_pred_path)\n",
    "df_true = None\n",
    "\n",
    "top_p = 0.75\n",
    "top_p_t = 0.75\n",
    "temp = 1.25\n",
    "temp_t = 1.25\n",
    "\n",
    "test_trials = test_data['Trial'].unique()\n",
    "# pick 8 trials at random from test\n",
    "trials = np.random.choice(test_trials, 8, replace=False)\n",
    "\n",
    "if df_pred_path is None:\n",
    "    from joblib import Parallel, delayed\n",
    "    # Define a function to process each trial\n",
    "    def process_trial(model, train_dataset, df, stoi, itos_dt, itos, window, window_prev, top_p, top_p_t, temp, temp_t, trial):\n",
    "        print(f\"-- Trial: {trial} --\")\n",
    "        df_trial = df[df['Trial'] == trial]\n",
    "        trial_dataset = train_dataset.copy(df_trial)\n",
    "        results_trial = predict_raster_recursive_time_auto(model, trial_dataset, window, window_prev, stoi, itos_dt, itos=itos, \n",
    "                                                        sample=True, top_p=top_p, top_p_t=top_p_t, temp=temp, temp_t=temp_t, \n",
    "                                                        frame_end=0, get_dt=True, gpu=False, pred_dt=True, plot_probs=False)\n",
    "        df_trial_pred, df_trial_true = process_predictions(results_trial, stoi, itos, window)\n",
    "        print(f\"pred: {df_trial_pred.shape}, true: {df_trial_true.shape}\" )\n",
    "        return df_trial_pred, df_trial_true\n",
    "\n",
    "    if PARALLEL:\n",
    "        # Process each trial in parallel\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_trial)(model, train_dataset, df, stoi, itos_dt, \n",
    "                                                            itos, window, window_prev, top_p, top_p_t, \n",
    "                                                            temp, temp_t, trial) for trial in trials)\n",
    "    else:\n",
    "        # Process each trial sequentially\n",
    "        results = []\n",
    "        for trial in trials:\n",
    "            results.append(process_trial(model, train_dataset, df, stoi, itos_dt, \n",
    "                                            itos, window, window_prev, top_p, top_p_t, \n",
    "                                            temp, temp_t, trial))\n",
    "    # Combine the results from each trial\n",
    "    for n, (df_trial_pred, df_trial_true) in enumerate(results):   \n",
    "        print(f\"-- No. {n} Trial --\")\n",
    "        if df_pred is None:\n",
    "            df_pred = df_trial_pred\n",
    "            df_true = df_trial_true\n",
    "        else:\n",
    "            df_pred = pd.concat([df_pred, df_trial_pred])\n",
    "            df_true = pd.concat([df_true, df_trial_true])\n",
    "\n",
    "\n",
    "from neuroformer.analysis import compute_scores\n",
    "df_true = df[df['Trial'].isin(trials)]\n",
    "scores = compute_scores(df_true, df_pred)\n",
    "print(scores)\n",
    "print(f\"len predL: {len(df_pred)}, len true: {len(df_true)}\")\n",
    "\n",
    "dir_name = os.path.dirname(model_path)\n",
    "model_name = os.path.basename(model_path)\n",
    "df_pred.to_csv(os.path.join(dir_name, F'df_pred_.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import get_rates_trial, calc_corr_psth\n",
    "\n",
    "df_1 = df[df['Trial'].isin(trials)]\n",
    "df_pred_full = df_pred\n",
    "\n",
    "window_pred = 1\n",
    "window_pred = window if window_pred is None else window_pred\n",
    "df_pred_full = set_intervals(df_pred_full, window, window_prev, window_pred)\n",
    "df_1 = set_intervals(df_1, window, window_prev, window_pred)\n",
    "\n",
    "intervals = np.array(sorted(set(df['Interval'].unique()) & set(df['Interval'].unique())))\n",
    "labels = np.array([round(window_pred + window_pred*n, 2) for n in range(0, int(max(df_pred_full['Interval']) / window_pred))])\n",
    "ids = sorted(set(df['ID'].unique()) & set(df['ID'].unique()))\n",
    "\n",
    "rates_pred = get_rates_trial(df_pred_full, labels)\n",
    "rates_1 = get_rates_trial(df_1, labels)\n",
    "\n",
    "top_corr_pred = calc_corr_psth(rates_pred, rates_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Evaluate results\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from neuroformer.visualize import *\n",
    "from neuroformer.analysis import get_accuracy\n",
    "\n",
    "\n",
    "len_pred, len_true = len(df_pred_full), len(df_1)\n",
    "print(f\"len_pred: {len_pred}, len_true: {len_true}\")\n",
    "\n",
    "accuracy = get_accuracy(df_pred, df_1)\n",
    "pred_scores = compute_scores(df_1, df_pred_full)\n",
    "\n",
    "print(f\"pred: {pred_scores}\")\n",
    "\n",
    "n_bins = 30\n",
    "set_plot_white()\n",
    "plt.figure(figsize=(10, 10), facecolor='white')\n",
    "plt.title(f'PSTH Correlations (V1 + AL) {title}', fontsize=25)\n",
    "plt.ylabel('Count (n)', fontsize=25)\n",
    "plt.xlabel('Pearson r', fontsize=25)\n",
    "# plt.hist(top_corr_real_2, label='real - real3', alpha=0.6)\n",
    "plt.hist(top_corr_pred, label='real - simulated', alpha=0.6, bins=30)\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "dir_name = os.path.dirname(model_path)\n",
    "model_name = os.path.basename(model_path)\n",
    "\n",
    "top_p = 0\n",
    "save_title = f'_top_p{top_p}'\n",
    "plt.savefig(os.path.join(dir_name, F'psth_corr_{save_title}_.svg'))\n",
    "df_pred.to_csv(os.path.join(dir_name, F'df_pred_{save_title}_.csv'))\n",
    "\n",
    "plot_distribution(df_1, df_pred, save_path=os.path.join(dir_name, F'psth_dist_.svg'))\n",
    "# save scores to json}}\n",
    "with open(os.path.join(dir_name, F'scores_{save_title}_.json'), 'w') as fp:\n",
    "    json.dump(pred_scores, fp)\n",
    "\n",
    "\n",
    "total_scores = dict()\n",
    "total_scores['pred'] = pred_scores\n",
    "\n",
    "print(f\"model: {title}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = iter(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iv: 0.550000011920929, ix+window: 0.600000011920929 pid: tensor([0.3000, 0.5500]) cid: tensor([0.5500, 0.6000])\n",
      "x: ['SOS', 1727, 1727, 1236, 1481, 1138, 1332, 450, 552, 1110, 489, 1340, 298, 1727, 166, 108, 1155, 1090, 'EOS']\n",
      "xid_prev: ['SOS', 1070, 449, 888, 773, 2161, 445, 888, 773, 888, 1900, 1900, 888, 1086, 445, 1156, 1881, 155, 773, 874, 2198, 1624, 253, 1125, 473, 773, 2161, 1929, 13, 2133, 1913, 13, 1558, 2151, 1454, 1166, 155, 1500, 1167, 1155, 1225, 486, 1284, 2133, 485, 773, 1262, 2161, 1454, 1643, 773, 1225, 2067, 1454, 1188, 1929, 1466, 2115, 1885, 813, 435, 1185, 773, 1696, 772, 40, 672, 1408, 1900, 689, 435, 1061, 2115, 25, 2024, 1855, 435, 2039, 1367, 1398, 1869, 773, 691, 653, 450, 2184, 2115, 2050, 117, 155, 1392, 113, 1130, 113, 1727, 1106, 198, 1379, 2070, 955, 1727, 1122, 'EOS', 'PAD', 'PAD', 'PAD']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Trial</th>\n",
       "      <th>raw_time</th>\n",
       "      <th>raw_interval</th>\n",
       "      <th>Interval</th>\n",
       "      <th>real_interval</th>\n",
       "      <th>Interval_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>0.550719</td>\n",
       "      <td>1727</td>\n",
       "      <td>3</td>\n",
       "      <td>12.485635</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>0.552210</td>\n",
       "      <td>1727</td>\n",
       "      <td>3</td>\n",
       "      <td>12.487126</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>0.555994</td>\n",
       "      <td>1236</td>\n",
       "      <td>3</td>\n",
       "      <td>12.490910</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>0.556918</td>\n",
       "      <td>1481</td>\n",
       "      <td>3</td>\n",
       "      <td>12.491834</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>0.557125</td>\n",
       "      <td>1138</td>\n",
       "      <td>3</td>\n",
       "      <td>12.492041</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>0.560827</td>\n",
       "      <td>1332</td>\n",
       "      <td>3</td>\n",
       "      <td>12.495743</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4258</th>\n",
       "      <td>0.565940</td>\n",
       "      <td>450</td>\n",
       "      <td>3</td>\n",
       "      <td>12.500856</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>0.566814</td>\n",
       "      <td>552</td>\n",
       "      <td>3</td>\n",
       "      <td>12.501730</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>0.574445</td>\n",
       "      <td>1110</td>\n",
       "      <td>3</td>\n",
       "      <td>12.509361</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>0.577258</td>\n",
       "      <td>489</td>\n",
       "      <td>3</td>\n",
       "      <td>12.512174</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>0.580261</td>\n",
       "      <td>1340</td>\n",
       "      <td>3</td>\n",
       "      <td>12.515177</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>0.581727</td>\n",
       "      <td>298</td>\n",
       "      <td>3</td>\n",
       "      <td>12.516643</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>0.582170</td>\n",
       "      <td>1727</td>\n",
       "      <td>3</td>\n",
       "      <td>12.517086</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>0.589021</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>12.523937</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>0.590911</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>12.525827</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>0.593190</td>\n",
       "      <td>1155</td>\n",
       "      <td>3</td>\n",
       "      <td>12.528106</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>0.593705</td>\n",
       "      <td>1090</td>\n",
       "      <td>3</td>\n",
       "      <td>12.528621</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time    ID  Trial   raw_time  raw_interval  Interval  real_interval  \\\n",
       "4252  0.550719  1727      3  12.485635         12.50       0.6            0.6   \n",
       "4253  0.552210  1727      3  12.487126         12.50       0.6            0.6   \n",
       "4254  0.555994  1236      3  12.490910         12.50       0.6            0.6   \n",
       "4255  0.556918  1481      3  12.491834         12.50       0.6            0.6   \n",
       "4256  0.557125  1138      3  12.492041         12.50       0.6            0.6   \n",
       "4257  0.560827  1332      3  12.495743         12.50       0.6            0.6   \n",
       "4258  0.565940   450      3  12.500856         12.55       0.6            0.6   \n",
       "4259  0.566814   552      3  12.501730         12.55       0.6            0.6   \n",
       "4260  0.574445  1110      3  12.509361         12.55       0.6            0.6   \n",
       "4261  0.577258   489      3  12.512174         12.55       0.6            0.6   \n",
       "4262  0.580261  1340      3  12.515177         12.55       0.6            0.6   \n",
       "4263  0.581727   298      3  12.516643         12.55       0.6            0.6   \n",
       "4264  0.582170  1727      3  12.517086         12.55       0.6            0.6   \n",
       "4265  0.589021   166      3  12.523937         12.55       0.6            0.6   \n",
       "4266  0.590911   108      3  12.525827         12.55       0.6            0.6   \n",
       "4267  0.593190  1155      3  12.528106         12.55       0.6            0.6   \n",
       "4268  0.593705  1090      3  12.528621         12.55       0.6            0.6   \n",
       "\n",
       "      Interval_2  \n",
       "4252        0.75  \n",
       "4253        0.75  \n",
       "4254        0.75  \n",
       "4255        0.75  \n",
       "4256        0.75  \n",
       "4257        0.75  \n",
       "4258        0.75  \n",
       "4259        0.75  \n",
       "4260        0.75  \n",
       "4261        0.75  \n",
       "4262        0.75  \n",
       "4263        0.75  \n",
       "4264        0.75  \n",
       "4265        0.75  \n",
       "4266        0.75  \n",
       "4267        0.75  \n",
       "4268        0.75  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# while x['trial'] < 4:\n",
    "\n",
    "x, y = next(iterable)\n",
    "\n",
    "T = len(x['id'])\n",
    "P = x['pad'] - 1\n",
    "T_prev = len(x['id_prev'])\n",
    "P_prev = x['pad_prev'] - 4\n",
    "\n",
    "iv = float(x['interval'])\n",
    "\n",
    "xid = x['id'][: T - P]\n",
    "xid = [itos[int(i)] for i in xid]\n",
    "\n",
    "xid_prev = x['id_prev'][: T_prev - P_prev]\n",
    "xid_prev = [itos[int(i)] for i in xid_prev]\n",
    "\n",
    "print(f\"iv: {iv}, ix+window: {iv + window} pid: {x['pid']} cid: {x['cid']}\")\n",
    "print(f\"x: {xid}\")\n",
    "print(f\"xid_prev: {xid_prev}\")\n",
    "\n",
    "if 'behavior' in y:\n",
    "    t_var = 'Interval' # 'Interval'\n",
    "    tdiff = 0\n",
    "    int_var = 'cid'\n",
    "    y_behavior = y['behavior']\n",
    "    y_behavior = [itos_speed[int(i)] for i in y_behavior]\n",
    "    print(f\"y_behavior: {y_behavior}\")\n",
    "    true_behavior = print(df_behavior[(df_behavior[t_var] > round(float(x[int_var][0]), 2) - tdiff) & (df_behavior[t_var] <= round(float(x[int_var][1]), 2)) & (df_behavior['Trial'] == int(x['trial']))])\n",
    "    print(f\"true_behavior: {true_behavior}\")\n",
    "\n",
    "tdiff = 0\n",
    "t_var = 'Time' # 'Interval'\n",
    "int_var = 'cid'\n",
    "# df[(df[t_var] >= iv - tdiff) & (df[t_var] <= iv + (window + tdiff)) & (df['Trial'] == int(x['trial']))]\n",
    "# df[(df[t_var] >= float(x[int_var][0]) - tdiff) & (df[t_var] <= float(x[int_var][1] + tdiff)) & (df['Trial'] == int(x['trial']))]\n",
    "df[(df[t_var] > float(x[int_var][0]) - tdiff) & (df[t_var] <= float(x['cid'][1] + tdiff)) & (df['Trial'] == int(x['trial']))]\n",
    "\n",
    "t_var = 'Time' # 'Interval'\n",
    "int_var = 'cid'\n",
    "df[(df[t_var] > round(float(x[int_var][0]), 2) - tdiff) & (df[t_var] <= round(float(x[int_var][1]), 2)) & (df['Trial'] == int(x['trial']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
