{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import set_seed\n",
    "\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from neuroformer.utils import print_full\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from neuroformer.visualize import *\n",
    "set_plot_params()\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "\n",
    "from neuroformer.model_neuroformer import GPT, GPTConfig, neuralGPTConfig\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "\n",
    "\n",
    "import json\n",
    "# for i in {1..10}; do python3 -m gather_atts.py; done\n",
    "\n",
    "from attention.LRN_attention import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.prepare_data import load_LRN\n",
    "\n",
    "df, stimulus = load_LRN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "n_seed = 25\n",
    "set_seed(n_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config files\n",
    "\n",
    "import yaml\n",
    "\n",
    "base_path = \"./models/tensorboard/LRN/channel/2_window:0.5_prev:19.5/sparse_f:None_id:None/w:0.5_wp:19.5\"\n",
    "\n",
    "with open(os.path.join(base_path, 'mconf.yaml'), 'r') as stream:\n",
    "    mconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'tconf.yaml'), 'r') as stream:\n",
    "    tconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'dconf.yaml'), 'r') as stream:\n",
    "    dconf = yaml.full_load(stream)\n",
    "\n",
    "import omegaconf\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# open yaml as omegacong\n",
    "mconf = OmegaConf.create(mconf)\n",
    "tconf = OmegaConf.create(tconf)\n",
    "dconf = OmegaConf.create(dconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(parent_path + \"code/data/OneCombo3/Combo3_all_stim.csv\")\n",
    "w_mult = 3\n",
    "frame_window = dconf.frame_window\n",
    "window = dconf.window\n",
    "window_prev = dconf.window_prev\n",
    "dt = dconf.dt\n",
    "dt_frames = dconf.dt_frames\n",
    "# p_window = window / (window + window_prev)\n",
    "# intervals = np.load(os.path.join(base_path, \"intervals.npy\"))\n",
    "intervals = None\n",
    "\n",
    "\n",
    "from SpikeVidUtils import make_intervals\n",
    "\n",
    "df['real_interval'] = make_intervals(df, dt)\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['Interval_2'] = make_intervals(df, window_prev)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# n_dt = sorted((df['Interval_dt'].unique()).round(2)) \n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1  # add first / last interval for SOS / EOS'\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)] + ['EOS'] + ['PAD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.68422611538335\n"
     ]
    }
   ],
   "source": [
    "int_trials = df.groupby(['Interval', 'Trial']).size()\n",
    "print(int_trials.mean())\n",
    "# df.groupby(['Interval', 'Trial']).agg(['nunique'])model_path\n",
    "# var_group = 'Interval_2'\n",
    "# n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "# df.groupby(['Interval_2', 'Trial']).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "## resnet3d feats\n",
    "n_embd = mconf.n_embd\n",
    "frame_feats = torch.tensor(stimulus, dtype=torch.float32).transpose(1, 0)\n",
    "frame_block_size = mconf.frame_block_size  # math.ceil(frame_feats.shape[-1] * frame_window)\n",
    "n_embd_frames = mconf.n_embd_frames\n",
    "\n",
    "prev_id_block_size = mconf.prev_id_block_size    # math.ceil(frame_block_size * (1 - p_window))\n",
    "id_block_size = mconf.id_block_size           # math.ceil(frame_block_size * p_window)\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
    "frame_memory = dconf.frame_memory   # how many frames back does model see\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "# translate neural embeddings to separate them from ID embeddings\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "trial_tokens = [f\"Trial {n}\" for n in df['Trial'].unique()]\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_split = 0.8\n",
    "train_trials = sorted(df['Trial'].unique())[:int(len(df['Trial'].unique()) * r_split)]\n",
    "train_data = df[df['Trial'].isin(train_trials)]\n",
    "test_data = df[~df['Trial'].isin(train_trials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 705418 Neurons: 1003\n",
      "id block size: 150\n",
      "frames: 200, id: 150\n",
      "Length: 177367 Neurons: 1003\n",
      "id block size: 150\n",
      "frames: 200, id: 150\n",
      "train: 58888, test: 14725\n"
     ]
    }
   ],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "# train_dat1aset = spikeTimeData(spikes, block_size, dt, stoi, itos)\n",
    "\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=intervals)\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                 window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                                 pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                 dt_frames=dt_frames, intervals=intervals)\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import get_class_weights\n",
    "# class_weights = get_class_weights(train_dataset, stoi, stoi_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2023 08:03:50 - INFO - model_neuroformer_LRN -   number of parameters: 2.603624e+07\n"
     ]
    }
   ],
   "source": [
    "from model_neuroformer_LRN import GPT, GPTConfig\n",
    "# initialize config class and model (holds hyperparameters)\n",
    "   \n",
    "conv_layer = False\n",
    "model_conf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                        id_vocab_size=train_dataset.id_population_size,\n",
    "                        frame_block_size=frame_block_size,\n",
    "                        id_block_size=id_block_size,  # frame_block_size\n",
    "                        prev_id_block_size=prev_id_block_size,\n",
    "                        sparse_mask=False, p_sparse=0.25, \n",
    "                        sparse_topk_frame=None, sparse_topk_id=None, sparse_topk_prev_id=None,\n",
    "                        n_dt=len(n_dt),\n",
    "                        data_size=train_dataset.size,\n",
    "                        class_weights=None,\n",
    "                        pretrain=False,\n",
    "                        n_state_layers=mconf.n_state_layers, n_state_history_layers=mconf.n_state_history_layers,\n",
    "                        n_stimulus_layers=mconf.n_stimulus_layers, self_att_layers=mconf.self_att_layers,\n",
    "                        n_head=mconf.n_head, n_embd=mconf.n_embd, \n",
    "                        contrastive=True, clip_emb=1024, clip_temp=0.5,\n",
    "                        temp_emb=True, pos_emb=False,\n",
    "                        id_drop=0.35, im_drop=0.35,\n",
    "                        window=window, window_prev=window_prev, frame_window=frame_window, dt=dt,\n",
    "                        n_embd_frames=n_embd_frames, dataset=None,\n",
    "                        ignore_index_id=stoi['PAD'], ignore_index_dt=stoi_dt['PAD'])  # 0.35\n",
    "\n",
    "for k, v in model_conf.__dict__.items():\n",
    "    if not hasattr(mconf, k):\n",
    "        print(f\"k: {k}, v: {v}\")\n",
    "        setattr(mconf, k, v)\n",
    "\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)\n",
    "max_epochs = 300\n",
    "batch_size = round((14))\n",
    "shuffle = True\n",
    "\n",
    "weighted = True if mconf.class_weights is not None else False\n",
    "title =  f'window:{window}_prev:{window_prev}_smooth'\n",
    "model_path = f\"\"\"./models/tensorboard/LRN/ignore_index/2_{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\n",
    "\n",
    "# model_path = \"/data5/antonis/neuroformer/models/tensorboard/LRN/channel/window:0.5_prev:19.5_smooth/sparse_f:None_id:None/w:0.5_wp:19.5/6_Cont:True_window:0.5_f_window:20_df:0.1_blocksize:150_conv_False_shuffle:True_batch:12_sparse_(None_None)_blocksz1150_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_197_max0.1_(8, 8, 8)_8_256.pt\"\n",
    "# if os.path.exists(model_path):\n",
    "#     print(f\"Loading model from {model_path}\")\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "# else:\n",
    "#     print(f\"Model not found at {model_path}\")\n",
    "#     raise FileNotFoundError\n",
    "\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=1e-4, \n",
    "                    num_workers=4, lr_decay=False, patience=3, warmup_tokens=8e7, \n",
    "                    decay_weights=True, weight_decay=0.2, shuffle=shuffle,\n",
    "                    final_tokens=len(train_dataset)*(id_block_size) * (max_epochs),\n",
    "                    clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                    dataset='higher_order', mode='predict',\n",
    "                    block_size=train_dataset.block_size,\n",
    "                    id_block_size=train_dataset.id_block_size,\n",
    "                    show_grads=False, plot_raster=False,\n",
    "                    ckpt_path=model_path, no_pbar=False, \n",
    "                    dist=False, save_every=1000)\n",
    "\n",
    "# trainer = Trainer(model, train_dataset, test_dataset, tconf, mconf)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=2, shuffle=shuffle, num_workers=4, pin_memory=True)\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from 6_Cont:False_window:0.5_f_window:20_df:0.1_blocksize:150_conv_False_shuffle:True_batch:32_sparse_(None_None)_blocksz1150_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_197_max0.1_(8, 8, 8)_8_256.pt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "RUN SIMULATION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from utils import *\n",
    "from IPython.utils import io\n",
    "# top_p=0.25, top_p_t=0.9, temp=2.\n",
    "\n",
    "model_weights = glob.glob(os.path.join(base_path, '**/**.pt'), recursive=True)\n",
    "model_weights = sorted(model_weights, key=os.path.getmtime, reverse=True)\n",
    "assert len(model_weights) > 0, \"No model weights found\"\n",
    "\n",
    "\n",
    "if model_path in model_weights:\n",
    "    load_weights = model_path\n",
    "else:\n",
    "    print(f'Loading weights from {os.path.basename(model_weights[0])}')\n",
    "    load_weights = model_weights[0]\n",
    "\n",
    "# load_weights = \"./models/tensorboard/LRN/final/p_reduce_20_window:0.5_prev:19.5/sparse_f:None_id:None/w:0.5_wp:19.5/6_Cont:False_window:0.5_f_window:20_df:0.1_blocksize:150_conv_False_shuffle:True_batch:58_sparse_(None_None)_blocksz1150_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_197_max0.1_(4, 4, 4)_1_256.pt\"\n",
    "model.load_state_dict(torch.load(load_weights, map_location=torch.device('cpu')))\n",
    "\n",
    "trials = test_data['Trial'].unique()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 881109 Neurons: 1003\n",
      "id block size: 150\n",
      "frames: 200, id: 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_matrix = np.zeros((len(stoi.keys()), 1000))\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "\n",
    "att_data = df[df['Trial'].isin([i for i in range(0, 500)])]\n",
    "att_dataset = SpikeTimeVidData2(att_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=intervals)\n",
    "loader = DataLoader(att_dataset, batch_size=3, shuffle=True, num_workers=1)\n",
    "# model = model.to(\"cuda\")\n",
    "model.load_state_dict(torch.load(load_weights, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, = model(x, y)\n",
    "\n",
    "attentions = get_atts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_KEY = \"neural_stimulus_block\"\n",
    "\n",
    "attentions['neural_state_block_0'].shape\n",
    "\n",
    "agg_atts = cat_atts(attentions, LAYER_KEY)\n",
    "agg_atts = stack_atts(attentions, LAYER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 8, 150, 1000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_atts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import set_plot_white\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "set_plot_white()\n",
    "\n",
    "GRAD_COND = False\n",
    "LAYER_KEY = \"neural_stimulus_block\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "neurons = []\n",
    "att_scores = []\n",
    "att_scores_grad = [] \n",
    "\n",
    "# loader = DataLoader(att_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "# iterable = iter(loader)\n",
    "\n",
    "# last_layer = \"neural_stimulus_block_{n}\".format(n=mconf.n_stimulus_layers-1)\n",
    "# n_neurons = 10\n",
    "# ncols = 5\n",
    "# nrows = n_neurons // ncols + 1\n",
    "\n",
    "# plt.figure(figsize=(40, (20) * (n_neurons // 20)))\n",
    "\n",
    "# model.eval()\n",
    "# model.to(\"cpu\")\n",
    "# n_idx = 3\n",
    "# counter = 0\n",
    "\n",
    "# while counter < n_neurons:\n",
    "#     # print(f\"Counter: {counter} / {n_neurons}\")\n",
    "#     x, y = next(iterable)\n",
    "\n",
    "#     try:\n",
    "#         neuron_x = int(itos[int(x['id'].flatten()[n_idx])])\n",
    "#         neuron_y = int(itos[int(y['id'].flatten()[n_idx])])\n",
    "#         counter += 1\n",
    "#         logging.info(f\"Counter: {counter} / {n_neurons}\")\n",
    "#         neurons.append({\"x\": neuron_x, \"y\": neuron_y})\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "#     model.zero_grad()\n",
    "#     with torch.set_grad_enabled(GRAD_COND):\n",
    "#         _, _, _, = model(x, y)\n",
    "#     attentions = get_atts(model)\n",
    "#     att_scores.append(cat_atts(attentions, LAYER_KEY))\n",
    "\n",
    "#     # if GRAD_COND:\n",
    "#     gradients = get_grads(model)\n",
    "#     attentions = gradcam(attentions, gradients)\n",
    "#     att_scores_grad.append(cat_atts(attentions, LAYER_KEY))\n",
    "\n",
    "#     att_vis = torch.cat([attentions[k] for k in attentions.keys() if k.startswith(LAYER_KEY)])\n",
    "    # att_vis = attentions[last_layer].min(dim=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/04/2023 08:04:10 - INFO - root -   Counter: 1 / 500\n",
      "03/04/2023 08:04:20 - INFO - root -   Counter: 2 / 500\n",
      "03/04/2023 08:04:30 - INFO - root -   Counter: 3 / 500\n",
      "03/04/2023 08:04:35 - INFO - root -   Counter: 4 / 500\n",
      "03/04/2023 08:04:40 - INFO - root -   Counter: 5 / 500\n",
      "03/04/2023 08:04:40 - INFO - root -   Counter: 6 / 500\n",
      "03/04/2023 08:04:42 - INFO - root -   Counter: 7 / 500\n",
      "03/04/2023 08:04:42 - INFO - root -   Counter: 8 / 500\n",
      "03/04/2023 08:04:43 - INFO - root -   Counter: 9 / 500\n",
      "03/04/2023 08:04:43 - INFO - root -   Counter: 10 / 500\n",
      "03/04/2023 08:04:44 - INFO - root -   Counter: 11 / 500\n",
      "03/04/2023 08:04:44 - INFO - root -   Counter: 12 / 500\n",
      "03/04/2023 08:04:44 - INFO - root -   Counter: 13 / 500\n",
      "03/04/2023 08:04:44 - INFO - root -   Counter: 14 / 500\n",
      "03/04/2023 08:04:45 - INFO - root -   Counter: 15 / 500\n",
      "03/04/2023 08:04:45 - INFO - root -   Counter: 16 / 500\n",
      "03/04/2023 08:04:45 - INFO - root -   Counter: 17 / 500\n",
      "03/04/2023 08:04:45 - INFO - root -   Counter: 18 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 19 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 20 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 21 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 22 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 23 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 24 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 25 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 26 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 27 / 500\n",
      "03/04/2023 08:04:46 - INFO - root -   Counter: 28 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 29 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 30 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 31 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 32 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 33 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 34 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 35 / 500\n",
      "03/04/2023 08:04:47 - INFO - root -   Counter: 36 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 37 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 38 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 39 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 40 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 41 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 42 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 43 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 44 / 500\n",
      "03/04/2023 08:04:48 - INFO - root -   Counter: 45 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 46 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 47 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 48 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 49 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 50 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 51 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 52 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 53 / 500\n",
      "03/04/2023 08:04:49 - INFO - root -   Counter: 54 / 500\n",
      "03/04/2023 08:04:50 - INFO - root -   Counter: 55 / 500\n",
      "03/04/2023 08:04:50 - INFO - root -   Counter: 56 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 57 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 58 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 59 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 60 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 61 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 62 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 63 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 64 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 65 / 500\n",
      "03/04/2023 08:04:51 - INFO - root -   Counter: 66 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 67 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 68 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 69 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 70 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 71 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 72 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 73 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 74 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 75 / 500\n",
      "03/04/2023 08:04:52 - INFO - root -   Counter: 76 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 77 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 78 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 79 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 80 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 81 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 82 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 83 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 84 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 85 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 86 / 500\n",
      "03/04/2023 08:04:53 - INFO - root -   Counter: 87 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 88 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 89 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 90 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 91 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 92 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 93 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 94 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 95 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 96 / 500\n",
      "03/04/2023 08:04:54 - INFO - root -   Counter: 97 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 98 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 99 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 100 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 101 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 102 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 103 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 104 / 500\n",
      "03/04/2023 08:04:55 - INFO - root -   Counter: 105 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 106 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 107 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 108 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 109 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 110 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 111 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 112 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 113 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 114 / 500\n",
      "03/04/2023 08:04:56 - INFO - root -   Counter: 115 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 116 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 117 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 118 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 119 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 120 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 121 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 122 / 500\n",
      "03/04/2023 08:04:57 - INFO - root -   Counter: 123 / 500\n",
      "03/04/2023 08:04:58 - INFO - root -   Counter: 124 / 500\n",
      "03/04/2023 08:04:58 - INFO - root -   Counter: 125 / 500\n",
      "03/04/2023 08:04:58 - INFO - root -   Counter: 126 / 500\n",
      "03/04/2023 08:04:58 - INFO - root -   Counter: 127 / 500\n",
      "03/04/2023 08:04:58 - INFO - root -   Counter: 128 / 500\n",
      "03/04/2023 08:04:59 - INFO - root -   Counter: 129 / 500\n",
      "03/04/2023 08:04:59 - INFO - root -   Counter: 130 / 500\n",
      "03/04/2023 08:04:59 - INFO - root -   Counter: 131 / 500\n",
      "03/04/2023 08:04:59 - INFO - root -   Counter: 132 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 133 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 134 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 135 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 136 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 137 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 138 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 139 / 500\n",
      "03/04/2023 08:05:00 - INFO - root -   Counter: 140 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 141 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 142 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 143 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 144 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 145 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 146 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 147 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 148 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 149 / 500\n",
      "03/04/2023 08:05:01 - INFO - root -   Counter: 150 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 151 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 152 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 153 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 154 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 155 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 156 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 157 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 158 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 159 / 500\n",
      "03/04/2023 08:05:02 - INFO - root -   Counter: 160 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 161 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 162 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 163 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 164 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 165 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 166 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 167 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 168 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 169 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 170 / 500\n",
      "03/04/2023 08:05:03 - INFO - root -   Counter: 171 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 172 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 173 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 174 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 175 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 176 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 177 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 178 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 179 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 180 / 500\n",
      "03/04/2023 08:05:04 - INFO - root -   Counter: 181 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 182 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 183 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 184 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 185 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 186 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 187 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 188 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 189 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 190 / 500\n",
      "03/04/2023 08:05:05 - INFO - root -   Counter: 191 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 192 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 193 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 194 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 195 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 196 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 197 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 198 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 199 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 200 / 500\n",
      "03/04/2023 08:05:06 - INFO - root -   Counter: 201 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 202 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 203 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 204 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 205 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 206 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 207 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 208 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 209 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 210 / 500\n",
      "03/04/2023 08:05:07 - INFO - root -   Counter: 211 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 212 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 213 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 214 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 215 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 216 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 217 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 218 / 500\n",
      "03/04/2023 08:05:08 - INFO - root -   Counter: 219 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 220 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 221 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 222 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 223 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 224 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 225 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 226 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 227 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 228 / 500\n",
      "03/04/2023 08:05:09 - INFO - root -   Counter: 229 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 230 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 231 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 232 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 233 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 234 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 235 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 236 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 237 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 238 / 500\n",
      "03/04/2023 08:05:10 - INFO - root -   Counter: 239 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 240 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 241 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 242 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 243 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 244 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 245 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 246 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 247 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 248 / 500\n",
      "03/04/2023 08:05:11 - INFO - root -   Counter: 249 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 250 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 251 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 252 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 253 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 254 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 255 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 256 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 257 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 258 / 500\n",
      "03/04/2023 08:05:12 - INFO - root -   Counter: 259 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 260 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 261 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 262 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 263 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 264 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 265 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 266 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 267 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 268 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 269 / 500\n",
      "03/04/2023 08:05:13 - INFO - root -   Counter: 270 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 271 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 272 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 273 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 274 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 275 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 276 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 277 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 278 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 279 / 500\n",
      "03/04/2023 08:05:14 - INFO - root -   Counter: 280 / 500\n",
      "03/04/2023 08:05:15 - INFO - root -   Counter: 281 / 500\n",
      "03/04/2023 08:05:15 - INFO - root -   Counter: 282 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 283 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 284 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 285 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 286 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 287 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 288 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 289 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 290 / 500\n",
      "03/04/2023 08:05:17 - INFO - root -   Counter: 291 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 292 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 293 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 294 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 295 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 296 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 297 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 298 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 299 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 300 / 500\n",
      "03/04/2023 08:05:18 - INFO - root -   Counter: 301 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 302 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 303 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 304 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 305 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 306 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 307 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 308 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 309 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 310 / 500\n",
      "03/04/2023 08:05:19 - INFO - root -   Counter: 311 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 312 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 313 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 314 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 315 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 316 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 317 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 318 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 319 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 320 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 321 / 500\n",
      "03/04/2023 08:05:20 - INFO - root -   Counter: 322 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 323 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 324 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 325 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 326 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 327 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 328 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 329 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 330 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 331 / 500\n",
      "03/04/2023 08:05:21 - INFO - root -   Counter: 332 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 333 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 334 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 335 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 336 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 337 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 338 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 339 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 340 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 341 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 342 / 500\n",
      "03/04/2023 08:05:22 - INFO - root -   Counter: 343 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 344 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 345 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 346 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 347 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 348 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 349 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 350 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 351 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 352 / 500\n",
      "03/04/2023 08:05:23 - INFO - root -   Counter: 353 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 354 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 355 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 356 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 357 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 358 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 359 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 360 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 361 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 362 / 500\n",
      "03/04/2023 08:05:24 - INFO - root -   Counter: 363 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 364 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 365 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 366 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 367 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 368 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 369 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 370 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 371 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 372 / 500\n",
      "03/04/2023 08:05:25 - INFO - root -   Counter: 373 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 374 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 375 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 376 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 377 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 378 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 379 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 380 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 381 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 382 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 383 / 500\n",
      "03/04/2023 08:05:26 - INFO - root -   Counter: 384 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 385 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 386 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 387 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 388 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 389 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 390 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 391 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 392 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 393 / 500\n",
      "03/04/2023 08:05:27 - INFO - root -   Counter: 394 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 395 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 396 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 397 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 398 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 399 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 400 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 401 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 402 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 403 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 404 / 500\n",
      "03/04/2023 08:05:28 - INFO - root -   Counter: 405 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 406 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 407 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 408 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 409 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 410 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 411 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 412 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 413 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 414 / 500\n",
      "03/04/2023 08:05:29 - INFO - root -   Counter: 415 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 416 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 417 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 418 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 419 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 420 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 421 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 422 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 423 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 424 / 500\n",
      "03/04/2023 08:05:30 - INFO - root -   Counter: 425 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 426 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 427 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 428 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 429 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 430 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 431 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 432 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 433 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 434 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 435 / 500\n",
      "03/04/2023 08:05:31 - INFO - root -   Counter: 436 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 437 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 438 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 439 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 440 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 441 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 442 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 443 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 444 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 445 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 446 / 500\n",
      "03/04/2023 08:05:32 - INFO - root -   Counter: 447 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 448 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 449 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 450 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 451 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 452 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 453 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 454 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 455 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 456 / 500\n",
      "03/04/2023 08:05:33 - INFO - root -   Counter: 457 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 458 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 459 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 460 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 461 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 462 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 463 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 464 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 465 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 466 / 500\n",
      "03/04/2023 08:05:34 - INFO - root -   Counter: 467 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 468 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 469 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 470 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 471 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 472 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 473 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 474 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 475 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 476 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 477 / 500\n",
      "03/04/2023 08:05:35 - INFO - root -   Counter: 478 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 479 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 480 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 481 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 482 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 483 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 484 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 485 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 486 / 500\n",
      "03/04/2023 08:05:36 - INFO - root -   Counter: 487 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 488 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 489 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 490 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 491 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 492 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 493 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 494 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 495 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 496 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 497 / 500\n",
      "03/04/2023 08:05:37 - INFO - root -   Counter: 498 / 500\n",
      "03/04/2023 08:05:38 - INFO - root -   Counter: 499 / 500\n",
      "03/04/2023 08:05:38 - INFO - root -   Counter: 500 / 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4000x50000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neurons = []\n",
    "att_scores = []\n",
    "att_scores_grad = [] \n",
    "\n",
    "loader = DataLoader(att_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "iterable = iter(loader)\n",
    "\n",
    "last_layer = \"neural_stimulus_block_{n}\".format(n=mconf.n_stimulus_layers-1)\n",
    "n_neurons = 500\n",
    "ncols = 5\n",
    "nrows = n_neurons // ncols + 1\n",
    "\n",
    "plt.figure(figsize=(40, (20) * (n_neurons // 20)))\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "n_idx = 3\n",
    "counter = 0\n",
    "\n",
    "\n",
    "while counter < n_neurons:\n",
    "    # print(f\"Counter: {counter} / {n_neurons}\")\n",
    "    x, y = next(iterable)\n",
    "\n",
    "    try:\n",
    "        neuron_x = int(itos[int(x['id'].flatten()[n_idx])])\n",
    "        neuron_y = int(itos[int(y['id'].flatten()[n_idx])])\n",
    "        counter += 1\n",
    "        logging.info(f\"Counter: {counter} / {n_neurons}\")\n",
    "        neurons.append({\"x\": neuron_x, \"y\": neuron_y})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    model.zero_grad()\n",
    "    with torch.set_grad_enabled(GRAD_COND):\n",
    "        _, _, _, = model(x, y)\n",
    "    attentions = get_atts(model)\n",
    "    att_scores_att = cat_atts(attentions, LAYER_KEY)[:, :, n_idx].unsqueeze(-3)\n",
    "    att_scores.append(att_scores_att)\n",
    "\n",
    "    # if GRAD_COND:\n",
    "    gradients = get_grads(model)\n",
    "    attentions = gradcam(attentions, gradients)\n",
    "    att_scores_grad.append(cat_atts(attentions, LAYER_KEY))\n",
    "\n",
    "    att_vis = torch.cat([attentions[k] for k in attentions.keys() if k.startswith(LAYER_KEY)])\n",
    "    att_vis = attentions[last_layer].min(dim=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_att_dict_state = collections.defaultdict(list)\n",
    "neuron_att_dict_idx = collections.defaultdict(list)\n",
    "\n",
    "for idx, row in enumerate(neurons):\n",
    "    xid = row['x']\n",
    "    attention = att_scores[idx]\n",
    "    neuron_att_dict_state[str(xid)].append(attention)\n",
    "    neuron_att_dict_idx[str(xid)].append(attention)\n",
    "\n",
    "for key in neuron_att_dict_state.keys():\n",
    "    neuron_att_dict_state[key] = torch.stack(neuron_att_dict_state[key])\n",
    "for key in neuron_att_dict_idx.keys():\n",
    "    neuron_att_dict_idx[key] = torch.stack(neuron_att_dict_idx[key])\n",
    "\n",
    "# save neuron_att_dict_state and idx as .mat files\n",
    "import scipy.io as sio\n",
    "\n",
    "save_path = \"./a_yiyi\"\n",
    "\n",
    "sio.savemat(os.path.join(save_path, 'neuron_att_dict_state'), neuron_att_dict_state)\n",
    "sio.savemat(os.path.join(save_path, 'neuron_att_dict_idx.mat'), neuron_att_dict_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x7f69c896cca0> (for post_execute):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "In draw_glyphs_to_bitmap: Could not convert glyph to bitmap (raster overflow; error code 0x62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/pyplot.py:119\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_draw_all_if_interactive\u001b[39m():\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m matplotlib\u001b[39m.\u001b[39mis_interactive():\n\u001b[0;32m--> 119\u001b[0m         draw_all()\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mfor\u001b[39;00m manager \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    131\u001b[0m     \u001b[39mif\u001b[39;00m force \u001b[39mor\u001b[39;00m manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mstale:\n\u001b[0;32m--> 132\u001b[0m         manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_idle()\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   2053\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 2054\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdraw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:405\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[1;32m    403\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[1;32m    404\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 405\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[1;32m    406\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/figure.py:3082\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3086\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/axes/_base.py:3100\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3097\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3098\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3100\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3101\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3103\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/text.py:735\u001b[0m, in \u001b[0;36mText.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    731\u001b[0m             textrenderer\u001b[39m.\u001b[39mdraw_tex(gc, x, y, clean_line,\n\u001b[1;32m    732\u001b[0m                                   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fontproperties, angle,\n\u001b[1;32m    733\u001b[0m                                   mtext\u001b[39m=\u001b[39mmtext)\n\u001b[1;32m    734\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 735\u001b[0m             textrenderer\u001b[39m.\u001b[39;49mdraw_text(gc, x, y, clean_line,\n\u001b[1;32m    736\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties, angle,\n\u001b[1;32m    737\u001b[0m                                    ismath\u001b[39m=\u001b[39;49mismath, mtext\u001b[39m=\u001b[39;49mmtext)\n\u001b[1;32m    739\u001b[0m gc\u001b[39m.\u001b[39mrestore()\n\u001b[1;32m    740\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:208\u001b[0m, in \u001b[0;36mRendererAgg.draw_text\u001b[0;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m# We pass '0' for angle here, since it will be rotated (in raster\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m# space) in the following call to draw_text_image).\u001b[39;00m\n\u001b[1;32m    207\u001b[0m font\u001b[39m.\u001b[39mset_text(s, \u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39mget_hinting_flag())\n\u001b[0;32m--> 208\u001b[0m font\u001b[39m.\u001b[39;49mdraw_glyphs_to_bitmap(\n\u001b[1;32m    209\u001b[0m     antialiased\u001b[39m=\u001b[39;49mmpl\u001b[39m.\u001b[39;49mrcParams[\u001b[39m'\u001b[39;49m\u001b[39mtext.antialiased\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    210\u001b[0m d \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mget_descent() \u001b[39m/\u001b[39m \u001b[39m64.0\u001b[39m\n\u001b[1;32m    211\u001b[0m \u001b[39m# The descent needs to be adjusted for the angle.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: In draw_glyphs_to_bitmap: Could not convert glyph to bitmap (raster overflow; error code 0x62)"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "In draw_glyphs_to_bitmap: Could not convert glyph to bitmap (raster overflow; error code 0x62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backend_bases.py:2338\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2335\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2336\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m-> 2338\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2339\u001b[0m             filename,\n\u001b[1;32m   2340\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2341\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2342\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2343\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39;49m_bbox_inches_restore,\n\u001b[1;32m   2344\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2345\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2346\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backend_bases.py:2204\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     optional_kws \u001b[39m=\u001b[39m {  \u001b[39m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfacecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2202\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbbox_inches_restore\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m   2203\u001b[0m     skip \u001b[39m=\u001b[39m optional_kws \u001b[39m-\u001b[39m {\u001b[39m*\u001b[39minspect\u001b[39m.\u001b[39msignature(meth)\u001b[39m.\u001b[39mparameters}\n\u001b[0;32m-> 2204\u001b[0m     print_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mwraps(meth)(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: meth(\n\u001b[1;32m   2205\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m skip}))\n\u001b[1;32m   2206\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     print_method \u001b[39m=\u001b[39m meth\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:410\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     deprecation_addendum \u001b[39m=\u001b[39m (\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf any parameter follows \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m, they should be passed as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeyword, not positionally.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    403\u001b[0m     warn_deprecated(\n\u001b[1;32m    404\u001b[0m         since,\n\u001b[1;32m    405\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m                  \u001b[39melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    409\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49minner_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minner_kwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:517\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m@_api\u001b[39m\u001b[39m.\u001b[39mdelete_parameter(\u001b[39m\"\u001b[39m\u001b[39m3.5\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_png\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, \u001b[39m*\u001b[39margs,\n\u001b[1;32m    470\u001b[0m               metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pil_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    471\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_print_pil(filename_or_obj, \u001b[39m\"\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m\"\u001b[39;49m, pil_kwargs, metadata)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:463\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_print_pil\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    459\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     FigureCanvasAgg\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    464\u001b[0m     mpl\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimsave(\n\u001b[1;32m    465\u001b[0m         filename_or_obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_rgba(), \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mfmt, origin\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    466\u001b[0m         dpi\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi, metadata\u001b[39m=\u001b[39mmetadata, pil_kwargs\u001b[39m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:405\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[1;32m    403\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[1;32m    404\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 405\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[1;32m    406\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/figure.py:3082\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3086\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/axes/_base.py:3100\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3097\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3098\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3100\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3101\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3103\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/text.py:735\u001b[0m, in \u001b[0;36mText.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    731\u001b[0m             textrenderer\u001b[39m.\u001b[39mdraw_tex(gc, x, y, clean_line,\n\u001b[1;32m    732\u001b[0m                                   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fontproperties, angle,\n\u001b[1;32m    733\u001b[0m                                   mtext\u001b[39m=\u001b[39mmtext)\n\u001b[1;32m    734\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 735\u001b[0m             textrenderer\u001b[39m.\u001b[39;49mdraw_text(gc, x, y, clean_line,\n\u001b[1;32m    736\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties, angle,\n\u001b[1;32m    737\u001b[0m                                    ismath\u001b[39m=\u001b[39;49mismath, mtext\u001b[39m=\u001b[39;49mmtext)\n\u001b[1;32m    739\u001b[0m gc\u001b[39m.\u001b[39mrestore()\n\u001b[1;32m    740\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:208\u001b[0m, in \u001b[0;36mRendererAgg.draw_text\u001b[0;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m# We pass '0' for angle here, since it will be rotated (in raster\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m# space) in the following call to draw_text_image).\u001b[39;00m\n\u001b[1;32m    207\u001b[0m font\u001b[39m.\u001b[39mset_text(s, \u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39mget_hinting_flag())\n\u001b[0;32m--> 208\u001b[0m font\u001b[39m.\u001b[39;49mdraw_glyphs_to_bitmap(\n\u001b[1;32m    209\u001b[0m     antialiased\u001b[39m=\u001b[39;49mmpl\u001b[39m.\u001b[39;49mrcParams[\u001b[39m'\u001b[39;49m\u001b[39mtext.antialiased\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    210\u001b[0m d \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mget_descent() \u001b[39m/\u001b[39m \u001b[39m64.0\u001b[39m\n\u001b[1;32m    211\u001b[0m \u001b[39m# The descent needs to be adjusted for the angle.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: In draw_glyphs_to_bitmap: Could not convert glyph to bitmap (raster overflow; error code 0x62)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4000x2000 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "ncols = 2\n",
    "nrows = n_neurons\n",
    "\n",
    "n_neurons = 10\n",
    "for idx, neuron in enumerate(neuron_att_dict_state.keys()):\n",
    "    plt.subplot(nrows, ncols, idx+1)\n",
    "    av_attention_full = neuron_att_dict_state[neuron].max(-4)[0].min(-3)[0].mean(0).mean(0)\n",
    "    av_attention_mean = av_attention_full.reshape(-1, 1000).mean(0)\n",
    "    plt.subplot(nrows, ncols, idx+1)\n",
    "    plt.plot(av_attention_mean)\n",
    "    plt.axvline(int(neuron), color=\"blue\")\n",
    "    # plt.subplot(nrows, ncols, idx+1+ncols)\n",
    "    # plt.plot(av_attention_full)\n",
    "    \n",
    "    plt.title(f\"{neurons}\")\n",
    "    plt.axis(\"off\")\n",
    "    if idx == n_neurons:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAD_COND = True\n",
    "LAYER_KEY = \"neural_stimulus_block\"\n",
    "\n",
    "lw = 5\n",
    "fs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_vis = torch.cat([attentions[k] for k in attentions.keys() if k.startswith(LAYER_KEY)])\n",
    "att_vis = att_vis.max(0)[0].min(0)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title(f\"x: {neuron_x}, y: {neuron_y}\", fontsize=20)\n",
    "plt.plot(att_vis[n_idx])\n",
    "plt.axvline(x=neuron_x, color='b', label='x', linewidth=lw)\n",
    "plt.axvline(x=neuron_y, color='g', label='y', linewidth=lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.attentionVis import rollout_attentions\n",
    "\n",
    "rollout_atts = [rollout_attentions(att) for att in att_scores]\n",
    "att_types = [att_scores, att_scores_grad, rollout_atts]\n",
    "\n",
    "ncols = len(att_types)\n",
    "nrows = len(neurons) + 1\n",
    "\n",
    "plt.figure(figsize=(20, (70)))\n",
    "title = \"Attention over time\"\n",
    "\n",
    "\n",
    "for n_idx, row in enumerate(neurons):\n",
    "    for n_att, attention in enumerate(att_types):\n",
    "        neuron_x = row['x']\n",
    "        neuron_y = row['y']\n",
    "\n",
    "        # att_vis = torch.cat([attention[k] for k in attention.keys() if k.startswith(LAYER_KEY)])\n",
    "        # att_vis = att_vis[-1].min(0)[0]\n",
    "        attention = attention[n_idx]\n",
    "        if len(attention.shape) == 4:\n",
    "            att_vis = attention.max(0)[0].min(0)[0]\n",
    "            # att_vis = attention[-1].min(0)[0]\n",
    "        else:\n",
    "            att_vis = attention\n",
    "\n",
    "        plt.subplot(nrows, ncols, n_idx * ncols + n_att + 1)\n",
    "        plt.grid()\n",
    "        plt.title(f\"x: {neuron_x}, y: {neuron_y}\", fontsize=20)\n",
    "        plt.plot(att_vis[n_idx])\n",
    "        # plt.axvline(x=neuron_x, color='b', label='x', linewidth=lw)\n",
    "        # plt.axvline(x=neuron_y, color='g', label='y', linewidth=lw)\n",
    "plt.suptitle(title)\n",
    "\n",
    "save_path = os.path.join(base_path,'attention', 'channels')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "n_files = glob.glob(os.path.join(save_path, '*/*.svg'))\n",
    "plt.savefig(os.path.join(save_path, f\"{title}_{len(n_files)}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.attentionVis import rollout_attentions\n",
    "from attention.LRN_attention import reshape_attentions\n",
    "\n",
    "rollout_atts = [rollout_attentions(att) for att in att_scores]\n",
    "att_types = [att_scores, att_scores_grad, rollout_atts]\n",
    "\n",
    "ncols = len(att_types)\n",
    "nrows = len(neurons) + 1\n",
    "\n",
    "plt.figure(figsize=(20, (70)))\n",
    "title = \"Attention averaged over time\"\n",
    "\n",
    "for n_idx, row in enumerate(neurons):\n",
    "    for n_att, attention in enumerate(att_types):\n",
    "        neuron_x = row['x']\n",
    "        neuron_y = row['y']\n",
    "\n",
    "        # att_vis = torch.cat([attention[k] for k in attention.keys() if k.startswith(LAYER_KEY)])\n",
    "        # att_vis = att_vis[-1].min(0)[0]\n",
    "        attention = attention[n_idx]\n",
    "        if len(attention.shape) == 4:\n",
    "            att_vis = attention.max(0)[0].min(0)[0]\n",
    "            # att_vis = attention[-1].min(0)[0]\n",
    "        else:\n",
    "            att_vis = attention\n",
    "        \n",
    "        att_vis = reshape_attentions(att_vis, stimulus)\n",
    "\n",
    "        plt.subplot(nrows, ncols, n_idx * ncols + n_att + 1)\n",
    "        plt.grid()\n",
    "        plt.title(f\"x: {neuron_x}, y: {neuron_y}\", fontsize=20)\n",
    "        plt.plot(att_vis[n_idx])\n",
    "        plt.axvline(x=neuron_x, color='b', label='x', linewidth=lw)\n",
    "        plt.axvline(x=neuron_y, color='g', label='y', linewidth=lw)\n",
    "\n",
    "save_path = os.path.join(base_path,'attention', 'channels')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "n_files = glob.glob(os.path.join(save_path, '*/*.svg'))\n",
    "plt.savefig(os.path.join(save_path, f\"{title}_{len(n_files)}.svg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4878f327e989b61de6701446a3bf7b6f9ae7705c9c90fa2b4cdf5489a55bcfeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
