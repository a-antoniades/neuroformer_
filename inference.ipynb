{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F6CeGQy9xVu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "from torch.utils import data\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "sys.path.append('../')\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as FeatureAlphaDropout\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from scipy import io as scipyio\n",
        "import skimage\n",
        "import skvideo.io\n",
        "\n",
        "import os\n",
        "import glob\n",
        "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
        "sys.path.append(\"neuroformer\")\n",
        "\n",
        "from analysis import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmB0YuTW-zdZ"
      },
      "outputs": [],
      "source": [
        "# set up logging\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIJX2fry_rAH"
      },
      "outputs": [],
      "source": [
        "from utils import set_seed\n",
        "set_seed(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# // write a function that find the explicit path of a file sing pathlib\n",
        "def get_path(path):\n",
        "    return str(Path(path).resolve())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U-Mr5sF_s-3",
        "outputId": "bbb0deae-6896-4c65-c0c4-6470bdd6ca46"
      },
      "outputs": [],
      "source": [
        "# R3D: (3 x T x H x W)\n",
        "\n",
        "from SpikeVidUtils import image_dataset\n",
        "\n",
        "stim_folder = \"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/OneCombo3/stimuli\"\n",
        "im_path = ['/Combined Stimuli 3-grating.tif',\n",
        "           '/Combined Stimuli 3-Movie2.tif',\n",
        "           '/Combined Stimuli 3-Movie3.tif']\n",
        "\n",
        "train_path = \"/content/stimulus\"\n",
        "train_path = \"/Users/antonis/Downloads/OneCombo3/stimuli\"\n",
        "video_stack = [skimage.io.imread(stim_folder + vid) for vid in im_path]\n",
        "print(glob.glob(train_path + '/*.tif'))\n",
        "video_stack = np.concatenate(video_stack, axis=0)\n",
        "\n",
        "# video_stack = skimage.io.imread(\"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/OneCombo3/stimuli/Combined Stimuli 3-grating.tif\")\n",
        "# video_stack = image_dataset(video_stack)\n",
        "# video_stack = video_stack[::3]  # convert from 60 to 20 fps\n",
        "# video_stack = video_stack.view(1, video_stack.shape[0], video_stack.shape[1], video_stack.shape[2], video_stack.shape[3])\n",
        "\n",
        "video_stack = image_dataset(video_stack)\n",
        "video_stack = video_stack[::3]  # convert from 60 to 20 fps\n",
        "video_stack = video_stack.view(3, video_stack.shape[0] // 3, video_stack.shape[1], video_stack.shape[2], video_stack.shape[3])\n",
        "# video_stack = video_stack.transpose(-1, -2)\n",
        "\n",
        "# rearrange(video_stack[0, 0:2].transpose(0,1), 'c t (h p1) (w p2) -> (t h w) (p1 p2 c)', p1=16, p2=16).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge_QNMrICWR7",
        "outputId": "40e9b4a3-c870-4eeb-8fff-82355db2f4b4"
      },
      "outputs": [],
      "source": [
        "video_stack.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "UWOkHke3_y4A",
        "outputId": "dcd40d85-e4c6-4e5b-b31b-68fcd419eafd"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(video_stack[0, 1, 0].permute(0, 1))\n",
        "plt.figure()\n",
        "plt.imshow(video_stack[1, 1, 0].permute(0, 1))\n",
        "plt.figure()\n",
        "plt.imshow(video_stack[2, 1, 0].permute(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRFtpwOs_0W4"
      },
      "outputs": [],
      "source": [
        "# spike_path = \"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/SImNew3D/neural/NatureMoviePart1-A\" # \"code/data/SImIm/simNeu_3D_WithNorm__Combo3.mat\" \n",
        "from SpikeVidUtils import trial_df_combo3\n",
        "\n",
        "spike_data = scipyio.loadmat(\"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/OneCombo3/spiketrain.mat\")\n",
        "spike_data = np.squeeze(spike_data['spiketrain'].T, axis=-1)\n",
        "spike_data = [trial_df_combo3(spike_data, n_stim) for n_stim in range(3)]\n",
        "spike_data = pd.concat(spike_data, axis=0)\n",
        "\n",
        "spike_data['Trial'] = spike_data['Trial'] + 1\n",
        "spike_data['Time'] = spike_data['Time'] * 0.0751\n",
        "spike_data = spike_data[(spike_data['Time'] > 0) & (spike_data['Time'] <= 32)]\n",
        "\n",
        "# vid_duration = [len(vid) * 1/20 for vid in vid_list]\n",
        "\n",
        "df = spike_data\n",
        "del spike_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR7Vs-Pn_3oo"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(parent_path + \"code/data/OneCombo3/Combo3_all_stim.csv\")\n",
        "window = 0.5\n",
        "dt = 0.05\n",
        "\n",
        "from SpikeVidUtils import make_intervals\n",
        "\n",
        "df['Interval'] = make_intervals(df, window)\n",
        "df['Interval_dt'] = make_intervals(df, dt)\n",
        "df['Interval_dt'] = (df['Interval_dt'] - df['Interval'] + window).round(3)\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwyX2t-z_44J"
      },
      "outputs": [],
      "source": [
        "# n_dt = sorted((df['Interval_dt'].unique()).round(2)) \n",
        "dt_range = int(window / dt) + 1  # add first / last interval for SOS / EOS'\n",
        "n_dt = [round(dt * n, 2) for n in range(dt_range)]\n",
        "df['Time'] = df['Time'].round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgNYdciA_5xo",
        "outputId": "9be97414-3f42-49e8-ebbf-b887cf2d221b"
      },
      "outputs": [],
      "source": [
        "# df.groupby(['Interval', 'Trial']).size().plot.bar()\n",
        "# df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
        "df.groupby(['Interval', 'Trial']).size().nlargest(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd3P4ASE_7gy",
        "outputId": "3f834a76-ced6-4023-bd1b-8a420f7d0e2d"
      },
      "outputs": [],
      "source": [
        "from SpikeVidUtils import SpikeTimeVidDataor/stimulus/vq-vae_code_feats-24-05-4x4x4.pt\").numpy() + 2\n",
        "# frame_feats = torch.load(parent_path + \"code/data/SImNew3D/stimulus/vq-vae_embed_feats-24-05-4x4x4.pt\").numpy()\n",
        "# frame_block_size = frames.shape[-1] - 1\n",
        "\n",
        "## resnet3d feats\n",
        "frame_feats = video_stack.transpose(1, 2)\n",
        "\n",
        "frame_block_size = int((20 * 64 * 112) / (8 * 8))\n",
        "# frame_block_size = 560\n",
        "prev_id_block_size = 52\n",
        "id_block_size = 52   # 95\n",
        "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
        "frame_memory = 20   # how many frames back does model see\n",
        "window = window\n",
        "\n",
        "neurons = sorted(list(set(df['ID'])))\n",
        "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
        "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
        "\n",
        "# translate neural embeddings to separate them from ID embeddings\n",
        "# frames = frames + [*id_stoi.keys()][-1] \n",
        "neurons = [i for i in range(df['ID'].min(), df['ID'].max() + 1)]\n",
        "# pixels = sorted(np.unique(frames).tolist())\n",
        "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
        "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
        "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
        "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
        "itos_dt = { i:ch for i,ch in enumerate(n_dt) }\n",
        "max(list(itos_dt.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ZJuUWTDpwk"
      },
      "outputs": [],
      "source": [
        "# train_len = round(len(df)*(4/5))\n",
        "# test_len = round(len(df) - train_len)\n",
        "\n",
        "# train_data = df[:train_len]\n",
        "# test_data = df[train_len:train_len + test_len].reset_index().drop(['index'], axis=1)\n",
        "\n",
        "n = []\n",
        "for n_stim in range(df['Trial'].max() // 20):\n",
        "    n_trial = [3, 15, 5, 18]\n",
        "    for n_trial in n_trial:\n",
        "        trial = (n_stim + 1) * 20 - n_trial\n",
        "        n.append(trial)\n",
        "train_data = df[~df['Trial'].isin(n)].reset_index(drop=True)\n",
        "test_data = df[df['Trial'].isin(n)].reset_index(drop=True)\n",
        "small_data = df[df['Trial'].isin([5])].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luwjZJiBDuJV",
        "outputId": "46a1af29-90f1-4d64-c785-f35316d319cd"
      },
      "outputs": [],
      "source": [
        "from SpikeVidUtils import SpikeTimeVidData2\n",
        "\n",
        "# train_dat1aset = spikeTimeData(spikes, block_size, dt, stoi, itos)\n",
        "\n",
        "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "# dataset = SpikeTimeVidData(df, frames, frame_feats, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos)\n",
        "# single_batch = SpikeTimeVidData(df[df['Trial'].isin([5])], None, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats)\n",
        "small_dataset = SpikeTimeVidData2(small_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "\n",
        "\n",
        "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYyJLHClVS5M"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(dataset):\n",
        "  dt = []\n",
        "  id = []\n",
        "  for x, y in dataset:\n",
        "    id.extend([stoi['SOS']] + y['id'][:len(y['id']) - x['pad']].flatten().tolist() + [stoi['PAD']])    # *x['pad']) # -1 in pad to include PAD token\n",
        "    dt.extend([stoi_dt[0]] + y['dt'][:len(y['dt']) - x['pad']].flatten().tolist() +  [dataset.dt_max])   #*x['pad']) # -1 in pad to include PAD token\n",
        "\n",
        "  id = pd.DataFrame(id)\n",
        "  dt = pd.DataFrame(dt)\n",
        "\n",
        "  id_freq = id.groupby([0]).size()\n",
        "  dt_freq = dt.groupby([0]).size()\n",
        "\n",
        "  id_ones = np.ones(dataset.id_population_size)\n",
        "  dt_ones = np.ones(dataset.dt_population_size)\n",
        "\n",
        "  id_ones[id_freq.index] = (1 / id_freq) * id_freq.max() / id_freq.max()\n",
        "  dt_ones[dt_freq.index] = (1 / dt_freq) * dt_freq.max() / dt_freq.max()\n",
        "  \n",
        "  class_freq = dict()\n",
        "  class_freq['id'] = torch.tensor(id_ones, dtype=torch.float32)\n",
        "  class_freq['dt'] = torch.tensor(dt_ones, dtype=torch.float32)\n",
        "  \n",
        "  return class_freq \n",
        "\n",
        "class_weights = get_class_weights(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTLKWWrqDyDd",
        "outputId": "7f7fdeff-145f-4412-ed24-6662db6ff997"
      },
      "outputs": [],
      "source": [
        "from model_neuroformer import GPT, GPTConfig, neuralGPTConfig, Decoder\n",
        "# initialize config class and model (holds hyperparameters)\n",
        "mconf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
        "                        id_vocab_size=train_dataset.id_population_size,\n",
        "                        frame_block_size=frame_block_size,\n",
        "                        id_block_size=id_block_size,  # frame_block_size\n",
        "                        prev_id_block_size=prev_id_block_size,\n",
        "                        sparse_mask=False, p_sparse=0.25, sparse_topk_frame=50, sparse_topk_id=id_block_size // 5,\n",
        "                        n_dt=len(n_dt),\n",
        "                        data_size=train_dataset.size,\n",
        "                        class_weights=class_weights,\n",
        "                        pretrain=False,\n",
        "                        n_state_layers=4, n_state_history_layers=4, n_stimulus_layers=8,\n",
        "                        n_layer=10, n_head=4, n_embd=64,\n",
        "                        temp_emb=True, pos_emb=True,\n",
        "                        id_drop=0.2, im_drop=0.2)\n",
        "model = GPT(mconf)\n",
        "# model.load_state_dict(torch.load(\"/Users/antonis/Downloads/model_shuffle_perceiver_2.0_dt_0.05_eos_8_8_256.pt\", map_location='cpu'))\n",
        "# model.load_state_dict(torch.load(\"/home/antonis/projects/slab/git/neuroformer/models/tensorboard/sparse_neuroformer_nopad_unweighted:dt_:True_perceiver_1.0_0.05_(4, 4, 8)_4_64.pt\", map_location='cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H0AqcZLqxBH",
        "outputId": "2ce22b00-a8b7-4b49-b846-42066ade9266"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_8_4_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_shuffle_8_4_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_81_4_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_83_4_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_dt_8_4_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_dt_8_8_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_dt_eos_8_8_256.pt\"))\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_2.0_dt_eos_8_8_256.pt\"))\n",
        "# model.load_state_dict(torch.load(f\"/content/drive/MyDrive/slab/models/OneCombo3/model_perceiver_2.0_dt:{dt}_eos_{mconf.n_layer}_{mconf.n_head}_{mconf.n_embd}.pt\"))\n",
        "# model.load_state_dict(torch.load(f\"/content/drive/MyDrive/slab/models/OneCombo3/model_shuffle_perceiver_2.0_dt:{dt}_eos_{mconf.n_layer}_{mconf.n_head}_{mconf.n_embd}.pt\"))\n",
        "or"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlY4cxbxVrN4"
      },
      "outputs": [],
      "source": [
        "# loader = DataLoader(small_dataset, shuffle=False, pin_memory=False,\n",
        "#                                   batch_size=1, num_workers=1)\n",
        "# x, y = next(iter(loader))\n",
        "# model = model.to('cpu')\n",
        "\n",
        "# preds, features, loss = model(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = DataLoader(test_dataset, shuffle=False, pin_memory=False,\n",
        "                                  batch_size=1, num_workers=1)\n",
        "                                  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXZQ45pGTyMx",
        "outputId": "443d95df-c2f4-404d-a43e-8b430c9ecd0b"
      },
      "outputs": [],
      "source": [
        "\"\"\" Predict using TEST dataset \"\"\"\n",
        "\n",
        "from utils import predict_raster, predict_raster_resnet, predict_raster_enc_dec, predict_raster_recursive, predict_beam_search, predict_raster_recursive_time, predict_raster_recursive_time_auto, predict_beam_search_time, predict_raster_hungarian\n",
        "from utils import set_plot_params\n",
        "set_plot_params()\n",
        "%matplotlib inline\n",
        "\n",
        "loader = DataLoader(test_dataset, shuffle=False, pin_memory=False,\n",
        "                                  batch_size=1, num_wororkers=1)\n",
        "\n",
        "# device = torch.cuda.current_device()\n",
        "# model = model.to(device)\n",
        "# model.load_state_dict(torch.load(\"/Users/antonis/projects/slab/neuroformer/OneCombo3/models/model_weighted_shuffle_nodecay_True_perceiver_2.0_dt_0.05_eos_8_8_256.pt\",  map_location='cpu'))\n",
        "\n",
        "\"\"\" \n",
        "\n",
        "To predict only neurons we pass <frame_end> so we see predictions only for Neurons \n",
        "If you want to also see frame_tokens, just pass <frame_end=0>\n",
        "\n",
        "NOTE: 512 ID is the <end-of-sequence-id>. Right now, makes no difference if I include\n",
        "it in loss, here it is included in loss and predictions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "results = predict_raster_recursive_time_auto(model, loader, window, stoi, itos_dt, sample=True, top_p=0.95, top_p_t=0.95, frame_end=0, get_dt=True, gpu=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# whole_dataset = SpikeTimeVidData2(df, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "\n",
        "# loader = DataLoader(whole_dataset, shuffle=False, pin_memory=False,\n",
        "#                                   batch_size=1, num_workers=1)\n",
        "\n",
        "# results = predict_raster_recursive_time_auto(model, loader, window, stoi, itos_dt, sample=True, top_p=0.675, top_p_t=0.675, frame_end=0, get_dt=True, gpu=False)\n",
        "                                  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results = predict_raster_recursive_time_auto(model, loader, window, stoi, itos_dt, sample=True, top_p=0.95, top_p_t=0.95, frame_end=0, get_dt=True, gpu=False)\n",
        "\n",
        "pred_keys = ['ID', 'dt', 'Trial', 'Interval']\n",
        "predicted_dict = {k: results[k] for k in results if k in pred_keys}\n",
        "df_pred = pd.DataFrame(predicted_dict)\n",
        "df_pred['Time'] = df_pred['dt'] + df_pred['Interval'] - 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "true_keys = ['true', 'time']\n",
        "true_dict = {k: results[k] for k in results if k in true_keys}\n",
        "df_true = pd.DataFrame(true_dict)\n",
        "df_true.rename({'true':'ID', 'time':'dt'}, axis=1, inplace=True)\n",
        "\n",
        "print(len(test_data), len(df_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kejTrZ1_2u8T"
      },
      "outputs": [],
      "source": [
        "# predicted_timing = [itos_dt[int(dt)] for dt in predicted_timing]\n",
        "# df_pred = pd.DataFrame({'True':true, 'Predicted':predicted, 'Time':true_timing, 'Predicted_Time':predicted_timing})    # Time':test_data['Time']})\n",
        "df_pred.to_csv(f\"/home/antonis/projects/slab/git/neuroformer/data/SimNeu3D/inference/sparse_neuroformer_nopad_unweighted:dt_:True_perceiver_1.0_0.05_(4, 4, 8)_4_64.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfOV6gZ7tft_"
      },
      "outputs": [],
      "source": [
        "# df_pred = pd.read_csv(\"/content/drive/MyDrive/slab/predictions/model_dt_perceiver_83_4_256.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ5MDNR8tQrS",
        "outputId": "8e651939-1fba-4a03-c27b-e193df2453b5"
      },
      "outputs": [],
      "source": [
        "set_plot_params()\n",
        "\n",
        "# from utils import set_plot_white\n",
        "# set_plot_white\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "8xuT7kfAB4cg",
        "outputId": "8b175ce4-a5ba-4fab-ae60-38183184f4b2"
      },
      "outputs": [],
      "source": [
        "# df_dt = [y['dt'][:len(y['dt']) - (x['pad'])] for x, y in test_dataset]\n",
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "# df_dt = df_true['time']\n",
        "freq_dt_true = df_true.groupby(['dt']).size()\n",
        "plt.bar(np.arange(len(freq_dt_true.index)), freq_dt_true, alpha=0.5, label='True')\n",
        "\n",
        "\n",
        "# df_dt_pred = df_pred['time_pred']\n",
        "freq_dt_pred = df_pred.groupby(['dt']).size()\n",
        "plt.bar(np.arange(len(freq_dt_pred.index)), freq_dt_pred, alpha=0.5, label='Predicted')\n",
        "\n",
        "\n",
        "# plt.xticks(ticks=pd.to_numeric(freq_dt_pred.index)labels=pd.to_numeric(freq_dt_pred.index))\n",
        "plt.title('dt Interval Groups')\n",
        "plt.xlabel('dt Group (n x 0.05s)')\n",
        "plt.ylabel('Count (N)')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig(\"dt_interval_dist.png\", dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_pred = pd.read_csv(\"OneCombo3/inference/model_weighted_shuffle:True_perceiver_2.0_dt:0.05_eos_8_8_256.csv\").iloc[:, 1:]\n",
        "# # df_pred['Trial'] = test_data['Trial']\n",
        "# df_pred.rename({'id':'ID', 'trial':'Trial', 'interval':'Interval', 'time':'Time'}, axis=1, inplace=True)\n",
        "# df_pred.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_neurons = len(train_data['ID'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_freqs(df, n_neurons):\n",
        "    freqs = np.zeros(n_neurons)\n",
        "    for i in range(n_neurons):\n",
        "        freqs[i] = (len(df[df['ID'] == i]))\n",
        "    return freqs\n",
        "\n",
        "freq_true = get_freqs(test_data, n_neurons)\n",
        "freq_pred = get_freqs(df_pred[df_pred['ID'] <= max(test_data['ID'].unique())], n_neurons)\n",
        "\n",
        "plt.xlabel('True Frequency (N)')\n",
        "plt.ylabel('Predicted Frequency (N)')\n",
        "plt.xlim(0, max(freq_pred))\n",
        "plt.scatter(freq_true, freq_pred, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_trial = [22, 25, 35, 37]\n",
        "intervals = sorted(set(df['Interval'].unique()) & set(df['Interval'].unique()))\n",
        "labels = [round(window + window*n, 2) for n in range(0, int(max(df['Interval']) / window))]\n",
        "ids = sorted(set(df['ID'].unique()) & set(df['ID'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_1 = test_data[test_data['Trial'].isin(n_trial)]\n",
        "df_2 = df_pred[df_pred['Trial'].isin(n_trial)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_trials.unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import *\n",
        "\n",
        "set_plot_white()\n",
        "\n",
        "true_color = \"#069AF3\"\n",
        "pred_color = \"#F97306\"\n",
        "train_color = \"#008000\"\n",
        "\n",
        "\n",
        "df_pred = df_pred[df_pred['ID'] <= max(test_data['ID'].unique())]\n",
        "\n",
        "n_trials = []\n",
        "fig, ax = plt.subplots(figsize=(10, 20), nrows=n_trials, ncols=2)\n",
        "\n",
        "neuron_ids = [i for i in range(20, 26)]\n",
        "for i in range(neuron_ids):\n",
        "    chosen_trial = np.random.choice(common_trials)\n",
        "    freq_true = get_freqs(test_data[test_data['Trial'] == chosen_trial], n_neurons)\n",
        "    freq_pred = get_freqs(df_pred[df_pred['Trial'] == chosen_trial], n_neurons)\n",
        "    freq_train = get_freqs(train_data[train_data['Trial'] == chosen_trial + 1], n_neurons)\n",
        "\n",
        "    ax[i, 0].set_title(f\"True vs. Predicted, {chosen_trial}\")\n",
        "    ax[i, 0].scatter(freq_true, freq_pred, alpha=0.5, color=pred_color)\n",
        "    ax[i, 0].set_xlim(0, max(freq_pred + freq_true))\n",
        "    ax[i, 0].set_ylim(0, max(freq_pred + freq_true))\n",
        "\n",
        "    ax[i, 1].set_title(f\"True vs. True, {chosen_trial} - {chosen_trial + 1}\")\n",
        "    ax[i, 1].scatter(freq_true, freq_train, alpha=0.5, color=true_color)\n",
        "    ax[i, 1].set_xlim(0, max(freq_train + freq_true))\n",
        "    ax[i, 1].set_ylim(0, max(freq_train + freq_true))\n",
        "\n",
        "    common_trials.remove(chosen_trial)\n",
        "\n",
        "\n",
        "fig.supxlabel('Count (N)')\n",
        "fig.supylabel('Count (N)')\n",
        "fig.suptitle(\"Trial ID Frequency Comparison\", y=0.92, fontsize=16)\n",
        "plt.tight_layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freq_true = test_data.groupby(['ID']).size()\n",
        "freq_pred = df_pred.groupby(['ID']).size()\n",
        "plt.scatter(freq_true, freq_pred, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KF-yN4YnW8JF",
        "outputId": "4c12e8ba-ce9c-4f29-e387-d85dd4bc54fb"
      },
      "outputs": [],
      "source": [
        "def plot_distribution(df_1, df_2):\n",
        "    plt.figure(figsize=(30,20))\n",
        "    n_min = 166\n",
        "    freq_true = df_1[df_1['ID'] < n_min].groupby(['ID']).size()\n",
        "    freq_pred = df_2[df_2['ID'] < n_min].groupby(['ID']).size()\n",
        "    plt.bar(freq_pred.index, freq_pred, label='predicted', alpha=0.5)\n",
        "    plt.bar(freq_true.index, freq_true, label='true', alpha=0.5)\n",
        "    plt.title('Neuron Firing Distribution', fontsize=40)\n",
        "    plt.legend(fontsize=30)\n",
        "    plt.xlabel('Neuron ID (n)', fontsize=30)\n",
        "    plt.ylabel('Count (N)', fontsize=30)\n",
        "    plt.xticks(fontsize=30)\n",
        "    plt.yticks(fontsize=30)\n",
        "    plt.savefig(\"id_interval_dist.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_distribution(test_data, df_pred)\n",
        "# plt.savefig(\"id_interval_dist.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_distribution(df[df['Trial'] == 1], df[df['Trial'] == 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkNi8QrXQnOd"
      },
      "outputs": [],
      "source": [
        "true_timing = np.array(true_timing)\n",
        "predicted_timing = np.array(predicted_timing)\n",
        "true_time_seq = [sum(true_timing[0:i[0]]) for i in enumerate(true_timing)]\n",
        "pred_time_seq = [sum(predicted_timing[0:i[0]]) for i in enumerate(predicted_timing)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YI5vHCJMR_MI",
        "outputId": "62561f65-5dcf-4992-c365-a63f66db9f1a"
      },
      "outputs": [],
      "source": [
        "len_pred = len(df_true)\n",
        "# len_pred = 1000\n",
        "plt.figure(figsize=(40,40))\n",
        "plt.title('Pixel / Spike Raster', size=50)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Neuron ID')\n",
        "plt.scatter(test_data['Time'], test_data['ID'], alpha=0.6, label='true', marker='o')\n",
        "plt.scatter(df_pred['Time'], df_pred['ID'], alpha=0.6, label='predicted', marker='x')\n",
        "plt.legend(fontsize=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W8m4D1RMXdCt",
        "outputId": "96ceeae1-9eb0-447c-888c-12e5323c7639"
      },
      "outputs": [],
      "source": [
        "len_pred = len(true)\n",
        "# len_pred = 1000\n",
        "plt.figure(figsize=(40,40))\n",
        "plt.title('Pixel / Spike Raster', size=50)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Neuron ID')\n",
        "plt.scatter(np.arange(len_pred), true[:len_pred], alpha=0.6, label='true', marker='o')\n",
        "plt.scatter(np.arange(len_pred), predicted[:len_pred], alpha=0.6, label='predicted', marker='x')\n",
        "plt.legend(fontsize=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBiX4j0-vrQQ",
        "outputId": "8128a9b6-904a-4cae-83c5-b1b323d4ea98"
      },
      "outputs": [],
      "source": [
        "df_pred['Predicted_Time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NCVcWeHlZ6_",
        "outputId": "8c1f8cea-c8ac-4729-a126-6e746312fa04"
      },
      "outputs": [],
      "source": [
        "np.arange(len(freq_dt_true.index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g63GZ43Vln3-"
      },
      "outputs": [],
      "source": [
        "predicted_timing = [itos_dt for dt in predicted_timing]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "6a-Pq3Zclp1-",
        "outputId": "fc665faf-44bf-4708-966e-05d6ee916f8f"
      },
      "outputs": [],
      "source": [
        "true_timing = pd.DataFrame(true_timing)\n",
        "predicted_timing = pd.DataFrame(predicted_timing)\n",
        "plot_distribution(true_timing[true_timing[0] > 0], predicted_timing[predicted_timing[0] > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idlvrNGDtHd3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transformer_vid3_dt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
