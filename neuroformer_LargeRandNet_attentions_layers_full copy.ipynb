{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "import glob\n",
    "import collections\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import set_seed\n",
    "\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from neuroformer.utils import print_full\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from neuroformer.visualize import *\n",
    "set_plot_params()\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "\n",
    "from neuroformer.model_neuroformer import GPT, GPTConfig, neuralGPTConfig\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "\n",
    "\n",
    "import json\n",
    "# for i in {1..10}; do python3 -m gather_atts.py; done\n",
    "\n",
    "from attention.LRN_attention import *\n",
    "\n",
    "DATASET = 'LRN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.prepare_data import load_LRN\n",
    "\n",
    "df, stimulus = load_LRN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "n_seed = 25\n",
    "set_seed(n_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config files\n",
    "\n",
    "import yaml\n",
    "\n",
    "base_path = \"./models/tensorboard/LRN/att_exp/2_window:0.5_prev:19.5_smooth/sparse_f:None_id:None/w:0.5_wp:19.5\"\n",
    "\n",
    "with open(os.path.join(base_path, 'mconf.yaml'), 'r') as stream:\n",
    "    mconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'tconf.yaml'), 'r') as stream:\n",
    "    tconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'dconf.yaml'), 'r') as stream:\n",
    "    dconf = yaml.full_load(stream)\n",
    "\n",
    "import omegaconf\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# open yaml as omegacong\n",
    "mconf = OmegaConf.create(mconf)\n",
    "tconf = OmegaConf.create(tconf)\n",
    "dconf = OmegaConf.create(dconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(parent_path + \"code/data/OneCombo3/Combo3_all_stim.csv\")\n",
    "w_mult = 3\n",
    "frame_window = dconf.frame_window\n",
    "window = dconf.window\n",
    "window_prev = dconf.window_prev\n",
    "dt = dconf.dt\n",
    "dt_frames = dconf.dt_frames\n",
    "# p_window = window / (window + window_prev)\n",
    "# intervals = np.load(os.path.join(base_path, \"intervals.npy\"))\n",
    "intervals = None\n",
    "\n",
    "\n",
    "from SpikeVidUtils import make_intervals\n",
    "\n",
    "df['real_interval'] = make_intervals(df, dt)\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['Interval_2'] = make_intervals(df, window_prev)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# n_dt = sorted((df['Interval_dt'].unique()).round(2)) \n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1  # add first / last interval for SOS / EOS'\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)] + ['EOS'] + ['PAD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_trials = df.groupby(['Interval', 'Trial']).size()\n",
    "print(int_trials.mean())\n",
    "# df.groupby(['Interval', 'Trial']).agg(['nunique'])model_path\n",
    "# var_group = 'Interval_2'\n",
    "# n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "# df.groupby(['Interval_2', 'Trial']).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "## resnet3d feats\n",
    "n_embd = mconf.n_embd\n",
    "frame_feats = torch.tensor(stimulus, dtype=torch.float32).transpose(1, 0)\n",
    "frame_block_size = mconf.frame_block_size  # math.ceil(frame_feats.shape[-1] * frame_window)\n",
    "n_embd_frames = mconf.n_embd_frames\n",
    "\n",
    "prev_id_block_size = mconf.prev_id_block_size    # math.ceil(frame_block_size * (1 - p_window))\n",
    "id_block_size = mconf.id_block_size           # math.ceil(frame_block_size * p_window)\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
    "frame_memory = dconf.frame_memory   # how many frames back does model see\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "# translate neural embeddings to separate them from ID embeddings\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "trial_tokens = [f\"Trial {n}\" for n in df['Trial'].unique()]\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_split = 0.8\n",
    "train_trials = sorted(df['Trial'].unique())[:int(len(df['Trial'].unique()) * r_split)]\n",
    "train_data = df[df['Trial'].isin(train_trials)]\n",
    "test_data = df[~df['Trial'].isin(train_trials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "from neuroformer.utils import update_object\n",
    "\n",
    "# train_dat1aset = spikeTimeData(spikes, block_size, dt, stoi, itos)\n",
    "\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=intervals)\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                 window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                                 pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                 dt_frames=dt_frames, intervals=intervals)\n",
    "\n",
    "update_object(train_dataset, tconf)\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import get_class_weights\n",
    "# class_weights = get_class_weights(train_dataset, stoi, stoi_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_neuroformer_LRN import GPT, GPTConfig\n",
    "# initialize config class and model (holds hyperparameters)\n",
    "   \n",
    "conv_layer = False\n",
    "model_conf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                        id_vocab_size=train_dataset.id_population_size,\n",
    "                        frame_block_size=frame_block_size,\n",
    "                        id_block_size=id_block_size,  # frame_block_size\n",
    "                        prev_id_block_size=prev_id_block_size,\n",
    "                        sparse_mask=False, p_sparse=0.25, \n",
    "                        sparse_topk_frame=None, sparse_topk_id=None, sparse_topk_prev_id=None,\n",
    "                        n_dt=len(n_dt),\n",
    "                        class_weights=None,\n",
    "                        pretrain=False,\n",
    "                        n_state_layers=mconf.n_state_layers, n_state_history_layers=mconf.n_state_history_layers,\n",
    "                        n_stimulus_layers=mconf.n_stimulus_layers, self_att_layers=mconf.self_att_layers,\n",
    "                        n_head=mconf.n_head, n_embd=mconf.n_embd, \n",
    "                        contrastive=True, clip_emb=1024, clip_temp=0.5,\n",
    "                        temp_emb=True, pos_emb=False,\n",
    "                        id_drop=0.35, im_drop=0.35,\n",
    "                        window=window, window_prev=window_prev, frame_window=frame_window, dt=dt,\n",
    "                        n_embd_frames=n_embd_frames, dataset=None,\n",
    "                        ignore_index_id=stoi['PAD'], ignore_index_dt=stoi_dt['PAD'])  # 0.35\n",
    "\n",
    "update_object(model_conf, mconf)\n",
    "\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)\n",
    "max_epochs = 300\n",
    "batch_size = round((14))\n",
    "shuffle = True\n",
    "\n",
    "weighted = True if mconf.class_weights is not None else False\n",
    "title =  f'window:{window}_prev:{window_prev}_smooth'\n",
    "model_path = f\"\"\"./models/tensorboard/LRN/ignore_index/2_{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\n",
    "\n",
    "# model_path = \"/data5/antonis/neuroformer/models/tensorboard/LRN/channel/window:0.5_prev:19.5_smooth/sparse_f:None_id:None/w:0.5_wp:19.5/6_Cont:True_window:0.5_f_window:20_df:0.1_blocksize:150_conv_False_shuffle:True_batch:12_sparse_(None_None)_blocksz1150_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_197_max0.1_(8, 8, 8)_8_256.pt\"\n",
    "# if os.path.exists(model_path):\n",
    "#     print(f\"Loading model from {model_path}\")\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "# else:\n",
    "#     print(f\"Model not found at {model_path}\")\n",
    "#     raise FileNotFoundError\n",
    "\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=1e-4, \n",
    "                    num_workers=4, lr_decay=False, patience=3, warmup_tokens=8e7, \n",
    "                    decay_weights=True, weight_decay=0.2, shuffle=shuffle,\n",
    "                    final_tokens=len(train_dataset)*(id_block_size) * (max_epochs),\n",
    "                    clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                    dataset='higher_order', mode='predict',\n",
    "                    block_size=train_dataset.block_size,\n",
    "                    id_block_size=train_dataset.id_block_size,\n",
    "                    show_grads=False, plot_raster=False,\n",
    "                    ckpt_path=model_path, no_pbar=False, \n",
    "                    dist=False, save_every=1000)\n",
    "\n",
    "# trainer = Trainer(model, train_dataset, test_dataset, tconf, mconf)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=2, shuffle=shuffle, num_workers=4, pin_memory=True)\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "RUN SIMULATION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from utils import *\n",
    "from IPython.utils import io\n",
    "# top_p=0.25, top_p_t=0.9, temp=2.\n",
    "\n",
    "model_weights = glob.glob(os.path.join(base_path, '**/**.pt'), recursive=True)\n",
    "model_weights = sorted(model_weights, key=os.path.getmtime, reverse=True)\n",
    "assert len(model_weights) > 0, \"No model weights found\"\n",
    "\n",
    "\n",
    "if model_path in model_weights:\n",
    "    load_weights = model_path\n",
    "else:\n",
    "    load_weights = model_weights[0]\n",
    "\n",
    "print(f'Loading weights from {os.path.basename(model_weights[0])}')\n",
    "\n",
    "# load_weights = \"./models/tensorboard/LRN/att_exp/2_window:0.5_prev:19.5_smooth/sparse_f:None_id:None/w:0.5_wp:19.5/6_Cont:False_window:0.5_f_window:20_df:0.1_blocksize:150_conv_False_shuffle:True_batch:64_sparse_(None_None)_blocksz1150_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_197_max0.1_(8, 8, 8)_8_256.pt\"\n",
    "\n",
    "# load_weights = \"./models/tensorboard/LRN/final/p_reduce_20_window:0.5_prev:19.5/sparse_f:None_id:None/w:0.5_wp:19.5/6_Cont:False_window:0.5_f_window:20_df:0.1_blocksize:150_conv_False_shuffle:True_batch:58_sparse_(None_None)_blocksz1150_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_197_max0.1_(4, 4, 4)_1_256.pt\"\n",
    "model.load_state_dict(torch.load(load_weights, map_location=torch.device('cpu')))\n",
    "\n",
    "trials = test_data['Trial'].unique()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_matrix = np.zeros((len(stoi.keys()), 1000))\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "\n",
    "att_data = df[df['Trial'].isin([i for i in range(0, 500)])]\n",
    "att_dataset = SpikeTimeVidData2(att_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=intervals, dataset=DATASET)\n",
    "loader = DataLoader(att_dataset, batch_size=3, shuffle=True, num_workers=1)\n",
    "# model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(att_dataset, batch_size=3, shuffle=True, num_workers=1)\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, = model(x, y)\n",
    "\n",
    "attentions = get_atts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "while counter < 100:\n",
    "    x, y = next(iterable)\n",
    "    # _, _, _, = model(x, y)\n",
    "    # att = get_atts(model)\n",
    "    # attentions = np.concatenate((attentions, att), axis=0)\n",
    "    # counter += 1\n",
    "    print(f\"id: {x['id'][0]}\")\n",
    "    print(f\"interval: {x['interval'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_KEY = \"neural_stimulus_block\"\n",
    "\n",
    "attentions['neural_state_block_0'].shape\n",
    "\n",
    "agg_atts = cat_atts(attentions, LAYER_KEY)\n",
    "print(agg_atts.shape)\n",
    "agg_atts = stack_atts(attentions, LAYER_KEY)\n",
    "print(agg_atts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attentions.keys())\n",
    "attentions['neural_stimulus_block_4'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_atts(attentions, LAYER_KEY).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import set_plot_white\n",
    "import logging\n",
    "\n",
    "set_plot_white()\n",
    "\n",
    "GRAD_COND = True\n",
    "LAYER_KEY = \"neural_stimulus_block\"\n",
    "\n",
    "neurons = []\n",
    "att_scores = []\n",
    "att_scores_grad = [] \n",
    "\n",
    "loader = DataLoader(att_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "iterable = iter(loader)\n",
    "\n",
    "last_layer = \"neural_stimulus_block_{n}\".format(n=mconf.n_stimulus_layers-1)\n",
    "n_neurons = 10\n",
    "ncols = 5\n",
    "nrows = n_neurons // ncols + 1\n",
    "\n",
    "plt.figure(figsize=(40, (20) * (n_neurons // 20)))\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "n_idx = 3\n",
    "counter = 0\n",
    "\n",
    "print(f\"-- Running {n_neurons} steps of attention formulation --\")\n",
    "pbar = tqdm(total=n_neurons)\n",
    "while counter < n_neurons:\n",
    "    # print(f\"Counter: {counter} / {n_neurons}\")\n",
    "    x, y = next(iterable)\n",
    "\n",
    "    try:\n",
    "        neuron_x = int(itos[int(x['id'].flatten()[n_idx])])\n",
    "        neuron_y = int(itos[int(y['id'].flatten()[n_idx])])\n",
    "        counter += 1\n",
    "        pbar.update(1)\n",
    "        # logging.info(f\"Counter: {counter} / {n_neurons}\")\n",
    "        neurons.append({\"x\": neuron_x, \"y\": neuron_y})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    model.zero_grad()\n",
    "    with torch.set_grad_enabled(GRAD_COND):\n",
    "        _, _, _, = model(x, y)\n",
    "    attentions = get_atts(model)\n",
    "    \n",
    "    att_scores.append(cat_atts(attentions, LAYER_KEY))\n",
    "\n",
    "    # if GRAD_COND:\n",
    "    gradients = get_grads(model)\n",
    "    attentions = gradcam(attentions, gradients)\n",
    "    att_scores_grad.append(cat_atts(attentions, LAYER_KEY))\n",
    "\n",
    "    att_vis = torch.cat([attentions[k] for k in attentions.keys() if k.startswith(LAYER_KEY)])\n",
    "    # att_vis = attentions[last_layer].mean(dim=1)[0][0]\n",
    "    att_vis = cat_atts(attentions, LAYER_KEY).max(dim=1)[0]\n",
    "    att_vis_mean = att_vis.min(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_att_dict_state = collections.defaultdict(list)\n",
    "neuron_att_dict_idx = collections.defaultdict(list)\n",
    "\n",
    "print(f\"-- now building matrix --\")\n",
    "pbar = tqdm(total=len(neurons))\n",
    "for idx, row in enumerate(neurons):\n",
    "    xid = row['x']\n",
    "    attention = att_scores[idx]\n",
    "    neuron_att_dict_state[str(xid)].append(attention)\n",
    "    neuron_att_dict_idx[str(xid)].append(attention)\n",
    "\n",
    "for key in neuron_att_dict_state.keys():\n",
    "    neuron_att_dict_state[key] = torch.stack(neuron_att_dict_state[key])\n",
    "for key in neuron_att_dict_idx.keys():\n",
    "    neuron_att_dict_idx[key] = torch.stack(neuron_att_dict_idx[key])\n",
    "\n",
    "# # save neuron_att_dict_state and idx as .mat files\n",
    "# import scipy.io as sio\n",
    "\n",
    "# save_path = \"\"\n",
    "# sio.savemat(os.path.join(save_path, 'attentions/neuron_att_dict_state'), neuron_att_dict_state)\n",
    "# sio.savemat(os.path.join(save_path, 'attentions/neuron_att_dict_idx.mat'), neuron_att_dict_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "n_plots = 50\n",
    "ncols = 2\n",
    "nrows = n_plots // ncols + 1\n",
    "\n",
    "n_neurons = 10\n",
    "for idx, neuron in enumerate(neuron_att_dict_state.keys()):\n",
    "    av_attention_full = neuron_att_dict_state[neuron].max(-4)[0].min(-3)[0].mean(0).mean(0)\n",
    "    av_attention_mean = av_attention_full.reshape(-1, 1000).mean(0)\n",
    "    plt.subplot(nrows, ncols, idx+1)\n",
    "    plt.plot(av_attention_mean)\n",
    "    plt.axvline(int(neuron), color=\"blue\")\n",
    "    # plt.subplot(nrows, ncols, idx+1+ncols)\n",
    "    # plt.plot(av_attention_full)\n",
    "    \n",
    "    # plt.title(f\"{neurons}\")\n",
    "    plt.axis(\"off\")\n",
    "    if idx >= n_plots:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAD_COND = True\n",
    "LAYER_KEY = \"neural_stimulus_block\"\n",
    "\n",
    "lw = 5\n",
    "fs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions[\"neural_stimulus_block_0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_vis = torch.cat([attentions[k] for k in attentions.keys() if k.startswith(LAYER_KEY)])\n",
    "att_vis = att_vis.max(0)[0].min(0)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title(f\"x: {neuron_x}, y: {neuron_y}\", fontsize=20)\n",
    "plt.plot(att_vis[n_idx])\n",
    "plt.axvline(x=neuron_x, color='b', label='x', linewidth=lw)\n",
    "plt.axvline(x=neuron_y, color='g', label='y', linewidth=lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.attentionVis import rollout_attentions\n",
    "\n",
    "rollout_atts = [rollout_attentions(att) for att in att_scores]\n",
    "att_types = [att_scores, att_scores_grad, rollout_atts]\n",
    "\n",
    "ncols = len(att_types)\n",
    "nrows = len(neurons) + 1\n",
    "\n",
    "plt.figure(figsize=(20, (70)))\n",
    "title = \"Attention over time\"\n",
    "\n",
    "\n",
    "for n_idx, row in enumerate(neurons):\n",
    "    for n_att, attention in enumerate(att_types):\n",
    "        neuron_x = row['x']\n",
    "        neuron_y = row['y']\n",
    "\n",
    "        # att_vis = torch.cat([attention[k] for k in attention.keys() if k.startswith(LAYER_KEY)])\n",
    "        # att_vis = att_vis[-1].min(0)[0]\n",
    "        attention = attention[n_idx]\n",
    "        if len(attention.shape) == 4:\n",
    "            att_vis = attention.max(0)[0].min(0)[0]\n",
    "            # att_vis = attention[-1].min(0)[0]\n",
    "        else:\n",
    "            att_vis = attention\n",
    "\n",
    "        plt.subplot(nrows, ncols, n_idx * ncols + n_att + 1)\n",
    "        plt.grid()\n",
    "        plt.title(f\"x: {neuron_x}, y: {neuron_y}\", fontsize=20)\n",
    "        plt.plot(att_vis[n_idx])\n",
    "        plt.axvline(x=neuron_x, color='b', label='x', linewidth=lw)\n",
    "        plt.axvline(x=neuron_y, color='g', label='y', linewidth=lw)\n",
    "plt.suptitle(title)\n",
    "\n",
    "save_path = os.path.join(base_path,'attention', 'channels')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "n_files = glob.glob(os.path.join(save_path, '*/*.svg'))\n",
    "plt.savefig(os.path.join(save_path, f\"{title}_{len(n_files)}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.attentionVis import rollout_attentions\n",
    "from attention.LRN_attention import reshape_attentions\n",
    "\n",
    "rollout_atts = [rollout_attentions(att) for att in att_scores]\n",
    "att_types = [att_scores, att_scores_grad, rollout_atts]\n",
    "\n",
    "ncols = len(att_types)\n",
    "nrows = len(neurons) + 1\n",
    "\n",
    "plt.figure(figsize=(20, (70)))\n",
    "title = \"Attention averaged over time\"\n",
    "\n",
    "for n_idx, row in enumerate(neurons):\n",
    "    for n_att, attention in enumerate(att_types):\n",
    "        neuron_x = row['x']\n",
    "        neuron_y = row['y']\n",
    "\n",
    "        # att_vis = torch.cat([attention[k] for k in attention.keys() if k.startswith(LAYER_KEY)])\n",
    "        # att_vis = att_vis[-1].min(0)[0]\n",
    "        attention = attention[n_idx]\n",
    "        if len(attention.shape) == 4:\n",
    "            att_vis = attention.max(0)[0].min(0)[0]\n",
    "            # att_vis = attention[-1].min(0)[0]\n",
    "        else:\n",
    "            att_vis = attention\n",
    "        \n",
    "        att_vis = reshape_attentions(att_vis, stimulus)\n",
    "\n",
    "        plt.subplot(nrows, ncols, n_idx * ncols + n_att + 1)\n",
    "        plt.grid()\n",
    "        plt.title(f\"x: {neuron_x}, y: {neuron_y}\", fontsize=20)\n",
    "        plt.plot(att_vis[n_idx])\n",
    "        plt.axvline(x=neuron_x, color='b', label='x', linewidth=lw)\n",
    "        plt.axvline(x=neuron_y, color='g', label='y', linewidth=lw)\n",
    "\n",
    "save_path = os.path.join(base_path,'attention', 'channels')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "n_files = glob.glob(os.path.join(save_path, '*/*.svg'))\n",
    "plt.savefig(os.path.join(save_path, f\"{title}_{len(n_files)}.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4878f327e989b61de6701446a3bf7b6f9ae7705c9c90fa2b4cdf5489a55bcfeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
