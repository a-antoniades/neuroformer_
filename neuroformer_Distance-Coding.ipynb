{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n",
      "CONTRASTIUVEEEEEEE False\n",
      "VISUAL: True\n",
      "PAST_STATE: True\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "from neuroformer.model_neuroformer import GPT, GPTConfig\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import set_seed, update_object, check_common_attrs, running_jupyter, all_device\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.SpikeVidUtils import make_intervals, round_n, SpikeTimeVidData2\n",
    "import gdown\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "import argparse\n",
    "from neuroformer.SpikeVidUtils import round_n\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--infer\", action=\"store_true\", help=\"Inference mode\")\n",
    "    parser.add_argument(\"--train\", action=\"store_true\", default=False, help=\"Train mode\")\n",
    "    parser.add_argument(\"--dist\", action=\"store_true\", default=False, help=\"Distributed mode\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=25, help=\"Random seed\")\n",
    "    parser.add_argument(\"--resume\", type=str, default=None, help=\"Resume from checkpoint\")\n",
    "    parser.add_argument(\"--rand_perm\", action=\"store_true\", default=False, help=\"Randomly permute the ID column\")\n",
    "    parser.add_argument(\"--mconf\", type=str, default=None, help=\"Path to model config file\")\n",
    "    parser.add_argument(\"--eos_loss\", action=\"store_true\", default=False, help=\"Use EOS loss\")\n",
    "    parser.add_argument(\"--no_eos_dt\", action=\"store_true\", default=False, help=\"No EOS dt token\")\n",
    "    parser.add_argument(\"--downstream\", action=\"store_true\", default=False, help=\"Downstream task\")\n",
    "    parser.add_argument(\"--freeze_model\", action=\"store_true\", default=False, help=\"Freeze model\")\n",
    "    parser.add_argument(\"--title\", type=str, default=None)\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"Distance-Coding\")\n",
    "    parser.add_argument(\"--behavior\", action=\"store_true\", default=False, help=\"Behavior task\")\n",
    "    parser.add_argument(\"--pred_behavior\", action=\"store_true\", default=False, help=\"Predict behavior\")\n",
    "    parser.add_argument(\"--past_state\", action=\"store_true\", default=False, help=\"Input past state\")\n",
    "    parser.add_argument(\"--visual\", action=\"store_true\", default=False, help=\"Visualize\")\n",
    "    parser.add_argument(\"--contrastive\", action=\"store_true\", default=False, help=\"Contrastive\")\n",
    "    parser.add_argument(\"--clip_loss\", action=\"store_true\", default=False, help=\"Clip loss\")\n",
    "    parser.add_argument(\"--clip_vars\", nargs=\"+\", default=['id','frames'], help=\"Clip variables\")\n",
    "    parser.add_argument(\"--class_weights\", action=\"store_true\", default=False, help=\"Class weights\")\n",
    "    parser.add_argument(\"--resample\", action=\"store_true\", default=False, help=\"Resample\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "if running_jupyter(): # or __name__ == \"__main__\":\n",
    "    print(\"Running in Jupyter\")\n",
    "    INFERENCE = False\n",
    "    DIST = False\n",
    "    SEED = 25\n",
    "    DOWNSTREAM = False\n",
    "    TITLE = None\n",
    "    RESUME = None\n",
    "    RAND_PERM = False\n",
    "    MCONF = None\n",
    "    EOS_LOSS = False\n",
    "    NO_EOS_DT = False\n",
    "    FREEZE_MODEL = False\n",
    "    TITLE = None\n",
    "    DATASET = \"Distance-Coding\"\n",
    "    BEHAVIOR = False\n",
    "    PREDICT_BEHAVIOR = False\n",
    "    VISUAL = True\n",
    "    PAST_STATE = True\n",
    "    CONTRASTIVE = False\n",
    "    CLIP_LOSS = True\n",
    "    CLIP_VARS = ['id','frames']\n",
    "    CLASS_WEIGHTS = False\n",
    "    RESAMPLE_DATA = False\n",
    "# else:\n",
    "    # print(\"Running in terminal\")\n",
    "    # args = parse_args()\n",
    "    # INFERENCE = not args.train\n",
    "    # DIST = args.dist\n",
    "    # SEED = args.seed\n",
    "    # DOWNSTREAM = args.downstream\n",
    "    # TITLE = args.title\n",
    "    # RESUME = args.resume\n",
    "    # RAND_PERM = args.rand_perm\n",
    "    # MCONF = args.mconf\n",
    "    # EOS_LOSS = args.eos_loss\n",
    "    # NO_EOS_DT = args.no_eos_dt\n",
    "    # FREEZE_MODEL = args.freeze_model\n",
    "    # DATASET = args.dataset\n",
    "    # BEHAVIOR = args.behavior\n",
    "    # PREDICT_BEHAVIOR = args.pred_behavior\n",
    "    # VISUAL = args.visual\n",
    "    # PAST_STATE = args.past_state\n",
    "    # CONTRASTIVE = args.contrastive\n",
    "    # CLIP_LOSS = args.clip_loss\n",
    "    # CLIP_VARS = args.clip_vars\n",
    "    # CLASS_WEIGHTS = args.class_weights\n",
    "    # RESAMPLE_DATA = args.resample\n",
    "\n",
    "# SET SEED - VERY IMPORTANT\n",
    "set_seed(SEED)\n",
    "\n",
    "print(f\"CONTRASTIUVEEEEEEE {CONTRASTIVE}\")\n",
    "print(f\"VISUAL: {VISUAL}\")\n",
    "print(f\"PAST_STATE: {PAST_STATE}\")\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Distance-Coding/neuroformer/spikerates.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1936719/3776578220.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdistance_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/Distance-Coding/neuroformer/distance_array.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mspikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Distance-Coding/neuroformer/spikerates.npy'"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from neuroformer.prepare_data import DataLinks\n",
    "from DataUtils import round_n\n",
    "\n",
    "spikes_path = \"data/Distance-Coding/neuroformer/spikerates.npy\"\n",
    "distance_path = \"data/Distance-Coding/neuroformer/distance_array.npy\"\n",
    "\n",
    "spikes = np.load(spikes_path)\n",
    "distance = np.round(np.load(distance_path), 3)\n",
    "\n",
    "frame_feats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/Distance-Coding/iscell.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1936719/3620923409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcell_numbers_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/Distance-Coding/iscell.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcell_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_numbers_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Distance-Coding/iscell.npy'"
     ]
    }
   ],
   "source": [
    "cell_numbers_path = \"./data/Distance-Coding/iscell.npy\"\n",
    "cell_numbers = np.load(cell_numbers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config files\n",
    "import yaml\n",
    "\n",
    "# base_path = \"configs/visnav/predict_behavior\"\n",
    "if MCONF is not None:\n",
    "    base_path = os.path.dirname(MCONF)\n",
    "elif RESUME is not None:\n",
    "    base_path = os.path.dirname(RESUME)\n",
    "else:\n",
    "    # base_path = \"./configs/Combo3_V1AL/kernel_size/wave_emb/01second-noselfatt/01second-noselfatt_small/\"\n",
    "    base_path = None\n",
    "    \n",
    "if base_path is not None:\n",
    "    with open(os.path.join(base_path, 'mconf.yaml'), 'r') as stream:\n",
    "        mconf = yaml.full_load(stream)\n",
    "\n",
    "    with open(os.path.join(base_path, 'tconf.yaml'), 'r') as stream:\n",
    "        tconf = yaml.full_load(stream)\n",
    "\n",
    "    with open(os.path.join(base_path, 'dconf.yaml'), 'r') as stream:\n",
    "        dconf = yaml.full_load(stream)\n",
    "\n",
    "    import omegaconf\n",
    "    from omegaconf import OmegaConf\n",
    "\n",
    "    # open yaml as omegacong\n",
    "    mconf = OmegaConf.create(mconf)\n",
    "    tconf = OmegaConf.create(tconf)\n",
    "    dconf = OmegaConf.create(dconf)\n",
    "\n",
    "    # set attrs that are not equal\n",
    "    common_attrs = check_common_attrs(mconf, tconf, dconf)\n",
    "    print(f\"Common attributes: {common_attrs}\")\n",
    "\n",
    "else:\n",
    "    mconf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_window = 0.5\n",
    "window = 0.02\n",
    "window_prev = 0.02\n",
    "window_behavior = window\n",
    "dt = 0.01\n",
    "dt_frames = 0.01\n",
    "dt_vars = 0.01\n",
    "intervals = None\n",
    "\n",
    "# randomly permute 'id' column\n",
    "if RAND_PERM:\n",
    "    df['ID'] = df['ID'].sample(frac=1, random_state=25).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervals.shape: (60003,)\n",
      "distance.shape: (60003,)\n",
      "ID vocab size: 252\n",
      "dt vocab size: 6\n",
      "distance vocab size: 10\n"
     ]
    }
   ],
   "source": [
    "## resnet3d feats\n",
    "from neuroformer.DataUtils import split_data_by_interval\n",
    "\n",
    "intervals = np.arange(0, spikes.shape[1] * dt, window)\n",
    "train_intervals, test_intervals, finetune_intervals = split_data_by_interval(intervals, r_split=0.8, r_split_ft=0.01)\n",
    "\n",
    "from neuroformer.DataUtils import Tokenizer\n",
    "\n",
    "# intervals = np.array([round_n(t, window) for t in np.arange(0)])\n",
    "id_block_size = 4000\n",
    "prev_id_block_size = 4000\n",
    "frame_block_size = 0\n",
    "\n",
    "# make sure intervals = same size as distance\n",
    "\n",
    "min_shape = min(intervals.shape[0], distance.shape[0])\n",
    "intervals = intervals[:min_shape]\n",
    "distance = distance[:min_shape]\n",
    "\n",
    "print(f\"intervals.shape: {intervals.shape}\")\n",
    "print(f\"distance.shape: {distance.shape}\")\n",
    "\n",
    "# -------- #\n",
    "\n",
    "\n",
    "spikes_dict = {\n",
    "    \"ID\": spikes,\n",
    "    \"Interval\": intervals,\n",
    "    \"dt\": dt,\n",
    "    \"id_block_size\": id_block_size,\n",
    "    \"prev_id_block_size\": prev_id_block_size,\n",
    "    \"frame_block_size\": frame_window,\n",
    "    \"window\": window,\n",
    "    \"window_prev\": window_prev,\n",
    "}\n",
    "\n",
    "\n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)]\n",
    "\n",
    "token_types = {\n",
    "    'ID': {'tokens': list(np.arange(0, spikes.shape[0]))},\n",
    "    'dt': {'tokens': n_dt, 'resolution': dt},\n",
    "    'distance': {'tokens': list(set(distance)), 'resolution': 0.001},\n",
    "}\n",
    "\n",
    "tokenizer = Tokenizer(token_types, max_window, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_var_distance = 0.01\n",
    "\n",
    "\"\"\" structure:\n",
    "{\n",
    "    type_of_modality:\n",
    "        {name of modality: {'data':data, 'dt': dt, 'predict': True/False},\n",
    "        ...\n",
    "        }\n",
    "    ...\n",
    "}\n",
    "\"\"\"\n",
    "modalities = {\n",
    "    'all': \n",
    "            {'distance': \n",
    "                {'data': distance, 'dt': dt_var_distance, 'predict': True}\n",
    "            },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance {'data': array([0., 0., 0., ..., 0., 0., 0.]), 'dt': 0.01, 'predict': True}\n"
     ]
    }
   ],
   "source": [
    "for modality_type, modality in modalities.items():\n",
    "    for variable_type, variable in modality.items():\n",
    "        print(variable_type, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# var_group = 'Interval'\n",
    "# int_trials = df.groupby([var_group, 'Trial']).size()\n",
    "# print(int_trials.mean())\n",
    "# # df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
    "# n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.1 * n_unique))\n",
    "# # df.groupby(['Interval_2', 'Trial']).size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Interval: 0.04\n",
      "Intervals:  60003\n",
      "Window:  0.02\n",
      "Window Prev:  0.02\n",
      "Population Size:  252\n",
      "ID Population Size:  252\n",
      "DT Population Size:  6\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.04\n",
      "Intervals:  60003\n",
      "Window:  0.02\n",
      "Window Prev:  0.02\n",
      "Population Size:  252\n",
      "ID Population Size:  252\n",
      "DT Population Size:  6\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.04\n",
      "Intervals:  60003\n",
      "Window:  0.02\n",
      "Window Prev:  0.02\n",
      "Population Size:  252\n",
      "ID Population Size:  252\n",
      "DT Population Size:  6\n",
      "Using explicitly passed intervals\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.DataUtils import NFDataloader\n",
    "\n",
    "train_dataset = NFDataloader(spikes_dict, tokenizer, frame_feats,\n",
    "                             dataset=DATASET, intervals=train_intervals, modalities=modalities)\n",
    "test_dataset = NFDataloader(spikes_dict, tokenizer, frame_feats,\n",
    "                            dataset=DATASET, intervals=test_intervals, modalities=modalities)\n",
    "finetune_dataset = NFDataloader(spikes_dict, tokenizer, frame_feats,\n",
    "                                dataset=DATASET, intervals=finetune_intervals, modalities=modalities)\n",
    "    \n",
    "# print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "iterable = iter(train_dataset)\n",
    "x, y = next(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_prev torch.Size([4000]) torch.int64\n",
      "dt_prev torch.Size([4000]) torch.float32\n",
      "pad_prev torch.Size([]) torch.int64\n",
      "id torch.Size([4000]) torch.int64\n",
      "dt torch.Size([4000]) torch.float32\n",
      "pad torch.Size([]) torch.int64\n",
      "interval torch.Size([]) torch.float32\n",
      "trial torch.Size([]) torch.int64\n",
      "cid torch.Size([2]) torch.float32\n",
      "pid torch.Size([2]) torch.float32\n",
      "id torch.Size([4000]) torch.int64\n",
      "dt torch.Size([4000]) torch.int64\n",
      "modalities_distance_value torch.Size([2]) torch.int64\n",
      "modalities_distance_dt torch.Size([]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "def recursive_print(x, keys=None):\n",
    "    if keys is None:\n",
    "        keys = []\n",
    "    if isinstance(x, dict):\n",
    "        for key, value in x.items():\n",
    "            recursive_print(value, keys + [key])\n",
    "    elif isinstance(x, torch.Tensor):\n",
    "        print(\"_\".join(keys), x.shape, x.dtype)\n",
    "\n",
    "# suppose iterable is your iterable object\n",
    "x, y = next(iterable)\n",
    "\n",
    "recursive_print(x)\n",
    "recursive_print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval: tensor([8.5800, 8.6000])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.6000, 8.6200])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.6200, 8.6400])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.6400, 8.6600])\n",
      "spikes: tensor([39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39])\n",
      "interval: tensor([8.6600, 8.6800])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.6800, 8.7000])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.7000, 8.7200])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.7200, 8.7400])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.7400, 8.7600])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.7600, 8.7800])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.7800, 8.8000])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.8000, 8.8200])\n",
      "spikes: tensor([113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166])\n",
      "interval: tensor([8.8200, 8.8400])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.8400, 8.8600])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.8600, 8.8800])\n",
      "spikes: tensor([55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,\n",
      "        55, 55, 55, 55, 55, 55, 55, 55, 55, 55])\n",
      "interval: tensor([8.8800, 8.9000])\n",
      "spikes: tensor([27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27])\n",
      "interval: tensor([8.9000, 8.9200])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.9200, 8.9400])\n",
      "spikes: tensor([], dtype=torch.int64)\n",
      "interval: tensor([8.9400, 8.9600])\n",
      "spikes: tensor([43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
      "        43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
      "        43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
      "        43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
      "        43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
      "        43, 43, 43, 43, 43, 43, 43, 43, 43, 43])\n",
      "interval: tensor([8.9600, 8.9800])\n",
      "spikes: tensor([  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "          2,   2,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
      "         17,  17,  17,  17, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118,\n",
      "        118, 118, 118, 118, 118, 118,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177,\n",
      "        177, 177, 177, 177, 177, 177, 177, 177, 177, 177])\n",
      "interval: tensor([8.9800, 9.0000])\n",
      "spikes: tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
      "        38, 38])\n",
      "interval: tensor([9.0000, 9.0200])\n",
      "spikes: tensor([196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196])\n",
      "interval: tensor([9.0200, 9.0400])\n",
      "spikes: tensor([ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68,  68,  68,  68, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240, 240,\n",
      "        240, 240, 240, 240, 240, 240, 240, 240])\n",
      "interval: tensor([9.0400, 9.0600])\n",
      "spikes: tensor([  2,   2,   2,  ..., 234, 234, 234])\n",
      "interval: tensor([9.0600, 9.0800])\n",
      "spikes: tensor([143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196])\n",
      "interval: tensor([9.0800, 9.1000])\n",
      "spikes: tensor([ 90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,  90,\n",
      "         90,  90, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192,\n",
      "        192, 192, 192, 192, 192, 192, 192, 192, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196])\n",
      "interval: tensor([9.1000, 9.1200])\n",
      "spikes: tensor([ 27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196])\n",
      "interval: tensor([9.1200, 9.1400])\n",
      "spikes: tensor([ 30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
      "         30,  30,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
      "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "        232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232])\n",
      "interval: tensor([9.1400, 9.1600])\n",
      "spikes: tensor([142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142,\n",
      "        142, 142,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "         91,  91,  91,  91])\n",
      "interval: tensor([9.1600, 9.1800])\n",
      "spikes: tensor([129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129])\n",
      "interval: tensor([9.1800, 9.2000])\n",
      "spikes: tensor([129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143,\n",
      "        143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243,\n",
      "        243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243, 243])\n",
      "interval: tensor([9.2000, 9.2200])\n",
      "spikes: tensor([129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,\n",
      "        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
      "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129])\n",
      "interval: tensor([9.2200, 9.2400])\n",
      "spikes: tensor([ 27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
      "         27,  27, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129])\n",
      "interval: tensor([9.2400, 9.2600])\n",
      "spikes: tensor([ 92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,\n",
      "         92,  92, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248,\n",
      "        248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,\n",
      "        235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235])\n",
      "interval: tensor([9.2600, 9.2800])\n",
      "spikes: tensor([129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129,\n",
      "        129, 129, 129, 129, 129, 129, 129, 129, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247, 247,\n",
      "        247, 247, 247, 247, 247, 247, 247, 247, 247, 247])\n",
      "interval: tensor([9.2800, 9.3000])\n",
      "spikes: tensor([129, 129, 129,  ..., 186, 186, 186])\n",
      "interval: tensor([9.3000, 9.3200])\n",
      "spikes: tensor([113, 113, 113,  ..., 186, 186, 186])\n",
      "interval: tensor([9.3200, 9.3400])\n",
      "spikes: tensor([68, 68, 68,  ..., 38, 38, 38])\n",
      "interval: tensor([9.3400, 9.3600])\n",
      "spikes: tensor([147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171,\n",
      "        171, 171, 171, 171, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113])\n",
      "interval: tensor([9.3600, 9.3800])\n",
      "spikes: tensor([186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
      "         32,  32,  32,  32,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
      "         81,  81,  81,  81,  81,  81, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103])\n",
      "interval: tensor([9.3800, 9.4000])\n",
      "spikes: tensor([147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113,\n",
      "        113, 113, 113, 113, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147,\n",
      "        147, 147, 147, 147, 147, 147, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186,\n",
      "        186, 186, 186, 186, 186, 186, 186, 186])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1200286/2735014616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"spikes: {x['id'][1:len(x['id']) - x_pad]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# sleep for 1 second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "n = 0\n",
    "while n == 0:\n",
    "    x, y = next(iterable)\n",
    "    x_pad = x['pad']\n",
    "    print(f\"interval: {x['cid']}\")\n",
    "    print(f\"spikes: {x['id'][1:len(x['id']) - x_pad]}\")\n",
    "    # sleep for 1 second\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 120005)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1200286/387403440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_neuron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspikes_neuron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspikes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_neuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes_neuron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspikes_neuron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "n_neuron = 25\n",
    "spikes_neuron = spikes[n_neuron].replace(0, np.nan)\n",
    "x_axis = np.arange(0, len(spikes_neuron))\n",
    "plt.scatter(x_axis, spikes_neuron, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Function to load YAML configuration file\n",
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "# Use the function\n",
    "config_path = \"./configs/NF_1.5/mconf.yaml\"\n",
    "config = load_config(config_path)  # replace 'config.yaml' with your file path\n",
    "\n",
    "from neuroformer.utils import update_config\n",
    "\n",
    "# update config\n",
    "updated_config = update_config(config, modalities, tokenizer, x, y, 2)\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def dict_to_object(d):\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: dict_to_object(v) for k, v in d.items()})\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "updated_dict_object = dict_to_object(updated_config)\n",
    "\n",
    "config = updated_dict_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/30/2023 16:00:47 - INFO - neuroformer.model_neuroformer_2 -   number of parameters: 2.571268e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 5\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.model_neuroformer_2 import GPT, GPTConfig\n",
    "\n",
    "config = updated_dict_object\n",
    "config.id_vocab_size = tokenizer.ID_vocab_size\n",
    "\n",
    "\n",
    "model = GPT(config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_242518/4239367082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrecursive_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroformer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroformer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroformer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroformer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data5/antonis/neuroformer/neuroformer/DataUtils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0;31m## PREV ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_prev\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                     \u001b[0mid_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_id_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_prev_block_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_prev'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dt_prev'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# + 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data5/antonis/neuroformer/neuroformer/DataUtils.py\u001b[0m in \u001b[0;36mget_interval\u001b[0;34m(self, interval, trial, block_size, data, data_dict, n_stim, pad)\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0midx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frame_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0mneuron_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mtime_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0;31m# second dimension (interval) has to exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data5/antonis/neuroformer/neuroformer/DataUtils.py\u001b[0m in \u001b[0;36mget_interval\u001b[0;34m(self, interval, trial, block_size, data, data_dict, n_stim, pad)\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0midx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frame_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0mneuron_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mtime_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0;31m# second dimension (interval) has to exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroformer/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroformer/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y = next(iterable)\n",
    "\n",
    "recursive_print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[249, 250, 251,  ..., 251, 251, 251],\n",
       "        [249, 250, 251,  ..., 251, 251, 251]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 2500\n",
    "BATCH_SIZE = 8\n",
    "SHUFFLE = True\n",
    "CKPT_PATH = './models/Distance-Coding/first_run/'\n",
    "\n",
    "from neuroformer.trainer import TrainerConfig, Trainer\n",
    "\n",
    "tconf = TrainerConfig(max_epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, learning_rate=7e-5, \n",
    "                    num_workers=4, lr_decay=True, patience=3, warmup_tokens=8e7, \n",
    "                    decay_weights=True, weight_decay=1.0, shuffle=SHUFFLE,\n",
    "                    final_tokens=len(train_dataset)*(config.block_size.id) * (MAX_EPOCHS),\n",
    "                    clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                    show_grads=False,\n",
    "                    ckpt_path=CKPT_PATH, no_pbar=False, \n",
    "                    dist=DIST, save_every=2500)\n",
    "\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "# def my_collate_fn(batch):\n",
    "#     try:\n",
    "#         return default_collate(batch)\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"There was an error with collating the batch: {str(e)}\")\n",
    "#         for idx, item in enumerate(batch):\n",
    "#             print(f\"Item {idx}: {item}\")  # Or print whatever specific information you need\n",
    "#         raise e  # Re-raise the exception to stop the training\n",
    "\n",
    "\n",
    "# loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=my_collate_fn)\n",
    "# pbar = tqdm(loader, total=len(loader), colour='purple')\n",
    "# for x, y in pbar:\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_device(x, model.device)\n",
    "y = all_device(y, model.device)\n",
    "\n",
    "logits, features, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id torch.Size([2, 4000]) torch.int64\n",
      "dt torch.Size([2, 4000]) torch.int64\n",
      "modalities_distance_value torch.Size([2, 1]) torch.int64\n",
      "modalities_distance_dt torch.Size([2]) torch.float32\n",
      "id_ torch.Size([7998]) torch.int64\n",
      "dt_ torch.Size([7998]) torch.int64\n",
      "id_eos torch.Size([2]) torch.int64\n",
      "dt_eos torch.Size([2]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "recursive_print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/30000 [00:00<2:25:26,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/30000 [00:00<2:14:35,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/30000 [00:01<2:00:14,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/30000 [00:01<2:16:36,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/30000 [00:01<2:05:19,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/30000 [00:02<2:35:19,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/30000 [00:02<2:33:45,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/30000 [00:03<2:44:26,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/30000 [00:03<2:36:38,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/30000 [00:03<2:42:11,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.utils_2 import predict_modality\n",
    "\n",
    "behavior_preds = predict_modality(model, finetune_dataset, modality='distance', block_type='modalities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_spikes = spikes[:, :12000].reshape((spikes.shape[0], -1, spikes.shape[1] // 10))\n",
    "new_spikes = new_spikes.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 120005)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
