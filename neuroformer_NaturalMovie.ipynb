{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F6CeGQy9xVu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "from torch.utils import data\n",
        "\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "sys.path.append('../')\n",
        "sys.path.append(\"neuroformer\")\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as FeatureAlphaDropout\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from scipy import io as scipyio\n",
        "import skimage\n",
        "import skvideo.io\n",
        "\n",
        "from utils import *\n",
        "\n",
        "import os\n",
        "import glob\n",
        "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmB0YuTW-zdZ"
      },
      "outputs": [],
      "source": [
        "# set up logging\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIJX2fry_rAH"
      },
      "outputs": [],
      "source": [
        "from utils import set_seed\n",
        "set_seed(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U-Mr5sF_s-3",
        "outputId": "bbb0deae-6896-4c65-c0c4-6470bdd6ca46"
      },
      "outputs": [],
      "source": [
        "# R3D: (3 x T x H x W)\n",
        "\n",
        "from SpikeVidUtils import image_dataset\n",
        "\n",
        "train_path = \"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/SImNew3D/stimulus/tiff\"\n",
        "vid_list = [skimage.io.imread(vid) for vid in sorted(glob.glob(train_path + '/*.tif'))]\n",
        "print(glob.glob(train_path + '/*.tif')[::-1])\n",
        "video_stack = np.concatenate(vid_list, axis=0, dtype=np.float32)\n",
        "\n",
        "\n",
        "# video_stack = skimage.io.imread(\"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/OneCombo3/stimuli/Combined Stimuli 3-grating.tif\")\n",
        "# video_stack = image_dataset(video_stack)\n",
        "# video_stack = video_stack[::3]  # convert from 60 to 20 fps\n",
        "# video_stack = video_stack.view(1, video_stack.shape[0], video_stack.shape[1], video_stack.shape[2], video_stack.shape[3])\n",
        "\n",
        "video_stack = image_dataset(video_stack)\n",
        "video_stack = video_stack[::3]  # convert from 60 to 20 fps\n",
        "video_stack = video_stack.view(1, video_stack.shape[0], video_stack.shape[1], video_stack.shape[2], video_stack.shape[3])\n",
        "video_stack = torch.nan_to_num(video_stack)\n",
        "# # video_stack = video_stack.transpose(-1, -2)\n",
        "\n",
        "# rearrange(video_stack[0, 0:2].transpose(0,1), 'c t (h p1) (w p2) -> (t h w) (p1 p2 c)', p1=16, p2=16).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(video_stack[0, 1].permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRFtpwOs_0W4"
      },
      "outputs": [],
      "source": [
        "# spike_path = \"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/SImNew3D/neural/NatureMoviePart1-A\" # \"code/data/SImIm/simNeu_3D_WithNorm__Combo3.mat\" \n",
        "from SpikeVidUtils import trial_df_real\n",
        "\n",
        "spike_data = scipyio.loadmat(\"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/SImNew3D/neural/NatureMoviePart1-A/20-NatureMovie_part1-A_spikes(1).mat\")\n",
        "spike_data = trial_df_real(np.squeeze(spike_data['spiketrain']['st'].T, axis=-1))\n",
        "spike_data = spike_data[spike_data['Time'] > 0]\n",
        "\n",
        "vid_duration = [len(vid) * 1/60 for vid in vid_list]\n",
        "\n",
        "df = spike_data\n",
        "df['Time'] = df['Time'] * 0.1499\n",
        "current_time = 0\n",
        "for idx, trial in enumerate(df['Trial'].unique()):\n",
        "    df['Time'][df['Trial'] == trial] += current_time\n",
        "    current_time += vid_duration[idx]    # add duration of last clip\n",
        "# spike_df = pd.concat(spike_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_sim = pd.read_csv(\"data/full_sim__model_weighted_shuffle_decay_True_perceiver_2.0_dt_0.05_eos_8_8_256.csv\").iloc[1:, 1:].reset_index(drop=True)\n",
        "# df_sim = df_sim[df_sim['ID'] <= 164]\n",
        "# df_sim['Trial'] = df_sim['Trial'] + df['Trial'].max()\n",
        "# df = pd.concat([df, df_sim], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR7Vs-Pn_3oo"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(parent_path + \"code/data/OneCombo3/Combo3_all_stim.csv\")\n",
        "window = 0.25\n",
        "dt = 0.05\n",
        "\n",
        "from SpikeVidUtils import make_intervals\n",
        "\n",
        "df['Interval'] = make_intervals(df, window)\n",
        "# df['Interval_dt'] = make_intervals(df, dt)\n",
        "# df['Interval_dt'] = (df['Interval_dt'] - df['Interval'] + window).round(3)\n",
        "df = df.reset_index(drop=True)\n",
        "df = df[df['Time'] <= 2732]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwyX2t-z_44J"
      },
      "outputs": [],
      "source": [
        "# n_dt = sorted((df['Interval_dt'].unique()).round(2)) \n",
        "dt_range = int(window / dt) + 1  # add first / last interval for SOS / EOS'\n",
        "n_dt = [round(dt * n, 2) for n in range(dt_range)]\n",
        "df['Time'] = df['Time'].round(3)\n",
        "print(n_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgNYdciA_5xo",
        "outputId": "9be97414-3f42-49e8-ebbf-b887cf2d221b"
      },
      "outputs": [],
      "source": [
        "# df.groupby(['Interval', 'Trial']).size().plot.bar()\n",
        "# df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
        "df.groupby(['Interval', 'Trial']).size().nlargest(10)\n",
        "# df.groupby(['Interval', 'Trial']).size().median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd3P4ASE_7gy",
        "outputId": "3f834a76-ced6-4023-bd1b-8a420f7d0e2d"
      },
      "outputs": [],
      "source": [
        "from SpikeVidUtils import SpikeTimeVidData\n",
        "\n",
        "## qv-vae feats\n",
        "# frames = torch.load(parent_path + \"code/data/SImNew3D/stimulus/vq-vae_code_feats-24-05-4x4x4.pt\").numpy() + 2\n",
        "# frame_feats = torch.load(parent_path + \"code/data/SImNew3D/stimulus/vq-vae_embed_feats-24-05-4x4x4.pt\").numpy()\n",
        "# frame_block_size = frames.shape[-1] - 1\n",
        "\n",
        "## resnet3d feats\n",
        "frame_feats = video_stack.transpose(1, 2)\n",
        "\n",
        "frame_block_size = int((20 * 64 * 112) / (8 * 8))\n",
        "id_block_size = 120   # 95\n",
        "prev_id_block_size = id_block_size\n",
        "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
        "frame_memory = 20   # how many frames back does model see\n",
        "window = window\n",
        "\n",
        "neurons = sorted(list(set(df['ID'])))\n",
        "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
        "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
        "\n",
        "# translate neural embeddings to separate them from ID embeddings\n",
        "# frames = frames + [*id_stoi.keys()][-1] \n",
        "neurons = [i for i in range(df['ID'].min(), df['ID'].max() + 1)]\n",
        "# pixels = sorted(np.unique(frames).tolist())\n",
        "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
        "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
        "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
        "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
        "itos_dt = { i:ch for i,ch in enumerate(n_dt) }\n",
        "max(list(itos_dt.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ZJuUWTDpwk"
      },
      "outputs": [],
      "source": [
        "# train_len = round(len(df)*(4/5))\n",
        "# test_len = round(len(df) - train_len)\n",
        "\n",
        "# train_data = df[:train_len]\n",
        "# test_data = df[train_len:train_len + test_len].reset_index().drop(['index'], axis=1)\n",
        "\n",
        "n = [7]\n",
        "train_data = df[~df['Trial'].isin(n)].reset_index(drop=True)\n",
        "test_data = df[df['Trial'].isin(n)].reset_index(drop=True)\n",
        "small_data = df[df['Trial'].isin([7])].reset_index(drop=True)\n",
        "small_data = small_data[small_data['Interval'].isin(small_data['Interval'].unique()[:100])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luwjZJiBDuJV",
        "outputId": "46a1af29-90f1-4d64-c785-f35316d319cd"
      },
      "outputs": [],
      "source": [
        "from SpikeVidUtils import SpikeTimeVidData2\n",
        "\n",
        "# train_dat1aset = spikeTimeData(spikes, block_size, dt, stoi, itos)\n",
        "\n",
        "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "# dataset = SpikeTimeVidData(df, frames, frame_feats, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos)\n",
        "# single_batch = SpikeTimeVidData(df[df['Trial'].isin([5])], None, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats)\n",
        "small_dataset = SpikeTimeVidData2(small_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
        "\n",
        "\n",
        "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iterable = iter(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = next(iterable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id_prev'][:len(x['id_prev']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id'][:len(x['id']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y['id'][:len(y['id']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y['dt'][:len(y['id']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id'].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id'].size() == x['id_prev'].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id_prev'].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYyJLHClVS5M"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(dataset):\n",
        "  dt = []\n",
        "  id = []\n",
        "  for x, y in dataset:\n",
        "    id.extend([stoi['SOS']] + y['id'][:len(y['id']) - x['pad']].flatten().tolist() + [stoi['PAD']]) # -1 in pad to include PAD token\n",
        "    dt.extend([stoi_dt[0]] + y['dt'][:len(y['dt']) - x['pad']].flatten().tolist() + [dataset.dt_max]) # -1 in pad to include PAD token\n",
        "\n",
        "  id = pd.DataFrame(id)\n",
        "  dt = pd.DataFrame(dt)\n",
        "\n",
        "  id_freq = id.groupby([0]).size()\n",
        "  dt_freq = dt.groupby([0]).size()\n",
        "\n",
        "  id_ones = np.ones(dataset.id_population_size)\n",
        "  dt_ones = np.ones(dataset.dt_population_size)\n",
        "\n",
        "  id_ones[id_freq.index] = (1 / id_freq) * id_freq.max() / id_freq.max()\n",
        "  dt_ones[dt_freq.index] = (1 / dt_freq) * dt_freq.max() / dt_freq.max()\n",
        "  \n",
        "  class_freq = dict()\n",
        "  class_freq['id'] = torch.tensor(id_ones, dtype=torch.float32)\n",
        "  class_freq['dt'] = torch.tensor(dt_ones, dtype=torch.float32)\n",
        "  \n",
        "  return class_freq \n",
        "\n",
        "class_weights = get_class_weights(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTLKWWrqDyDd",
        "outputId": "7f7fdeff-145f-4412-ed24-6662db6ff997"
      },
      "outputs": [],
      "source": [
        "from model_neuroformer import GPT, GPTConfig, neuralGPTConfig, Decoder\n",
        "# initialize config class and model (holds hyperparameters)\n",
        "mconf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
        "                        id_vocab_size=train_dataset.id_population_size,\n",
        "                        frame_block_size=frame_block_size,\n",
        "                        id_block_size=id_block_size,  # frame_block_size\n",
        "                        prev_id_block_size=prev_id_block_size,\n",
        "                        sparse_mask=False, p_sparse=0.25, sparse_topk_frame=50, sparse_topk_id=id_block_size // 5,\n",
        "                        n_dt=len(n_dt),\n",
        "                        data_size=train_dataset.size,\n",
        "                        class_weights=class_weights,\n",
        "                        pretrain=False,\n",
        "                        n_state_layers=4, n_state_history_layers=4, n_stimulus_layers=6,\n",
        "                        n_layer=10, n_head=4, n_embd=64,\n",
        "                        temp_emb=True, pos_emb=True,\n",
        "                        id_drop=0.2, im_drop=0.2)\n",
        "model = GPT(mconf)\n",
        "model.load_state_dict(torch.load(\"/home/antonis/projects/slab/git/neuroformer/models/tensorboard/natural_stim/sparse_diagmaskmix_neuroformer_nopad_unweighted:dt_:True_perceiver_1.0_0.05_(4, 4, 6)_4_64.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H0AqcZLqxBH",
        "outputId": "2ce22b00-a8b7-4b49-b846-42066ade9266"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/slab/models/OneCombo3/model_8_4_256.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlY4cxbxVrN4"
      },
      "outputs": [],
      "source": [
        "# loader = DataLoader(small_dataset, shuffle=False, pin_memory=False,\n",
        "#                                   batch_size=1, num_workers=1)\n",
        "# x, y = next(iter(loader))\n",
        "# model = model.to('cpu')\n",
        "\n",
        "# preds, features, loss = model(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tensor(611.5000, device='cuda:0', dtype=torch.float16) tensor(1, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_Lm4vumDzfM",
        "outputId": "e956c2e8-a6ed-4e55-9253-df310e4b763c"
      },
      "outputs": [],
      "source": [
        "from trainer import Trainer, TrainerConfig\n",
        "# model.load_state_dict(torch.load(parent_path +  \"code/transformer_vid3/runs/models/12-01-21-14:18-e:19-b:239-l:4-h:2-ne:512-higher_order.pt\"))\n",
        "# model.load_state_dict(torch.load(parent_path +  \"code/transformer_vid3/runs/models/12-14-21-23:44-e:17-b:650-l:8-h:4-ne:256-higher_order.pt\"))\n",
        "\n",
        "\n",
        "\n",
        "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)\n",
        "max_epochs = 2500\n",
        "batch_size = 32 * 2\n",
        "shuffle = True\n",
        "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=7e-5, \n",
        "                      num_workers=4, lr_decay=True, patience=3, warmup_tokens=8e0, \n",
        "                      decay_weights=True, shuffle=shuffle,\n",
        "                      final_tokens=len(train_dataset)*(id_block_size) * (max_epochs),\n",
        "                      clip_norm=1.0, grad_norm_clip=1.0,\n",
        "                      dataset='higher_order', mode='predict',\n",
        "                      block_size=train_dataset.block_size,\n",
        "                      id_block_size=train_dataset.id_block_size,\n",
        "                      show_grads=False, plot_raster=False,\n",
        "                      ckpt_path=f\"/home/antonis/projects/slab/git/neuroformer/models/tensorboard/natural_stim/sparse_diagmaskmix_neuroformer_nopad_unweighted:dt_:{shuffle}_perceiver_1.0_{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\")\n",
        "# f\"/home/antonis/projects/slab/git/neuroformer/models/model_sim_weighted_shuffle_decay:{shuffle}_perceiver_2.0_dt:{dt}_eos_{mconf.n_layer}_{mconf.n_head}_{mconf.n_embd}.pt\")\n",
        "\n",
        "trainer = Trainer(model, train_dataset, test_dataset, tconf, mconf)\n",
        "trainer.train()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bug_df = df[(df['Interval'].isin([610.5, 611, 611.5]) & df['Trial'].isin([1]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bug_dataset = SpikeTimeVidData2(bug_df, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = DataLoader(test_dataset, shuffle=False, pin_memory=False,\n",
        "                                  batch_size=32*2, num_workers=1)                   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iterable = iter(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = next(iterable)\n",
        "model.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['interval']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(x['interval'], x['trial'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds, features, loss = model(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id_prev']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id'][..., :len(x['id']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y['id'][..., :len(y['id']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y['dt'][..., :len(x['id']) - x['pad']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_int = float(x['interval'])\n",
        "train_data[(train_data['Interval'].isin([dt_int - 0.5, dt_int])) & (train_data['Trial'] == x['trial'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['interval']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['trial'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x['id_prev']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def return_att(att_mod):\n",
        "    return att_mod.att.shape\n",
        "\n",
        "return_att(model.neural_visual_transformer.neural_state_block[0].attn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(torch.sum(model.neural_visual_transformer.neural_state_block[0].attn.att, axis=1) / 8).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXZQ45pGTyMx",
        "outputId": "443d95df-c2f4-404d-a43e-8b430c9ecd0b"
      },
      "outputs": [],
      "source": [
        "\"\"\" Predict using TEST dataset \"\"\"\n",
        "\n",
        "from utils import predict_raster, predict_raster_resnet, predict_raster_enc_dec, predict_raster_recursive, predict_beam_search, predict_raster_recursive_time, predict_raster_recursive_time_auto, predict_beam_search_time, predict_raster_hungarian\n",
        "from utils import set_plot_params\n",
        "set_plot_params()\n",
        "%matplotlib inline\n",
        "\n",
        "loader = DataLoader(small_dataset, shuffle=False, pin_memory=False,\n",
        "                                  batch_size=1, num_workers=1)\n",
        "\n",
        "# device = torch.cuda.current_device()\n",
        "# model = model.to(device)\n",
        "model.load_state_dict(torch.load(\"/home/antonis/projects/slab/git/neuroformer/models/tensorboard/natural_stim/sparse_diagmaskmix_neuroformer_nopad_unweighted:dt_:True_perceiver_1.0_0.05_(4, 4, 6)_4_64.pt\"))\n",
        "\n",
        "\"\"\" \n",
        "\n",
        "To predict only neurons we pass <frame_end> so we see predictions only for Neurons \n",
        "If you want to also see frame_tokens, just pass <frame_end=0>\n",
        "\n",
        "NOTE: 512 ID is the <end-of-sequence-id>. Right now, makes no difference if I include\n",
        "it in loss, here it is included in loss and predictions.\n",
        "\n",
        "\"\"\"\n",
        "# true, predicted, true_timing, predicted_timing = predict_time_raster(model, loader, \n",
        "#                                                                     f_block_sz=frame_block_size, id_block_sz=frame_block_size, \n",
        "#                                                                     get_dt=True)\n",
        "\n",
        "# true, predicted, true_timing, predicted_timing = predict_time_raster(model, loader, \n",
        "#                                                                     f_block_sz=frame_block_size, id_block_sz=frame_block_size,\n",
        "#                                                                     get_dt=True)\n",
        "\n",
        "# true, predicted = predict_raster(model, loader)\n",
        "\n",
        "# true, predicted = predict_beam_search(model, loader, stoi, frame_end=0)\n",
        "# true, predicted, true_timing = predict_raster_recursive(model, loader, stoi, sample=True, top_p=0.95, gpu=True, frame_end=0)\n",
        "results = predict_raster_recursive_time_auto(model, loader, window, stoi, itos_dt, sample=True, top_p=0.95, top_p_t=0.95, temp=1.0, temp_t=1.0, frame_end=0, get_dt=True, gpu=True)\n",
        "\n",
        "# true, predicted = predict_raster_hungarian(model, loader)\n",
        "# true, predicted = predict_raster(model, loader, gpu=True)\n",
        "\n",
        "# true_df = pd.DataFrame(true.numpy())\n",
        "# predicted_df = pd.DataFrame(predicted.numpy())\n",
        "# print(len(true_df[true_df[0] == 512]), len(predicted_df[predicted_df[0] == 512])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results = predict_raster_recursive_time_auto(model, loader, window, stoi, itos_dt, sample=True, top_p=0.95, top_p_t=0.95, frame_end=0, get_dt=True, gpu=False)\n",
        "\n",
        "pred_keys = ['pred', 'time_pred', 'trial', 'interval']\n",
        "predicted_dict = {k: results[k] for k in results if k in pred_keys}\n",
        "df_pred = pd.DataFrame(predicted_dict)\n",
        "df_pred.rename({'pred':'ID', 'time_pred':'dt', 'trial':'Trial'}, axis=1, inplace=True)\n",
        "df_pred['Time'] = df_pred['dt'] + df_pred['interval'] - 0.5\n",
        "\n",
        "# df_pred = df_pred[df_pred['ID'] < stoi['SOS']]\n",
        "# df_true['time'] = df_true['dt'] + df_true['interval'] - 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "true_keys = ['true', 'time']\n",
        "true_dict = {k: results[k] for k in results if k in true_keys}\n",
        "df_true = pd.DataFrame(true_dict)\n",
        "df_true.rename({'true':'ID', 'time':'dt'}, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kejTrZ1_2u8T"
      },
      "outputs": [],
      "source": [
        "# # predicted_timing = [itos_dt[int(dt)] for dt in predicted_timing]\n",
        "# # df_pred = pd.DataFrame({'True':true, 'Predicted':predicted, 'Time':true_timing, 'Predicted_Time':predicted_timing})    # Time':test_data['Time']})\n",
        "# df_pred.to_csv(f\"/content/drive/MyDrive/slab/predictions/OneCombo3/model_weighted_shuffle:{shuffle}_perceiver_2.0_dt:{dt}_eos_{mconf.n_layer}_{mconf.n_head}_{mconf.n_embd}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_sim = pd.read_csv(\"/home/antonis/projects/slab/git/neuroformer/data/full_sim__model_weighted_shuffle_decay_True_perceiver_2.0_dt_0.05_eos_8_8_256.csv\").iloc[:,1:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(df_true), len(df_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_true[df_true['dt'] == 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred[df_pred['ID'] == 166][:30].groupby('dt').size().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data[:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freq_dt_true = df_true.groupby(['dt']).size()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pred[30:2 * 30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_true[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_dt = [y['dt'][:len(y['dt']) - (x['pad'])] for x, y in test_dataset]\n",
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "# df_dt = df_true['time']\n",
        "freq_dt_true = df_true.groupby(['dt']).size()\n",
        "# freq_dt_true = df_sim.groupby(['dt']).size()\n",
        "plt.bar(np.arange(len(freq_dt_true.index)), freq_dt_true, alpha=0.5, label='True')\n",
        "\n",
        "\n",
        "# df_dt_pred = df_pred['time_pred']\n",
        "freq_dt_pred = df_pred.groupby(['dt']).size()\n",
        "plt.bar(np.arange(len(freq_dt_pred.index)), freq_dt_pred, alpha=0.5, label='Predicted')\n",
        "\n",
        "\n",
        "# plt.xticks(ticks=pd.to_numeric(freq_dt_pred.index)labels=pd.to_numeric(freq_dt_pred.index))\n",
        "plt.title('dt Interval Groups')\n",
        "plt.xlabel('dt Group (n x 0.05s)')\n",
        "plt.ylabel('Count (N)')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig(\"dt_interval_dist.png\", dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(df_pred), len(df_true))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_distribution(df_1, df_2):\n",
        "    plt.figure(figsize=(30,20))\n",
        "    n_min = 166\n",
        "    freq_true = df_1[df_1['ID'] < n_min].groupby(['ID']).size()\n",
        "    freq_pred = df_2[df_2['ID'] < n_min].groupby(['ID']).size()\n",
        "    plt.bar(freq_pred.index, freq_pred, label='predicted', alpha=0.5)\n",
        "    plt.bar(freq_true.index, freq_true, label='true', alpha=0.5)\n",
        "    plt.title('Neuron Firing Distribution', fontsize=40)\n",
        "    plt.legend(fontsize=30)\n",
        "    plt.xlabel('Neuron ID (n)', fontsize=30)\n",
        "    plt.ylabel('Count (N)', fontsize=30)\n",
        "    plt.xticks(fontsize=30)\n",
        "    plt.yticks(fontsize=30)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_distribution(df_true, df_pred)\n",
        "# plt.savefig(\"id_interval_dist.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len_pred = len(df_true)\n",
        "# len_pred = 1000\n",
        "plt.figure(figsize=(40,40))\n",
        "plt.title('Pixel / Spike Raster', size=50)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Neuron ID')\n",
        "plt.scatter(small_data['Time'], small_data['ID'], alpha=0.6, label='true', marker='o')\n",
        "plt.scatter(df_pred['Time'][1:], df_pred['ID'][1:], alpha=0.6, label='predicted', marker='x')\n",
        "plt.legend(fontsize=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len_pred = len(df_true)\n",
        "# len_pred = 1000\n",
        "plt.figure(figsize=(40,40))\n",
        "plt.title('Pixel / Spike Raster', size=50)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Neuron ID')\n",
        "plt.scatter(test_data['Time'], test_data['ID'], alpha=0.6, label='true', marker='o')\n",
        "plt.scatter(df_pred['Time'], df_pred['ID'], alpha=0.6, label='predicted', marker='x')\n",
        "plt.legend(fontsize=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transformer_vid3_dt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
