{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/neuroformer/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/neuroformer/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libjpeg.so.8: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from trainer import Trainer, TrainerConfig\n",
    "from utils import set_seed\n",
    "\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from utils import print_full\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from visualize import *\n",
    "set_plot_params()\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "\n",
    "from model_neuroformer import GPT, GPTConfig, neuralGPTConfig\n",
    "from trainer import Trainer, TrainerConfig\n",
    "\n",
    "\n",
    "import json\n",
    "# for i in {1..10}; do python3 -m gather_atts.py; done\n",
    "\n",
    "# set os cuda device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/VisNav_VR_Expt\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading data...\")\n",
    "    import gdown\n",
    "    url = \"https://drive.google.com/drive/folders/117S-7NmbgrqjmjZ4QTNgoa-mx8R_yUso?usp=sharing\"\n",
    "    gdown.download_folder(id=url, quiet=False, use_cookies=False, output=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config files\n",
    "import yaml\n",
    "\n",
    "base_path = \"./configs/visnav\"\n",
    "\n",
    "with open(os.path.join(base_path, 'mconf.yaml'), 'r') as stream:\n",
    "    mconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'tconf.yaml'), 'r') as stream:\n",
    "    tconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'dconf.yaml'), 'r') as stream:\n",
    "    dconf = yaml.full_load(stream)\n",
    "\n",
    "import omegaconf\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# open yaml as omegacong\n",
    "mconf = OmegaConf.create(mconf)\n",
    "tconf = OmegaConf.create(tconf)\n",
    "dconf = OmegaConf.create(dconf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eyerad', 'phi', 'speed', 'spiketimes', 't', 'th', 'vid_sm'])\n"
     ]
    }
   ],
   "source": [
    "import mat73\n",
    "\n",
    "data_path = \"data/VisNav_VR_Expt/experiment_data.mat\"\n",
    "data = mat73.loadmat(data_path)['neuroformer']\n",
    "\n",
    "stimulus = data['vid_sm']\n",
    "response = data['spiketimes']['spks']\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import trial_df, get_df_visnav\n",
    "\n",
    "df = get_df_visnav(response)\n",
    "\n",
    "behavior_vars = ['t', 'eyerad', 'phi', 'speed', 'th']\n",
    "behavior = pd.DataFrame({k: data[k] for k in behavior_vars})\n",
    "\n",
    "# rename t to time\n",
    "behavior = behavior.rename(columns={'t': 'Time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>eyerad</th>\n",
       "      <th>phi</th>\n",
       "      <th>speed</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.861233</td>\n",
       "      <td>0.824016</td>\n",
       "      <td>1.740320</td>\n",
       "      <td>0.349926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.861233</td>\n",
       "      <td>0.824016</td>\n",
       "      <td>1.778366</td>\n",
       "      <td>0.349926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.558082</td>\n",
       "      <td>0.906881</td>\n",
       "      <td>1.703803</td>\n",
       "      <td>0.175581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.440854</td>\n",
       "      <td>1.964517</td>\n",
       "      <td>1.721167</td>\n",
       "      <td>0.216280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.268716</td>\n",
       "      <td>2.772023</td>\n",
       "      <td>1.430982</td>\n",
       "      <td>0.183940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32610</th>\n",
       "      <td>1630.50</td>\n",
       "      <td>0.701991</td>\n",
       "      <td>1.705420</td>\n",
       "      <td>-1.049336</td>\n",
       "      <td>2.298774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32611</th>\n",
       "      <td>1630.55</td>\n",
       "      <td>0.626503</td>\n",
       "      <td>2.255591</td>\n",
       "      <td>-1.107073</td>\n",
       "      <td>2.186725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32612</th>\n",
       "      <td>1630.60</td>\n",
       "      <td>0.518336</td>\n",
       "      <td>3.049515</td>\n",
       "      <td>-1.139765</td>\n",
       "      <td>2.042599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32613</th>\n",
       "      <td>1630.65</td>\n",
       "      <td>0.372313</td>\n",
       "      <td>1.927352</td>\n",
       "      <td>-1.163798</td>\n",
       "      <td>1.988948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32614</th>\n",
       "      <td>1630.70</td>\n",
       "      <td>0.214475</td>\n",
       "      <td>0.535680</td>\n",
       "      <td>-1.218695</td>\n",
       "      <td>1.890057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32615 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time    eyerad       phi     speed        th\n",
       "0         0.00 -1.861233  0.824016  1.740320  0.349926\n",
       "1         0.05 -1.861233  0.824016  1.778366  0.349926\n",
       "2         0.10 -1.558082  0.906881  1.703803  0.175581\n",
       "3         0.15 -1.440854  1.964517  1.721167  0.216280\n",
       "4         0.20 -0.268716  2.772023  1.430982  0.183940\n",
       "...        ...       ...       ...       ...       ...\n",
       "32610  1630.50  0.701991  1.705420 -1.049336  2.298774\n",
       "32611  1630.55  0.626503  2.255591 -1.107073  2.186725\n",
       "32612  1630.60  0.518336  3.049515 -1.139765  2.042599\n",
       "32613  1630.65  0.372313  1.927352 -1.163798  1.988948\n",
       "32614  1630.70  0.214475  0.535680 -1.218695  1.890057\n",
       "\n",
       "[32615 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017837</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019413</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022265</td>\n",
       "      <td>1321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026705</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030869</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614196</th>\n",
       "      <td>1630.671644</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614197</th>\n",
       "      <td>1630.676900</td>\n",
       "      <td>2088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614198</th>\n",
       "      <td>1630.679834</td>\n",
       "      <td>1634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614199</th>\n",
       "      <td>1630.683086</td>\n",
       "      <td>1227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614200</th>\n",
       "      <td>1630.686526</td>\n",
       "      <td>2193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time    ID  Trial\n",
       "0          0.017837   455      0\n",
       "1          0.019413   135      0\n",
       "2          0.022265  1321      0\n",
       "3          0.026705  1498      0\n",
       "4          0.030869   262      0\n",
       "...             ...   ...    ...\n",
       "614196  1630.671644  1151      0\n",
       "614197  1630.676900  2088      0\n",
       "614198  1630.679834  1634      0\n",
       "614199  1630.683086  1227      0\n",
       "614200  1630.686526  2193      0\n",
       "\n",
       "[614201 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_window = 0.5\n",
    "window = 0.05\n",
    "window_prev = 0.5\n",
    "window_behavior = window + window_prev\n",
    "dt = 0.01\n",
    "dt_frames = 0.05\n",
    "dt_vars = 0.05\n",
    "intervals = None\n",
    "\n",
    "from SpikeVidUtils import make_intervals\n",
    "\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['real_interval'] = make_intervals(df, 0.05)\n",
    "df['Interval_2'] = make_intervals(df, window_prev)\n",
    "df = df.reset_index(drop=True)\n",
    "behavior['Interval'] = make_intervals(behavior, window)\n",
    "behavior['Interval_2'] = make_intervals(behavior, window_prev)\n",
    "\n",
    "# n_dt = sorted((df['Interval_dt'].unique()).round(2)) \n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1  # add first / last interval for SOS / EOS'\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)] + ['EOS'] + ['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# int_trials = df.groupby(['Interval', 'Trial']).size()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(int_trials.mean())\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# df.groupby(['Interval', 'Trial']).agg(['nunique'])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# var_group = 'Interval_2'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# n_unique = len(df.groupby([var_group, 'Trial']).size())\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mInterval\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mTrial\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39msize()\u001b[39m.\u001b[39msort_values(ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mnlargest(\u001b[39mint\u001b[39m(\u001b[39m0.05\u001b[39m \u001b[39m*\u001b[39m n_unique))\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8403\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8404\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8405\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8406\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8407\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8408\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8409\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8410\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[1;32m   8411\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8412\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8413\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    966\u001b[0m         obj,\n\u001b[1;32m    967\u001b[0m         keys,\n\u001b[1;32m    968\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    969\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    970\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    971\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    972\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    973\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    976\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/opt/conda/envs/neuroformer/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Interval'"
     ]
    }
   ],
   "source": [
    "# int_trials = df.groupby(['Interval', 'Trial']).size()\n",
    "# print(int_trials.mean())\n",
    "# df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
    "# var_group = 'Interval_2'\n",
    "# n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "df.groupby(['Interval', 'Trial']).size().sort_values(ascending=False).nlargest(int(0.05 * n_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32615"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "## resnet3d feats\n",
    "kernel_size = (2, 5, 5)\n",
    "n_embd = 256\n",
    "n_embd_frames = 64\n",
    "frame_feats = stimulus\n",
    "\n",
    "frame_block_size = ((20 // kernel_size[0] * 64 * 112) // (n_embd_frames))\n",
    "frame_feats = torch.tensor(stimulus, dtype=torch.float32)\n",
    "conv_layer = True\n",
    "\n",
    "assert (window + window_prev) % dt_vars < 1e-5, \"window + window_prev must be divisible by dt_vars\"\n",
    "samples_per_behavior = int((window + window_prev) // dt_vars)\n",
    "behavior_block_size = int((window + window_prev) // dt_vars) * (len(behavior.columns) - 1)\n",
    "\n",
    "prev_id_block_size = 500\n",
    "id_block_size = 100   #\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size\n",
    "frame_memory = frame_window // dt_frames\n",
    "window = window\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "trial_tokens = [f\"Trial {n}\" for n in df['Trial'].unique()]\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_split = 0.8\n",
    "duration = df['Interval'].max()\n",
    "train_time = duration * r_split\n",
    "train_data = df[df['Interval'] <= train_time]\n",
    "test_data = df[df['Interval'] > train_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 461921 Neurons: 2204\n",
      "id block size: 100\n",
      "frames: 1120, id: 100\n",
      "Length: 152280 Neurons: 2204\n",
      "id block size: 100\n",
      "frames: 1120, id: 100\n",
      "train: 26080, test: 6523\n"
     ]
    }
   ],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                  dt_frames=dt_frames, intervals=intervals, dataset='visnav',\n",
    "                                  behavior=behavior, dt_vars=dt_vars, \n",
    "                                  behavior_block_size=behavior_block_size, samples_per_behavior=samples_per_behavior,\n",
    "                                  window_behavior=window_behavior)\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                 window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                                 pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                 dt_frames=dt_frames, intervals=intervals, dataset='visnav',\n",
    "                                 behavior=behavior)\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 11, 1]) torch.Size([2, 11])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iterable)\n",
    "print(x['behavior'].shape, x['behavior_dt'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_prev torch.Size([2, 500])\n",
      "dt_prev torch.Size([2, 500])\n",
      "pad_prev torch.Size([2])\n",
      "id torch.Size([2, 100])\n",
      "dt torch.Size([2, 100])\n",
      "pad torch.Size([2])\n",
      "interval torch.Size([2])\n",
      "trial torch.Size([2])\n",
      "behavior torch.Size([2, 6, 11, 1])\n",
      "behavior_dt torch.Size([2, 11])\n",
      "frames torch.Size([2, 1, 10, 30, 100])\n",
      "cid torch.Size([2, 2])\n",
      "pid torch.Size([2, 2])\n",
      "f_idx torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "for key in x.keys():\n",
    "    print(key, x[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286720\n",
      "256 53\n"
     ]
    }
   ],
   "source": [
    "from model_neuroformer import GPT, GPTConfig\n",
    "\n",
    "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)   \n",
    "max_epochs = 300\n",
    "batch_size = round((2))\n",
    "shuffle = True\n",
    "\n",
    "title =  f'window:{window}_prev:{window_prev}_smooth'\n",
    "\n",
    "model_path = f\"\"\"./models/tensorboard/visnav/first/{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\n",
    "\n",
    "model_conf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                        id_vocab_size=train_dataset.id_population_size,\n",
    "                        frame_block_size=frame_block_size,\n",
    "                        id_block_size=id_block_size,  # frame_block_size\n",
    "                        prev_id_block_size=prev_id_block_size,\n",
    "                        behavior_block_size=behavior_block_size,\n",
    "                        sparse_mask=False, p_sparse=None, \n",
    "                        sparse_topk_frame=None, sparse_topk_id=None, sparse_topk_prev_id=None,\n",
    "                        n_dt=len(n_dt),\n",
    "                        data_size=train_dataset.size,\n",
    "                        class_weights=None,\n",
    "                        pretrain=False,\n",
    "                        n_state_layers=mconf.n_state_layers, n_state_history_layers=mconf.n_state_history_layers,\n",
    "                        n_stimulus_layers=mconf.n_stimulus_layers, self_att_layers=mconf.self_att_layers,\n",
    "                        n_behavior_layers=mconf.n_behavior_layers,\n",
    "                        n_head=mconf.n_head, n_embd=mconf.n_embd, \n",
    "                        contrastive=True, clip_emb=1024, clip_temp=0.5,\n",
    "                        conv_layer=conv_layer, kernel_size=kernel_size,\n",
    "                        temp_emb=True, pos_emb=False,\n",
    "                        id_drop=0.35, im_drop=0.35,\n",
    "                        window=window, window_prev=window_prev, frame_window=frame_window, dt=dt,\n",
    "                        neurons=neurons, stoi_dt=stoi_dt, itos_dt=itos_dt, n_embd_frames=n_embd_frames,\n",
    "                        ignore_index_id=stoi['PAD'], ignore_index_dt=stoi_dt['PAD'])  # 0.35\n",
    "\n",
    "model = GPT(model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=1e-4, \n",
    "                    num_workers=4, lr_decay=False, patience=3, warmup_tokens=8e7, \n",
    "                    decay_weights=True, weight_decay=0.2, shuffle=shuffle,\n",
    "                    final_tokens=len(train_dataset)*(id_block_size) * (max_epochs),\n",
    "                    clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                    dataset='higher_order', mode='predict',\n",
    "                    block_size=train_dataset.block_size,\n",
    "                    id_block_size=train_dataset.id_block_size,\n",
    "                    show_grads=False, plot_raster=False,\n",
    "                    ckpt_path=model_path, no_pbar=False, \n",
    "                    dist=True, save_every=1000)\n",
    "\n",
    "# trainer = Trainer(model, train_dataset, test_dataset, tconf, model_conf)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_int_min = test_data['Interval'].min()\n",
    "test_int_max = test_data['Interval'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict_raster_recursive_time_auto\n",
    "\n",
    "results_dict = dict()\n",
    "df_pred = None\n",
    "df_true = None\n",
    "\n",
    "top_p = 0.75\n",
    "top_p_t = 0.75\n",
    "temp = 1.2\n",
    "temp_t = 1.2\n",
    "\n",
    "# with io.capture_output() a\n",
    "#s captured:\n",
    "print(f\"Trial: {trial}\")\n",
    "df_trial = df[(df['interval'] > test_int_min) & (df['interval'] < test_int_min + 100)]\n",
    "trial_dataset = SpikeTimeVidData2(df_trial,  None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                            window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                            pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                            dt_frames=dt_frames, intervals=intervals)\n",
    "trial_loader = DataLoader(trial_dataset, shuffle=False, pin_memory=False)\n",
    "results_trial = predict_raster_recursive_time_auto(model, trial_dataset, window, window_prev, stoi, itos_dt, itos=itos, \n",
    "                                                    sample=True, top_p=top_p, top_p_t=top_p_t, temp=temp, temp_t=temp_t, \n",
    "                                                    frame_end=0, get_dt=True, gpu=False, pred_dt=True)\n",
    "# results_trial = predict_raster_hungarian(model, loader, itos_dt, top_p=0.75, temp=1)\n",
    "# print(f\"MAX ID ---- {sorted(results_trial['ID'].unique()[-10])}\")\n",
    "df_trial_pred, df_trial_true = process_predictions(results_trial, stoi, itos, window)\n",
    "print(f\"pred: {df_trial_pred.shape}, true: {df_trial_true.shape}\" )\n",
    "if df_pred is None:\n",
    "    df_pred = df_trial_pred\n",
    "    df_true = df_trial_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4878f327e989b61de6701446a3bf7b6f9ae7705c9c90fa2b4cdf5489a55bcfeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
