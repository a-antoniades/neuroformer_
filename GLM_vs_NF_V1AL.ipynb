{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import glob\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from neuroformer.model_neuroformer import GPT, GPTConfig, neuralGPTConfig\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import set_seed, update_object, check_common_attrs\n",
    "from neuroformer.visualize import set_plot_params, set_plot_white\n",
    "from neuroformer.SpikeVidUtils import round_n, set_intervals\n",
    "set_plot_params()\n",
    "set_plot_white()\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_trials(df_glm, t_data, key='raw_interval'):\n",
    "    for i, trial in enumerate(t_data['Trial'].unique()):\n",
    "        start_interval = t_data[t_data['Trial'] == trial][key].min()\n",
    "        end_interval = t_data[t_data['Trial'] == trial][key].max()\n",
    "        # print(start_interval, end_interval, trial)\n",
    "        df_glm.loc[(df_glm[key] >= start_interval) & (df_glm[key] <= end_interval), 'Trial'] = trial\n",
    "    return df_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.SpikeVidUtils import create_full_trial\n",
    "from neuroformer.SpikeVidUtils import make_intervals\n",
    "from neuroformer.analysis import get_rates_trial, calc_corr_psth, get_accuracy, compute_scores\n",
    "\n",
    "DATASET = \"V1_AL\"\n",
    "T_BIN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/Combo3_V1AL/Combo3_V1AL_response.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df['Interval'] = make_intervals(df, T_BIN)\n",
    "\n",
    "pred_path = \"./data/Combo3_V1AL/glm_comparison/pred.csv\"\n",
    "df_pred = pd.read_csv(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_path = \"./data/Combo3_V1AL/combo3neuronGLM.mat\"\n",
    "mat = scipyio.loadmat(glm_path)\n",
    "df_glm = pd.DataFrame(mat['glmneuron'], columns=['Interval', 'ID', 'Trial']).reset_index(drop=True)\n",
    "df_glm['Time'] = df_glm['Interval']\n",
    "df_glm = df_glm.sort_values(by=['Trial', 'Interval']).reset_index(drop=True)\n",
    "df_glm = align_trials(df_glm, df_pred, key='Interval')\n",
    "df_glm['Interval'] = make_intervals(df_glm, T_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial ranges trial 0-20:(0 - 32), trial 20-40 (32 - 64), trial 40-60:(64 - 96)\n",
    "\n",
    "df['Interval'][df['Trial'] > 20] = df['Interval'][df['Trial'] > 20] + 32\n",
    "df_pred['Interval'][df_pred['Trial'] > 20] = df_pred['Interval'][df_pred['Trial'] > 20] + 32\n",
    "df_glm['Interval'][df_glm['Trial'] > 20] = df_glm['Interval'][df_glm['Trial'] > 20] + 32\n",
    "\n",
    "df['Interval'][df['Trial'] > 40] = df['Interval'][df['Trial'] > 40] + 32\n",
    "df_pred['Interval'][df_pred['Trial'] > 40] = df_pred['Interval'][df_pred['Trial'] > 40] + 32\n",
    "df_glm['Interval'][df_glm['Trial'] > 40] = df_glm['Interval'][df_glm['Trial'] > 40] + 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glm = df_glm.sort_values(by=['Trial', 'Interval']).reset_index(drop=True)    \n",
    "print(df_glm['Trial'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = df_pred['Trial'].unique()\n",
    "n_1 = trials + 1\n",
    "n_2 = trials + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.SpikeVidUtils import create_full_trial\n",
    "\n",
    "df_pred = create_full_trial(df_pred, trials)\n",
    "df_1 = create_full_trial(df, trials)\n",
    "df_2 = create_full_trial(df, n_1)\n",
    "df_3 = create_full_trial(df, n_2)\n",
    "df_glm = create_full_trial(df_glm, trials)\n",
    "\n",
    "df_pred['Interval'] = make_intervals(df_pred, T_BIN)\n",
    "df_1['Interval'] = make_intervals(df_1, T_BIN)\n",
    "df_2['Interval'] = make_intervals(df_2, T_BIN)\n",
    "df_3['Interval'] = make_intervals(df_3, T_BIN)\n",
    "\n",
    "# trim everything to length L\n",
    "# L = 100\n",
    "# df_pred = df_pred.iloc[:L]\n",
    "# df_1 = df_1.iloc[:L]\n",
    "# df_2 = df_2.iloc[:L]\n",
    "# df_3 = df_3.iloc[:L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.analysis import compute_scores, compute_scores_scikit\n",
    "scores = compute_scores(df_1, df_pred)\n",
    "scores_scikit = compute_scores_scikit(df_1, df_pred)\n",
    "\n",
    "scores_glm = compute_scores(df_1, df_glm)\n",
    "scores_scikit_glm = compute_scores_scikit(df_1, df_glm)\n",
    "\n",
    "print(\"Scores\")\n",
    "print(\"Neuroformer\")\n",
    "print(scores)\n",
    "print(\"GLM\")\n",
    "print(scores_glm)\n",
    "\n",
    "print(\"Scores Scikit\")\n",
    "print(\"Neuroformer\")\n",
    "print(scores_scikit)\n",
    "print(\"GLM\")\n",
    "print(scores_scikit_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming your dataframes are named 'pred' and 'true'\n",
    "\n",
    "# Define the number of bins\n",
    "true = df_1\n",
    "pred = df_pred\n",
    "\n",
    "# Bin the 'Interval' values into classes\n",
    "pred['Interval_pred'] = pd.Categorical(pred['Interval']).codes\n",
    "true['Interval_true'] = pd.Categorical(true['Interval']).codes\n",
    "\n",
    "# Merge your dataframes on 'ID' and 'Trial' to align predictions with ground truth\n",
    "merged_df = pd.merge(pred, true, on=['ID', 'Trial'])\n",
    "\n",
    "# Then group by 'ID' and 'Trial'\n",
    "grouped = merged_df.groupby(['ID', 'Trial'])\n",
    "\n",
    "# Initialize lists to store results\n",
    "ids = []\n",
    "trials = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# For each group, calculate precision, recall, and F1 score\n",
    "for name, group in grouped:\n",
    "    id, trial = name\n",
    "    precision = precision_score(group['Interval_true'], group['Interval_pred'], average='micro')\n",
    "    recall = recall_score(group['Interval_true'], group['Interval_pred'], average='micro')\n",
    "    f1 = f1_score(group['Interval_true'], group['Interval_pred'], average='micro')\n",
    "    \n",
    "    ids.append(id)\n",
    "    trials.append(trial)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "\n",
    "# Create a results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'ID': ids,\n",
    "    'Trial': trials,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1': f1s\n",
    "})\n",
    "\n",
    "mean_results = results.mean()\n",
    "\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_full = df_pred\n",
    "\n",
    "window = 0.5\n",
    "window_prev = 0.5\n",
    "window_pred = 0.5\n",
    "labels = np.array([round(window_pred + window_pred*n, 2) for n in range(0, int(max(df_pred_full['Interval']) / window_pred))])\n",
    "\n",
    "df_1 = set_intervals(df_1, window, window_prev, window_pred)\n",
    "df_2 = set_intervals(df_2, window, window_prev, window_pred)\n",
    "df_3 = set_intervals(df_3, window, window_prev, window_pred)\n",
    "\n",
    "rates_pred = get_rates_trial(df_pred_full, labels)\n",
    "rates_1 = get_rates_trial(df_1, labels)\n",
    "rates_2 = get_rates_trial(df_2, labels)\n",
    "rates_3 = get_rates_trial(df_3, labels)\n",
    "rates_glm = get_rates_trial(df_glm, labels)\n",
    "\n",
    "neurons = df['ID'].unique()\n",
    "top_corr_pred = calc_corr_psth(rates_pred, rates_1, neurons=neurons)\n",
    "top_corr_real = calc_corr_psth(rates_1, rates_2, neurons=neurons)\n",
    "top_corr_real_2 = calc_corr_psth(rates_1, rates_3, neurons=neurons)\n",
    "top_corr_glm = calc_corr_psth(rates_glm, rates_1, neurons=neurons)\n",
    "\n",
    "# turn index into ID column\n",
    "top_corr_pred = top_corr_pred.reset_index()\n",
    "top_corr_real = top_corr_real.reset_index()\n",
    "top_corr_glm = top_corr_glm.reset_index()\n",
    "\n",
    "# rename columns\n",
    "top_corr_pred = top_corr_pred.rename(columns={'index': 'ID', 0: 'Correlation'})\n",
    "top_corr_real = top_corr_real.rename(columns={'index': 'ID', 0: 'Correlation'})\n",
    "top_corr_glm = top_corr_glm.rename(columns={'index': 'ID', 0: 'Correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # turn index into ID column\n",
    "# top_corr_pred = top_corr_pred.reset_index()\n",
    "# top_corr_real = top_corr_real.reset_index()\n",
    "# top_corr_glm = top_corr_glm.reset_index()\n",
    "\n",
    "# # rename columns\n",
    "# top_corr_pred = top_corr_pred.rename(columns={'index': 'ID', 0: 'Correlation'})\n",
    "# top_corr_real = top_corr_real.rename(columns={'index': 'ID', 0: 'Correlation'})\n",
    "# top_corr_glm = top_corr_glm.rename(columns={'index': 'ID', 0: 'Correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicate values in IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes on 'ID'\n",
    "merged_df = pd.merge(top_corr_pred, top_corr_glm, on=['ID'])\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(merged_df['pearson_r_y'], merged_df['pearson_r_x'], alpha=0.7)\n",
    "\n",
    "# Add a reference line (y=x) to show where the predicted correlation equals the true correlation\n",
    "plt.plot(\n",
    "    [merged_df['pearson_r_y'].min(), merged_df['pearson_r_y'].max()],\n",
    "    [merged_df['pearson_r_y'].min(), merged_df['pearson_r_y'].max()],\n",
    "    color='red', linestyle='--'\n",
    ")\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel('True Correlation')\n",
    "plt.ylabel('Predicted Correlation')\n",
    "plt.title('Predicted vs. True Correlation')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ids = top_corr_pred.sort_values(by=['pearson_r'], ascending=False).iloc[:10]\n",
    "print(top_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spikes for top 10 neurons\n",
    "trial_duration = 96\n",
    "n_intervals = int(trial_duration / window_pred)\n",
    "intervals = np.array([round(window_pred + window_pred*n, 2) for n in range(0, n_intervals)])\n",
    "\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_path = \"./data/Combo3_V1AL/combo3neuronGLM.mat\"\n",
    "mat = scipyio.loadmat(glm_path)\n",
    "df_glm = pd.DataFrame(mat['glmneuron'], columns=['Interval', 'ID', 'Trial']).reset_index(drop=True)\n",
    "df_glm['Time'] = df_glm['Interval']\n",
    "df_glm = df_glm.sort_values(by=['Trial', 'Interval']).reset_index(drop=True)\n",
    "df_glm = align_trials(df_glm, df_pred, key='Interval')\n",
    "df_glm['Interval'] = make_intervals(df_glm, T_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(20, 1, figsize=(10, 30), sharex=True)  # Create subplots with shared x-axis\n",
    "\n",
    "for i in range(0, 10):\n",
    "    neuron_id = top_ids.iloc[i]['ID']\n",
    "    neuron_pred = df_pred[df_pred['ID'] == neuron_id]\n",
    "    trials = neuron_pred['Trial'].unique()\n",
    "    neuron_true = df[(df['ID'] == neuron_id) & (df['Trial'].isin(trials))]\n",
    "    neuron_pred_times = neuron_pred['Time']\n",
    "    neuron_true_times = neuron_true['Time']\n",
    "    neuron_pred = neuron_pred.sort_values(by=['Time'])\n",
    "    neuron_true = neuron_true.sort_values(by=['Time'])\n",
    "    \n",
    "    # Predicted plot on top\n",
    "    axes[2*i].scatter(neuron_pred['Interval'], neuron_pred['Trial'], color='k', marker='|', label='Predicted')\n",
    "    axes[2*i].set_xlim([0, 96])  # Setting x limits\n",
    "    axes[2*i].set_ylabel('Trial', fontsize=13)\n",
    "    \n",
    "    # True plot at bottom\n",
    "    axes[2*i+1].scatter(neuron_true['Interval'], neuron_true['Trial'], color='r', marker='|', label='True')\n",
    "    axes[2*i+1].set_xlim([0, 96])  # Setting x limits\n",
    "    axes[2*i+1].set_ylabel('Trial', fontsize=13)\n",
    "\n",
    "plt.xlabel('Interval', fontsize=15)\n",
    "plt.suptitle('Neuron Spike Rasters', fontsize=20, y=0.91)  # Main title for all subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(30, 1, figsize=(10, 60), sharex=True)  # Create subplots with shared x-axis\n",
    "\n",
    "for i in range(0, 10):\n",
    "    neuron_id = top_ids.iloc[i]['ID']\n",
    "    neuron_pred = df_pred[df_pred['ID'] == neuron_id]\n",
    "    neuron_glm_pred = df_glm[df_glm['ID'] == neuron_id]\n",
    "    trials = neuron_pred['Trial'].unique()\n",
    "    neuron_true = df[(df['ID'] == neuron_id) & (df['Trial'].isin(trials))]\n",
    "    neuron_pred_times = neuron_pred['Time']\n",
    "    neuron_glm_pred_times = neuron_glm_pred['Time']\n",
    "    neuron_true_times = neuron_true['Time']\n",
    "    neuron_pred = neuron_pred.sort_values(by=['Time'])\n",
    "    neuron_glm_pred = neuron_glm_pred.sort_values(by=['Time'])\n",
    "    neuron_true = neuron_true.sort_values(by=['Time'])\n",
    "\n",
    "    # Predicted plot on top\n",
    "    axes[3*i].scatter(neuron_pred['Interval'], neuron_pred['Trial'], color='k', marker='|', label='Predicted')\n",
    "    axes[3*i].set_xlim([0, 100])  # Setting x limits\n",
    "    axes[3*i].set_ylabel('Trial', fontsize=13)\n",
    "    axes[3*i].set_yticks([])  # Disable ytick labels\n",
    "    axes[3*i].set_yticks(np.linspace(0, neuron_pred['Trial'].max(), 4))  # Keep 4 ticks on the y-axis\n",
    "\n",
    "    # True plot at bottom\n",
    "    axes[3*i+2].scatter(neuron_glm_pred['Interval'], neuron_glm_pred['Trial'], color='b', marker='|', label='GLM Predicted')\n",
    "    axes[3*i+2].set_xlim([0, 100])  # Setting x limits\n",
    "    axes[3*i+2].set_ylabel('Trial', fontsize=13)\n",
    "    axes[3*i+2].set_yticks([])  # Disable ytick labels\n",
    "    axes[3*i+2].set_yticks(np.linspace(0, neuron_glm_pred['Trial'].max(), 4))  # Keep 4 ticks on the y-axis\n",
    "\n",
    "    # GLM Predicted plot in the middle\n",
    "    axes[3*i+1].scatter(neuron_true['Interval'], neuron_true['Trial'], color='r', marker='|', label='True')\n",
    "    axes[3*i+1].set_xlim([0, 100])  # Setting x limits\n",
    "    axes[3*i+1].set_ylabel('Trial', fontsize=13)\n",
    "    axes[3*i+1].set_yticks([])  # Disable ytick labels\n",
    "    axes[3*i+1].set_yticks(np.linspace(0, neuron_true['Trial'].max(), 4))  # Keep 4 ticks on the y-axis\n",
    "\n",
    "    # Add overarching title\n",
    "    axes[3*i].set_title('Neuron ID: ' + str(neuron_id), fontsize=15, y=1.05)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "# disable all ytick labels\n",
    "for ax in axes:\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.xlabel('Interval', fontsize=15)\n",
    "plt.suptitle('Neuron Spike Rasters', fontsize=20, y=0.91)  # Main title for all subplots\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "for i in range(0, 10):\n",
    "    neuron_id = top_ids.iloc[i]['ID']\n",
    "    neuron_pred = df_pred[df_pred['ID'] == neuron_id]\n",
    "    trials = neuron_pred['Trial'].unique()\n",
    "    neuron_true = df[(df['ID'] == neuron_id) & (df['Trial'].isin(trials))]\n",
    "    neuron_pred_times = neuron_pred['Time']\n",
    "    neuron_true_times = neuron_true['Time']\n",
    "    neuron_pred = neuron_pred.sort_values(by=['Time'])\n",
    "    neuron_true = neuron_true.sort_values(by=['Time'])\n",
    "    plt.subplot(5, 2, i+1)  # Displaying 5 rows, 2 columns of plots.\n",
    "    plt.scatter(neuron_pred['Interval'], neuron_pred['Trial'], color='k', marker='|', label='Predicted')\n",
    "    plt.scatter(neuron_true['Interval'], neuron_true['Trial'], color='r', marker='|', label='True')\n",
    "    plt.title('Neuron ID: ' + str(neuron_id), fontsize=15)\n",
    "    plt.xlabel('Interval', fontsize=13)\n",
    "    plt.ylabel('Trial', fontsize=13)\n",
    "    plt.legend()\n",
    "plt.tight_layout()  # To ensure the subplots do not overlap\n",
    "plt.suptitle('Neuron Spike Rasters', fontsize=20, y=1.02)  # Main title for all subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i in range(0, 10):\n",
    "    neuron_id = top_ids.iloc[i]['ID']\n",
    "    neuron = df_pred[df_pred['ID'] == neuron_id]\n",
    "    neuron_times = neuron['Time']\n",
    "    neuron = neuron.sort_values(by=['Time'])\n",
    "    plt.subplot(5, 2, i+1)  # Displaying 5 rows, 2 columns of plots.\n",
    "    \n",
    "    # Define the number of bins to suit your data\n",
    "    plt.hist2d(neuron['Interval'], neuron['Trial'], bins=[100, 100], cmap='binary')\n",
    "    \n",
    "    plt.title('Neuron ID: ' + str(neuron_id), fontsize=15)\n",
    "    plt.xlabel('Interval', fontsize=13)\n",
    "    plt.ylabel('Trial', fontsize=13)\n",
    "    plt.colorbar(label='Number of Spikes')  # Shows the color scale\n",
    "    \n",
    "plt.tight_layout()  # To ensure the subplots do not overlap\n",
    "plt.suptitle('Neuron Spike Histograms', fontsize=20, y=1.02)  # Main title for all subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i in range(0, 10):\n",
    "    neuron_id = top_ids.iloc[i]['ID']\n",
    "    neuron = df_pred[df_pred['ID'] == neuron_id]\n",
    "    neuron_times = neuron['Time']\n",
    "    neuron = neuron.sort_values(by=['Time'])\n",
    "    plt.subplot(5, 2, i+1)  # Displaying 5 rows, 2 columns of plots.\n",
    "    \n",
    "    # Define the number of bins to suit your data\n",
    "    plt.hist(neuron['Interval'], bins=100, color='black')\n",
    "    \n",
    "    plt.title('Neuron ID: ' + str(neuron_id), fontsize=15)\n",
    "    plt.xlabel('Interval', fontsize=13)\n",
    "    plt.ylabel('Number of Spikes', fontsize=13)\n",
    "    \n",
    "plt.tight_layout()  # To ensure the subplots do not overlap\n",
    "plt.suptitle('Neuron Spike Histograms across Intervals', fontsize=20, y=1.02)  # Main title for all subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
