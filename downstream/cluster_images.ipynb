{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import glob\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "sys.path.append(\"../../neuroformer/neuroformer\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils import set_seed, print_full\n",
    "\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.load_models import load_natmovie\n",
    "\n",
    "DATASET = 'NaturalStim'\n",
    "data_dir = \"../data/NaturalMovie/\"\n",
    "data_dir = \"../data/NaturalStim/\"\n",
    "response_path = \".././data/NaturalStim/20-NatureMovie_part1-A_spikes(1).mat\"\n",
    "stimulus_path = \".././data/NaturalMovie/stimulus/docuMovie.pt\"\n",
    "base_path = f\"../configs/{DATASET}\"\n",
    "\n",
    "# df, stimulus, train_dataset, test_dataset, model = load_natmovie(data_dir, response_path, stimulus_path, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading data...\")\n",
    "    import gdown\n",
    "    url = \"https://drive.google.com/drive/folders/1jgYBERZpXdbAP-E5xcSAHsWSa95Z9IFe?usp=sharing\"\n",
    "    gdown.download_folder(id=url, quiet=False, use_cookies=False, output=\"data/\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# load config files\n",
    "import yaml\n",
    "\n",
    "with open(os.path.join(base_path, 'mconf.yaml'), 'r') as stream:\n",
    "    mconf = yaml.full_load(stream)\n",
    "\n",
    "with open(os.path.join(base_path, 'tconf.yaml'), 'r') as stream:\n",
    "    tconf = yaml.full_load(stream)\n",
    "\n",
    "# with open(os.path.join(base_path, 'dconf.yaml'), 'r') as stream:\n",
    "#     dconf = yaml.full_load(stream)\n",
    "\n",
    "import omegaconf\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# open yaml as omegacong\n",
    "mconf = OmegaConf.create(mconf)\n",
    "tconf = OmegaConf.create(tconf)\n",
    "# dconf = OmegaConf.create(dconf)\n",
    "\n",
    "\n",
    "# %%\n",
    "frame_window = 0.05\n",
    "window = 0.05\n",
    "window_prev = 0.2\n",
    "window_behavior = window\n",
    "dt = 0.005\n",
    "dt_frames = 0.05\n",
    "dt_vars = 0.05\n",
    "intervals = None\n",
    "n_frames = frame_window // dt_frames\n",
    "\n",
    "# %%\n",
    "## choose modalities ##\n",
    "\n",
    "# behavior\n",
    "visual_stim = True\n",
    "\n",
    "# %%\n",
    "from neuroformer.SpikeVidUtils import trial_df_real, make_intervals\n",
    "from neuroformer.prepare_data import load_natmovie_real\n",
    "\n",
    "df, stimulus = load_natmovie_real(response_path, stimulus_path, dt_frames)\n",
    "\n",
    "\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['real_interval'] = make_intervals(df, 0.05)\n",
    "df['Interval_2'] = make_intervals(df, window_prev)\n",
    "\n",
    "# randomly permute ID column\n",
    "df['ID'] = np.random.permutation(df['ID'].values)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1  # add first / last interval for SOS / EOS'\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)] + ['EOS'] + ['PAD']\n",
    "\n",
    "\n",
    "# %%\n",
    "# int_trials = df.groupby(['Interval', 'Trial']).size()\n",
    "# print(int_trials.mean())\n",
    "# df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
    "var_group = 'Interval'\n",
    "n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "df.groupby([var_group, 'Trial']).size().sort_values(ascending=False).nlargest(int(0.05 * n_unique))\n",
    "# df.groupby([var_group, 'Trial']).size().sort_values(ascending=False).nsmallest(int(0.99 * n_unique))\n",
    "\n",
    "# %%\n",
    "## resnet3d feats\n",
    "n_embd = 256\n",
    "n_embd_frames = 64\n",
    "conv_layer = True\n",
    "kernel_size = (1, 8, 8)\n",
    "\n",
    "frame_block_size = ((20 // kernel_size[0] * 64 * 112) // (n_embd_frames))\n",
    "frame_feats = stimulus if visual_stim else None\n",
    "frame_block_size = (20 * 64 * 112) // (n_embd_frames)\n",
    "# frame_block_size = 560\n",
    "prev_id_block_size = 67\n",
    "id_block_size = prev_id_block_size   # 95\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
    "frame_memory = 20   # how many frames back does model see\n",
    "window = window\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "neurons = [i for i in range(df['ID'].min(), df['ID'].max() + 1)]\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }\n",
    "\n",
    "\n",
    "# %%\n",
    "import random\n",
    "\n",
    "r_split = 0.8\n",
    "all_trials = sorted(df['Trial'].unique())\n",
    "train_trials = random.sample(all_trials, int(len(all_trials) * r_split))\n",
    "\n",
    "train_data = df[df['Trial'].isin(train_trials)]\n",
    "test_data = df[~df['Trial'].isin(train_trials)]\n",
    "\n",
    "# %%\n",
    "from neuroformer.SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                dt_frames=dt_frames, intervals=None, dataset=DATASET,\n",
    "                                window_behavior=window_behavior)\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats,\n",
    "                                pred=False, window_prev=window_prev, frame_window=frame_window,\n",
    "                                dt_frames=dt_frames, intervals=None, dataset=DATASET,\n",
    "                                dt_vars=dt_vars, \n",
    "                                window_behavior=window_behavior)\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "iterable = iter(loader)\n",
    "\n",
    "# %%\n",
    "x, y = next(iterable)\n",
    "# print(x['behavior'].shape, x['behavior_dt'].shape)\n",
    "for k in x.keys():\n",
    "    print(k, x[k].shape)\n",
    "\n",
    "# %%\n",
    "# for trial in df['Trial'].unique():\n",
    "#     video_trial = stimulus[trial]\n",
    "#     video_duration = video_trial.shape[1] * dt_frames\n",
    "#     df.drop(df[(df['Trial'] == trial) & (df['Time'] > video_duration)].index, inplace=True)\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# %%\n",
    "from model_neuroformer import GPT, GPTConfig\n",
    "\n",
    "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)   \n",
    "max_epochs = 300\n",
    "batch_size = round((32 * 6))\n",
    "shuffle = True\n",
    "\n",
    "title =  f'window:{window}_prev:{window_prev}_contatpad'\n",
    "\n",
    "model_path = f\"\"\"./models/tensorboard/{DATASET}/RANDOM/{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\n",
    "\n",
    "model_conf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                        id_vocab_size=train_dataset.id_population_size,\n",
    "                        frame_block_size=frame_block_size,\n",
    "                        id_block_size=id_block_size,  # frame_block_size\n",
    "                        prev_id_block_size=prev_id_block_size,\n",
    "                        sparse_mask=False, p_sparse=None, \n",
    "                        sparse_topk_frame=None, sparse_topk_id=None, sparse_topk_prev_id=None,\n",
    "                        n_dt=len(n_dt),\n",
    "                        data_size=train_dataset.size,\n",
    "                        class_weights=None,\n",
    "                        pretrain=False,\n",
    "                        n_state_layers=mconf.n_state_layers, n_state_history_layers=mconf.n_state_history_layers,\n",
    "                        n_stimulus_layers=mconf.n_stimulus_layers, self_att_layers=mconf.self_att_layers,\n",
    "                        n_behavior_layers=mconf.n_behavior_layers,\n",
    "                        n_head=mconf.n_head, n_embd=mconf.n_embd, \n",
    "                        contrastive=mconf.contrastive, clip_emb=1024, clip_temp=mconf.clip_temp,\n",
    "                        conv_layer=conv_layer, kernel_size=kernel_size,\n",
    "                        temp_emb=mconf.temp_emb, pos_emb=False,\n",
    "                        id_drop=0.35, im_drop=0.35, b_drop=0.45,\n",
    "                        window=window, window_prev=window_prev, frame_window=frame_window, dt=dt,\n",
    "                        neurons=neurons, stoi_dt=stoi_dt, itos_dt=itos_dt, n_embd_frames=n_embd_frames,\n",
    "                        ignore_index_id=stoi['PAD'], ignore_index_dt=stoi_dt['PAD'])  # 0.35\n",
    "\n",
    "model = GPT(model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"../models/tensorboard/NaturalStim/window:0.05_prev:0.2_contatpad/sparse_f:None_id:None/w:0.05_wp:0.2/6_Cont:True_window:0.05_f_window:0.05_df:0.005_blocksize:67_conv_True_shuffle:True_batch:192_sparse_(None_None)_blocksz2374_pos_emb:False_temp_emb:True_drop:0.35_dt:True_2.0_42_max0.005_(8, 8, 8)_8_256.pt\"\n",
    "model.load_state_dict(torch.load(weights, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.SpikeVidUtils import get_interval_idx, round_n\n",
    "\n",
    "dt_frames = 1 / 20\n",
    "intervals = [round_n(get_interval_idx(idx, dt_frames), 0.05) for idx in indexes_mouse]\n",
    "\n",
    "indexes_mouse = [range(0, 50), range(140, 300), range(370, 420), range(500, 578), range(617, 626), range(740, 840)]\n",
    "# fuse the ranges together\n",
    "indexes_mouse = [item for sublist in indexes_mouse for item in sublist]\n",
    "\n",
    "from neuroformer.SpikeVidUtils import get_frame_idx\n",
    "\n",
    "dt_frames = 0.05\n",
    "intervals = [get_frame_idx()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
