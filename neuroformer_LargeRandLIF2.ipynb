{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import glob\n",
    "import collections\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from trainer import Trainer, TrainerConfig\n",
    "from utils import set_seed\n",
    "\n",
    "\n",
    "from scipy import io as scipyio\n",
    "from scipy.special import softmax\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from utils import print_full\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from visualize import *\n",
    "set_plot_params()\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "\n",
    "from model_neuroformer import GPT, GPTConfig, neuralGPTConfig, Decoder\n",
    "from trainer import Trainer, TrainerConfig\n",
    "\n",
    "\n",
    "import json\n",
    "# for i in {1..10}; do python3 -m gather_atts.py; done\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stim_path = \"data/LargeRandLIF2/LargeRandNet2_PoissonRate.csv\"\n",
    "# response_path = \"data/LargeRandLIF2/LargeRandNet2_SpikeTime.csv\"\n",
    "\n",
    "# if not os.path.exists(response_path):\n",
    "#     print(\"Downloading data...\")\n",
    "#     import gdown\n",
    "#     url = \"https://drive.google.com/drive/folders/1dkU4GjyKt5ror5DuyfM135ISsnE69Jp5?usp=sharing\"\n",
    "#     gdown.download_folder(id=url, quiet=False, use_cookies=False, output=\"data/\")\n",
    "\n",
    "stim_path = \"data/LargeRandLIF2-2/LargeRandNet2_PoissonRate.csv\"\n",
    "response_path = \"data/LargeRandLIF2-2/LargeRandNet2_SpikeTime.csv\"\n",
    "\n",
    "if not os.path.exists(response_path):\n",
    "    print(\"Downloading data...\")\n",
    "    import gdown\n",
    "    url = \"https://drive.google.com/drive/folders/1yDWde9rJ_9nOYN5Ic-_JoAYaW2a2jYOY?usp=sharing\"\n",
    "    gdown.download_folder(id=url, quiet=False, use_cookies=False, output=\"data/\")\n",
    "\n",
    "\n",
    "# Load Data\n",
    "stimulus = np.transpose(np.loadtxt(stim_path, delimiter=','), (1, 0))\n",
    "df = pd.read_csv(response_path, names=['Time', 'ID'])\n",
    "dt_res = 10000\n",
    "df['Time'] = df['Time'].round(4)\n",
    "df['Trial'] = df['Time'].apply(lambda x: x // dt_res + 1).astype(int)\n",
    "df['Time'] = df['Time'].apply(lambda x: x - ((x // dt_res) * dt_res)).round(2)\n",
    "df['ID'] = df['ID'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "n_seed = 25\n",
    "set_seed(n_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 500)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f542ff951c0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stimulus[0, :,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016789</th>\n",
       "      <td>9997.1</td>\n",
       "      <td>787</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016790</th>\n",
       "      <td>9997.2</td>\n",
       "      <td>494</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016791</th>\n",
       "      <td>9998.3</td>\n",
       "      <td>254</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016792</th>\n",
       "      <td>9998.9</td>\n",
       "      <td>786</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016793</th>\n",
       "      <td>9999.6</td>\n",
       "      <td>605</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6016794 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time   ID  Trial\n",
       "0           4.6   50      1\n",
       "1           4.7  112      1\n",
       "2           5.0  460      1\n",
       "3           5.1  206      1\n",
       "4           5.2  645      1\n",
       "...         ...  ...    ...\n",
       "6016789  9997.1  787    100\n",
       "6016790  9997.2  494    100\n",
       "6016791  9998.3  254    100\n",
       "6016792  9998.9  786    100\n",
       "6016793  9999.6  605    100\n",
       "\n",
       "[6016794 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(parent_path + \"code/data/OneCombo3/Combo3_all_stim.csv\")\n",
    "frame_window = 20\n",
    "window = 1\n",
    "window_prev = 20 - window\n",
    "dt = 0.1\n",
    "dt_frames = 20\n",
    "start_interval = max(window, window_prev)\n",
    "p_window = window / (window + window_prev)\n",
    "\n",
    "from SpikeVidUtils import make_intervals\n",
    "\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['Interval_2'] = make_intervals(df, window_prev)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# n_dt = sorted((df['Interval_dt'].unique()).round(2)) \n",
    "max_window = max(window, window_prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1  # add first / last interval for SOS / EOS'\n",
    "n_dt = [round(dt * n, 2) for n in range(dt_range)] + ['PAD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import df_to_dict\n",
    "\n",
    "# dict_path = \"data/LargeRandLIF2-2/LargeRandNet2_SpikeTime_dict.pkl\"\n",
    "\n",
    "# if not os.path.exists(dict_path):\n",
    "#     print(\"Creating dictionary...\")\n",
    "#     df_dict = df_to_dict(df)\n",
    "#     with open(dict_path, 'wb') as f:\n",
    "#         pickle.dump(df_dict, f)\n",
    "# else:\n",
    "#     print(\"Loading dictionary...\")\n",
    "#     with open(dict_path, 'rb') as f:\n",
    "#         df_dict = pickle.load(f)\n",
    "\n",
    "# int_trials = df.groupby(['Interval', 'Trial']).size()\n",
    "# print(int_trials.mean())\n",
    "# # df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
    "# var_group = 'Interval'\n",
    "# n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "# # df.groupby(['Interval_2', 'Trial']).size().mean()\n",
    "\n",
    "# var_group = 'Interval_2'\n",
    "# n_unique = len(df.groupby([var_group, 'Trial']).size())\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "# # df.groupby(['Interval_2', 'Trial']).size().mean()\n",
    "\n",
    "# df.groupby([var_group, 'Trial']).size().nlargest(int(0.2 * n_unique))\n",
    "# df.groupby(['Interval_2', 'Trial']).size().mean()\n",
    "\n",
    "# n_unique = len(int_trials)\n",
    "# int_trials.nlargest(int(0.2 * n_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "## resnet3d feats\n",
    "n_embd = 256\n",
    "frame_feats = torch.tensor(stimulus, dtype=torch.float32)\n",
    "frame_block_size = 500  # math.ceil(frame_feats.shape[-1] * frame_window)\n",
    "n_embd_frames = 10000\n",
    "\n",
    "prev_id_block_size = 800 # math.ceil(frame_block_size * (1 - p_window))\n",
    "id_block_size = 150    # math.ceil(frame_block_size * p_window)\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
    "frame_memory = 20   # how many frames back does model see\n",
    "window = window\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "# translate neural embeddings to separate them from ID embeddings\n",
    "neurons = sorted(list(set(df['ID'].unique())))\n",
    "trial_tokens = [f\"Trial {n}\" for n in df['Trial'].unique()]\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_split = 0.8\n",
    "train_trials = sorted(df['Trial'].unique())[:int(len(df['Trial'].unique()) * r_split)]\n",
    "train_data = df[df['Trial'].isin(train_trials)]\n",
    "test_data = df[~df['Trial'].isin(train_trials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4819760 Neurons: 1003 Pixels: 0.\n",
      "id block size: 150\n",
      "frames: 1000, id: 150\n",
      "Length: 1197034 Neurons: 1003 Pixels: 0.\n",
      "id block size: 150\n",
      "frames: 1000, id: 150\n",
      "train: 780973, test: 195214\n"
     ]
    }
   ],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window, start_interval=20,\n",
    "                                  dt_frames=dt_frames, dataset='LIF2')\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window, start_interval=20,\n",
    "                                  dt_frames=dt_frames, dataset='LIF2')\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import get_class_weights\n",
    "# class_weights = get_class_weights(train_dataset, stoi, stoi_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/13/2023 13:05:07 - INFO - model_neuroformer_LRN -   number of parameters: 5.245548e+08\n"
     ]
    }
   ],
   "source": [
    "from model_neuroformer_LRN import GPT, GPTConfig, neuralGPTConfig\n",
    "# initialize config class and model (holds hyperparameters)\n",
    "# for is_conv in [True, False]:    \n",
    "conv_layer = False\n",
    "mconf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                    id_vocab_size=train_dataset.id_population_size,\n",
    "                    frame_block_size=frame_block_size,\n",
    "                    id_block_size=id_block_size,  # frame_block_size\n",
    "                    prev_id_block_size=prev_id_block_size,\n",
    "                    sparse_mask=False, p_sparse=0.25, sparse_topk_frame=None, sparse_topk_id=None,\n",
    "                    n_dt=len(n_dt),\n",
    "                    data_size=train_dataset.size,\n",
    "                    class_weights=None,\n",
    "                    pretrain=False,\n",
    "                    n_state_layers=6, n_state_history_layers=4, n_stimulus_layers=4, self_att_layers=8,\n",
    "                    n_layer=10, n_head=8, n_embd=n_embd, n_embd_frames=n_embd_frames,\n",
    "                    contrastive=True, clip_emb=1024, clip_temp=0.5,\n",
    "                    temp_emb=True, pos_emb=False,\n",
    "                    id_drop=0.2, im_drop=0.2,\n",
    "                    window=window, window_prev=window_prev, frame_window=frame_window, dt=dt,\n",
    "                    neurons=neurons, stoi_dt=stoi_dt, itos_dt=itos_dt, dataset='LIF2')  # 0.35\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = (mconf.n_state_layers, mconf.n_state_history_layers, mconf.n_stimulus_layers)\n",
    "max_epochs = 500\n",
    "batch_size = (32 * 8)\n",
    "shuffle = True\n",
    "\n",
    "weighted = True if mconf.class_weights is not None else False\n",
    "title =  f'window:{window}'\n",
    "model_path = f\"\"\"./models/tensorboard/LRL2/ignore_index/{title}/sparse_f:{mconf.sparse_topk_frame}_id:{mconf.sparse_topk_id}/w:{window}_wp:{window_prev}/{6}_Cont:{mconf.contrastive}_window:{window}_f_window:{frame_window}_df:{dt}_blocksize:{id_block_size}_conv_{conv_layer}_shuffle:{shuffle}_batch:{batch_size}_sparse_({mconf.sparse_topk_frame}_{mconf.sparse_topk_id})_blocksz{block_size}_pos_emb:{mconf.pos_emb}_temp_emb:{mconf.temp_emb}_drop:{mconf.id_drop}_dt:{shuffle}_2.0_{max(stoi_dt.values())}_max{dt}_{layers}_{mconf.n_head}_{mconf.n_embd}.pt\"\"\"\n",
    "\n",
    "# if os.path.exists(model_path):\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "#     print(f\"-- loaded model from {model_path} --\")\n",
    "\n",
    "\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=1e-4, \n",
    "                    num_workers=4, lr_decay=False, patience=3, warmup_tokens=8e7, \n",
    "                    decay_weights=True, weight_decay=0.1, shuffle=shuffle,\n",
    "                    final_tokens=len(train_dataset)*(id_block_size) * (max_epochs),\n",
    "                    clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                    dataset='higher_order', mode='predict',\n",
    "                    block_size=train_dataset.block_size,\n",
    "                    id_block_size=train_dataset.id_block_size,\n",
    "                    show_grads=False, plot_raster=False,\n",
    "                    ckpt_path=model_path, no_pbar=False, dist=False,\n",
    "                    save_every=1000)\n",
    "\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf, mconf)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, shuffle=False, pin_memory=False)\n",
    "iterable = iter(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iterable)\n",
    "model.cpu()\n",
    "features, logits, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "RUN SIMULATION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from IPython.utils import io\n",
    "# top_p=0.25, top_p_t=0.9, temp=2.\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "# trials = np.random.choice(train_data['Trial'].unique(), size=12)\n",
    "trials = test_data['Trial'].unique()[:4]\n",
    "results_dict = dict()\n",
    "# for n in range(2, 20):\n",
    "df_pred = None\n",
    "df_true = None\n",
    "n_p = 0.3   # (n + 1) * 0.05\n",
    "temp = 2\n",
    "# stoi['SOS'] = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 81\n",
      "Length: 2858 Neurons: 1003 Pixels: 0.\n",
      "id block size: 50\n",
      "frames: 1000, id: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "len pred: 2759, len true: 3232: 100%|██████████| 470/470 [24:41<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS fouuuund: 0\n",
      "EOS fouuuund: 470\n",
      "pred: (2758, 5), true: (2762, 2)\n",
      "Trial: 82\n",
      "Length: 2813 Neurons: 1003 Pixels: 0.\n",
      "id block size: 50\n",
      "frames: 1000, id: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "len pred: 1019, len true: 1204:  40%|████      | 188/466 [09:23<1:01:33, 13.28s/it]"
     ]
    }
   ],
   "source": [
    "end_interval = window * 500\n",
    "\n",
    "for trial in trials:    # test_data['Trial'].unique():\n",
    "    # with io.capture_output() as captured:\n",
    "        print(f\"Trial: {trial}\")\n",
    "        df_trial = df[(df['Trial'] == trial) & (df['Time'] < end_interval)]\n",
    "        trial_dataset = SpikeTimeVidData2(df_trial, None, block_size, id_block_size, frame_block_size, prev_id_block_size, \n",
    "                                  window, dt, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, \n",
    "                                  pred=False, window_prev=window_prev, frame_window=frame_window, start_interval=20,\n",
    "                                  dt_frames=dt_frames, dataset='LIF2')\n",
    "        trial_loader = DataLoader(trial_dataset, shuffle=False, pin_memory=False)\n",
    "        results_trial = predict_raster_recursive_time_auto(model, trial_dataset, window, window_prev, stoi, itos_dt, itos=itos, \n",
    "                                                           sample=True, top_p=0.95, top_p_t=0.95, temp=1.0, temp_t=1., frame_end=0, get_dt=True, gpu=False, pred_dt=True)\n",
    "        # results_trial = predict_raster_hungarian(model, loader, itos_dt, top_p=0.75, temp=1)\n",
    "        # print(f\"MAX ID ---- {sorted(results_trial['ID'].unique()[-10])}\")\n",
    "        df_trial_pred, df_trial_true = process_predictions(results_trial, stoi, itos, window)\n",
    "        print(f\"pred: {df_trial_pred.shape}, true: {df_trial_true.shape}\" )\n",
    "        if df_pred is None:\n",
    "            df_pred = df_trial_pred\n",
    "            df_true = df_trial_true\n",
    "        else:\n",
    "            df_pred = pd.concat([df_pred, df_trial_pred])\n",
    "            df_true = pd.concat([df_true, df_trial_true])\n",
    "\n",
    "# df_preds[n] = df_pred\n",
    "# print(f\"--- n: {n}, n_p: {n_p}, temp: {temp} ---\")\n",
    "scores = compute_scores(df[df['Trial'].isin(trials)], df_pred)\n",
    "print(scores)\n",
    "print(f\"pred: {len(df_pred)}, true: {len(df_true)}\" )\n",
    "# results_dict[n] = (scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Interval_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016789</th>\n",
       "      <td>9997.1</td>\n",
       "      <td>787</td>\n",
       "      <td>100</td>\n",
       "      <td>9998.0</td>\n",
       "      <td>10013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016790</th>\n",
       "      <td>9997.2</td>\n",
       "      <td>494</td>\n",
       "      <td>100</td>\n",
       "      <td>9998.0</td>\n",
       "      <td>10013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016791</th>\n",
       "      <td>9998.3</td>\n",
       "      <td>254</td>\n",
       "      <td>100</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>10013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016792</th>\n",
       "      <td>9998.9</td>\n",
       "      <td>786</td>\n",
       "      <td>100</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>10013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016793</th>\n",
       "      <td>9999.6</td>\n",
       "      <td>605</td>\n",
       "      <td>100</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6016794 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time   ID  Trial  Interval  Interval_2\n",
       "0           4.6   50      1       5.0        19.0\n",
       "1           4.7  112      1       5.0        19.0\n",
       "2           5.0  460      1       5.0        19.0\n",
       "3           5.1  206      1       6.0        19.0\n",
       "4           5.2  645      1       6.0        19.0\n",
       "...         ...  ...    ...       ...         ...\n",
       "6016789  9997.1  787    100    9998.0     10013.0\n",
       "6016790  9997.2  494    100    9998.0     10013.0\n",
       "6016791  9998.3  254    100    9999.0     10013.0\n",
       "6016792  9998.9  786    100    9999.0     10013.0\n",
       "6016793  9999.6  605    100   10000.0     10013.0\n",
       "\n",
       "[6016794 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['Trial'].isin(trials)]\n",
    "df_2 = df[df['Trial'].isin(trials + 1)]\n",
    "df_3 = df[df['Trial'].isin(trials + 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_full = df_pred\n",
    "window_pred = 5\n",
    "\n",
    "df_list = [df_pred_full, df_1, df_2, df_3]\n",
    "\n",
    "for df_ in df_list:\n",
    "    df_['Interval'] = make_intervals(df_, window_pred)\n",
    "    df_ = df_[df_['Interval'] > window_prev + window]\n",
    "    df_ = df_[df_['Interval'] < 2 * window]\n",
    "\n",
    "\n",
    "window_pred = window if window_pred is None else window_pred\n",
    "intervals = np.array(sorted(set(df['Interval'].unique()) & set(df['Interval'].unique())))\n",
    "labels = np.array([round(window_pred + window_pred*n, 2) for n in range(0, int(max(df_pred_full['Interval']) / window_pred))])\n",
    "ids = sorted(set(df['ID'].unique()) & set(df['ID'].unique()))\n",
    "\n",
    "\n",
    "# labels = sorted(set(df_pred_full['Interval'].unique()))\n",
    "rates_pred = get_rates_trial(df_pred_full, labels)\n",
    "rates_1 = get_rates_trial(df_1, labels)\n",
    "rates_2 = get_rates_trial(df_2, labels)\n",
    "rates_3 = get_rates_trial(df_3, labels)\n",
    "\n",
    "top_corr_pred = calc_corr_psth(rates_pred, rates_1)\n",
    "top_corr_real = calc_corr_psth(rates_1, rates_2)\n",
    "top_corr_real_2 = calc_corr_psth(rates_1, rates_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "Evaluate results\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from visualize import *\n",
    "\n",
    "# df_2['Trial'] -= 2\n",
    "id_pred, id_true_1, id_true_2 = len(df_pred_full['ID'].unique()), len(df_1['ID'].unique()), len(df_2['ID'].unique())\n",
    "print(f\"id_pred: {id_pred}, id_true_1: {id_true_1}, id_true_2: {id_true_2}\")\n",
    "\n",
    "len_pred, len_true = len(df_pred_full), len(df_1)\n",
    "print(f\"len_pred: {len_pred}, len_true: {len_true}\")\n",
    "\n",
    "accuracy = get_accuracy(df_pred, df_2)\n",
    "\n",
    "scores = compute_scores(df_1, df_2)\n",
    "pred_scores = compute_scores(df_1, df_pred_full)\n",
    "print(f\"real: {scores}\")\n",
    "print(f\"pred: {pred_scores}\")\n",
    "\n",
    "set_plot_white()\n",
    "plt.figure(figsize=(10, 10), facecolor='white')\n",
    "plt.title(f'PSTH Correlations (V1 + AL) {title}', fontsize=25)\n",
    "plt.ylabel('Count (n)', fontsize=25)\n",
    "plt.xlabel('Pearson r', fontsize=25)\n",
    "plt.hist(top_corr_real, label='real - real2', alpha=0.6)\n",
    "# plt.hist(top_corr_real_2, label='real - real3', alpha=0.6)\n",
    "plt.hist(top_corr_pred, label='real - simulated', alpha=0.6)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "dir_name = os.path.dirname(model_path)\n",
    "model_name = os.path.basename(model_path)\n",
    "plt.savefig(os.path.join(dir_name, F'psth_corr_{title}.svg'))\n",
    "df_pred.to_csv(os.path.join(dir_name, F'df_pred_{title}.csv'))\n",
    "\n",
    "plot_distribution(df_1, df_pred, save_path=os.path.join(dir_name, F'psth_dist_{title}.svg'))\n",
    "\n",
    "total_scores = dict()\n",
    "total_scores['real'] = scores\n",
    "total_scores['pred'] = pred_scores\n",
    "\n",
    "print(f\"model: {title}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=5, shuffle=False, pin_memory=False)\n",
    "iterable = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500])\n",
      "iv: 20.0, ix+window: 21.0 pid: tensor([ 1., 20.]) cid: tensor([20., 21.])\n",
      "x: ['SOS', 117, 297, 418, 569, 151, 156, 588, 701, 33, 41, 343, 845, 643, 138, 560, 656, 170, 341]\n",
      "xid_prev: ['SOS', 50, 112, 460, 206, 645, 350, 488, 544, 334, 348, 623, 830, 892, 85, 151, 43, 263, 878, 778, 836, 50, 777, 147, 999, 867, 206, 623, 43, 544, 950, 151, 124, 347, 560, 252, 460, 625, 580, 334, 248, 796, 114, 72, 273, 564, 674, 350, 488, 85, 276, 542, 469, 800, 878, 970, 43, 201, 724, 348, 464, 642, 21, 460, 151, 777, 836, 948, 120, 163, 701, 263, 741, 75, 175, 713, 15, 79, 317, 493, 112, 662, 335, 449, 305, 366, 856, 884, 72, 581, 922, 65, 252, 18, 197, 56, 57, 518, 319, 462, 940, 983, 408, 454, 745, 92, 224, 509, 840, 999, 242, 488, 883, 262, 564, 354, 639, 114, 379, 674, 113, 349, 987, 188, 724, 216, 874, 76, 315, 460, 2, 593, 796, 149, 326, 712, 229, 334, 590, 680, 783, 942, 944, 477, 102, 982, 799, 59, 120, 474, 508, 820, 880, 305, 794, 124, 798, 884, 382, 675, 741, 891, 112, 501, 245, 714, 358, 79, 413, 690, 777]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Interval_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>21.0</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>21.1</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>21.1</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>21.1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>21.2</td>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time   ID  Trial  Interval  Interval_2\n",
       "0     4.6   50      1       5.0        19.0\n",
       "1     4.7  112      1       5.0        19.0\n",
       "2     5.0  460      1       5.0        19.0\n",
       "3     5.1  206      1       6.0        19.0\n",
       "4     5.2  645      1       6.0        19.0\n",
       "..    ...  ...    ...       ...         ...\n",
       "187  21.0  341      1      21.0        38.0\n",
       "188  21.1  122      1      22.0        38.0\n",
       "189  21.1  149      1      22.0        38.0\n",
       "190  21.1  173      1      22.0        38.0\n",
       "191  21.2  907      1      22.0        38.0\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iterable)\n",
    "x['id'], x['interval'], x['trial']\n",
    "\n",
    "\n",
    "T = len(x['id'])\n",
    "P = x['pad']\n",
    "T_prev = len(x['id_prev'])\n",
    "P_prev = x['pad_prev']\n",
    "\n",
    "iv = float(x['interval'])\n",
    "\n",
    "xid = x['id'][: T - P]\n",
    "xid = [itos[int(i)] for i in xid]\n",
    "\n",
    "xid_prev = x['id_prev'][: T_prev - P_prev]\n",
    "xid_prev = [itos[int(i)] for i in xid_prev]\n",
    "\n",
    "print(x['frames'].shape)\n",
    "\n",
    "print(f\"iv: {iv}, ix+window: {iv + window} pid: {x['pid']} cid: {x['cid']}\")\n",
    "print(f\"x: {xid}\")\n",
    "\n",
    "print(f\"xid_prev: {xid_prev}\")\n",
    "\n",
    "tdiff = 0.2\n",
    "t_var = 'Time' # 'Interval'\n",
    "int_var = 'pid'\n",
    "# df[(df[t_var] >= iv - tdiff) & (df[t_var] <= iv + (window + tdiff)) & (df['Trial'] == int(x['trial']))]\n",
    "# df[(df[t_var] >= float(x[int_var][0]) - tdiff) & (df[t_var] <= float(x[int_var][1] + tdiff)) & (df['Trial'] == int(x['trial']))]\n",
    "df[(df[t_var] >= float(x[int_var][0]) - tdiff) & (df[t_var] <= float(x['cid'][1] + tdiff)) & (df['Trial'] == int(x['trial']))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d081bc067bf79be810ce3d13e0a50750de639b750af8f2c90615b4772e48a538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
