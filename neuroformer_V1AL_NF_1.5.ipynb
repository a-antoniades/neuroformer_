{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter\n",
      "CONTRASTIUVEEEEEEE False\n",
      "VISUAL: True\n",
      "PAST_STATE: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path, PurePath\n",
    "path = Path.cwd()\n",
    "parent_path = path.parents[1]\n",
    "sys.path.append(str(PurePath(parent_path, 'neuroformer')))\n",
    "sys.path.append('neuroformer')\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "from neuroformer.model_neuroformer_2 import GPT, GPTConfig, get_attr\n",
    "from neuroformer.utils import get_attr\n",
    "from neuroformer.trainer import Trainer, TrainerConfig\n",
    "from neuroformer.utils_2 import (set_seed, update_object, running_jupyter, \n",
    "                                 all_device, load_config, \n",
    "                                 dict_to_object, object_to_dict, recursive_print,\n",
    "                                 create_modalities_dict)\n",
    "from neuroformer.visualize import set_plot_params\n",
    "from neuroformer.SpikeVidUtils import make_intervals, round_n, SpikeTimeVidData2\n",
    "from neuroformer.DataUtils import round_n, split_data_by_interval, Tokenizer\n",
    "from neuroformer.datasets import load_V1AL\n",
    "\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\"\n",
    "\n",
    "import argparse\n",
    "import wandb\n",
    "\n",
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--infer\", action=\"store_true\", help=\"Inference mode\")\n",
    "    parser.add_argument(\"--train\", action=\"store_true\", default=False, help=\"Train mode\")\n",
    "    parser.add_argument(\"--dist\", action=\"store_true\", default=False, help=\"Distributed mode\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=25, help=\"Random seed\")\n",
    "    parser.add_argument(\"--resume\", type=str, default=None, help=\"Resume from checkpoint\")\n",
    "    parser.add_argument(\"--rand_perm\", action=\"store_true\", default=False, help=\"Randomly permute the ID column\")\n",
    "    parser.add_argument(\"--mconf\", type=str, default=None, help=\"Path to model config file\")\n",
    "    parser.add_argument(\"--eos_loss\", action=\"store_true\", default=False, help=\"Use EOS loss\")\n",
    "    parser.add_argument(\"--no_eos_dt\", action=\"store_true\", default=False, help=\"No EOS dt token\")\n",
    "    parser.add_argument(\"--downstream\", action=\"store_true\", default=False, help=\"Downstream task\")\n",
    "    parser.add_argument(\"--freeze_model\", action=\"store_true\", default=False, help=\"Freeze model\")\n",
    "    parser.add_argument(\"--title\", type=str, default=None)\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"V1AL\")\n",
    "    parser.add_argument(\"--behavior\", action=\"store_true\", default=False, help=\"Behavior task\")\n",
    "    parser.add_argument(\"--pred_behavior\", action=\"store_true\", default=False, help=\"Predict behavior\")\n",
    "    parser.add_argument(\"--past_state\", action=\"store_true\", default=False, help=\"Input past state\")\n",
    "    parser.add_argument(\"--visual\", action=\"store_true\", default=False, help=\"Visualize\")\n",
    "    parser.add_argument(\"--contrastive\", action=\"store_true\", default=False, help=\"Contrastive\")\n",
    "    parser.add_argument(\"--clip_loss\", action=\"store_true\", default=False, help=\"Clip loss\")\n",
    "    parser.add_argument(\"--clip_vars\", nargs=\"+\", default=['id','frames'], help=\"Clip variables\")\n",
    "    parser.add_argument(\"--class_weights\", action=\"store_true\", default=False, help=\"Class weights\")\n",
    "    parser.add_argument(\"--resample\", action=\"store_true\", default=False, help=\"Resample\")\n",
    "    parser.add_argument(\"--loss_bprop\", type=str, default=None, help=\"Loss type to backpropagate\")\n",
    "    parser.add_argument(\"--config\", type=str, default=None, help=\"Config file\")\n",
    "    parser.add_argument(\"--sweep_id\", type=str, default=None, help=\"Sweep ID\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "if running_jupyter(): # or __name__ == \"__main__\":\n",
    "    print(\"Running in Jupyter\")\n",
    "    INFERENCE = False\n",
    "    DIST = False\n",
    "    SEED = 69\n",
    "    DOWNSTREAM = False\n",
    "    TITLE = None\n",
    "    RESUME = None\n",
    "    RAND_PERM = False\n",
    "    MCONF = None\n",
    "    EOS_LOSS = False\n",
    "    NO_EOS_DT = False\n",
    "    FREEZE_MODEL = False\n",
    "    TITLE = None\n",
    "    DATASET = \"lateral\"\n",
    "    BEHAVIOR = False\n",
    "    PREDICT_BEHAVIOR = False\n",
    "    VISUAL = True\n",
    "    PAST_STATE = True\n",
    "    CONTRASTIVE = False\n",
    "    CLIP_LOSS = True\n",
    "    CLIP_VARS = ['id','frames']\n",
    "    CLASS_WEIGHTS = False\n",
    "    RESAMPLE_DATA = False\n",
    "    LOSS_BPROP = None\n",
    "    CONFIG = None\n",
    "else:\n",
    "    print(\"Running in terminal\")\n",
    "    args = parse_args()\n",
    "    INFERENCE = not args.train\n",
    "    DIST = args.dist\n",
    "    SEED = args.seed\n",
    "    DOWNSTREAM = args.downstream\n",
    "    TITLE = args.title\n",
    "    RESUME = args.resume\n",
    "    RAND_PERM = args.rand_perm\n",
    "    MCONF = args.mconf\n",
    "    EOS_LOSS = args.eos_loss\n",
    "    NO_EOS_DT = args.no_eos_dt\n",
    "    FREEZE_MODEL = args.freeze_model\n",
    "    DATASET = args.dataset\n",
    "    BEHAVIOR = args.behavior\n",
    "    PREDICT_BEHAVIOR = args.pred_behavior\n",
    "    VISUAL = args.visual\n",
    "    PAST_STATE = args.past_state\n",
    "    CONTRASTIVE = args.contrastive\n",
    "    CLIP_LOSS = args.clip_loss\n",
    "    CLIP_VARS = args.clip_vars\n",
    "    CLASS_WEIGHTS = args.class_weights\n",
    "    RESAMPLE_DATA = args.resample\n",
    "    LOSS_BPROP = args.loss_bprop\n",
    "    CONFIG = args.config\n",
    "\n",
    "# SET SEED - VERY IMPORTANT\n",
    "set_seed(SEED)\n",
    "\n",
    "print(f\"CONTRASTIUVEEEEEEE {CONTRASTIVE}\")\n",
    "print(f\"VISUAL: {VISUAL}\")\n",
    "print(f\"PAST_STATE: {PAST_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "if CONFIG is None:\n",
    "    # config_path = \"./configs/NF_1.5/mconf.yaml\"\n",
    "    # config_path = \"./configs/NF_1.5/VisNav_VR_Expt/gru2_only/mconf.yaml\"\n",
    "    # config_path = \"./configs/NF_1.5/VisNav_VR_Expt/mlp_only/mconf.yaml\"\n",
    "    # config_path = \"./configs/NF_1.5/VisNav_VR_Expt/gru2_only_cls/mconf.yaml\"\n",
    "    config_path = \"./configs/Combo3_V1AL/NF_1.5/mconf.yaml\"\n",
    "\n",
    "else:\n",
    "    config_path = CONFIG\n",
    "config = load_config(config_path)  # replace 'config.yaml' with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "-- DATA --\n",
    "neuroformer/data/OneCombo3_V1AL/\n",
    "df = response\n",
    "video_stack = stimulus\n",
    "DOWNLOAD DATA URL = https://drive.google.com/drive/folders/1jNvA4f-epdpRmeG9s2E-2Sfo-pwYbjeY?usp=sharing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_V1AL()\n",
    "spikes = data['spikes']\n",
    "stimulus = data['stimulus']\n",
    "speed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = config.window.curr\n",
    "window_prev = config.window.prev\n",
    "dt = config.resolution.dt\n",
    "\n",
    "\n",
    "# from neuroformer.DataUtils import make_intervals\n",
    "# df = pd.read_csv(\"./data/VisNav_VR_Expt/MedialVRDataset/df.csv\")\n",
    "# selection_1 = np.array(pd.read_csv(\"./data/VisNav_VR_Expt/MedialVRDataset/sel1.csv\")).flatten()\n",
    "# df = df[df['ID'].isin(selection_1)]\n",
    "# df['Interval'] = make_intervals(df, window)\n",
    "# df['Interval_2'] = make_intervals(df, window_prev)\n",
    "# # df.groupby(['Interval', 'Trial']).size().plot.bar()\n",
    "# # df.groupby(['Interval', 'Trial']).agg(['nunique'])model_path\n",
    "# n_unique = len(df.groupby(['Interval', 'Trial']).size())\n",
    "# print(df.groupby(['Interval', 'Trial']).size().nlargest(int(0.7 * n_unique)))\n",
    "# print(df.groupby(['Interval_2', 'Trial']).size().nlargest(int(0.2 * n_unique)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervals.shape: (620,)\n",
      "ID vocab size: 518\n",
      "dt vocab size: 19\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "intervals = np.arange(0, 31, config.window.curr)\n",
    "trials = list(set(data['spikes'].keys()))\n",
    "combinations = np.array(list(itertools.product(intervals, trials)))\n",
    "train_intervals, test_intervals, finetune_intervals = split_data_by_interval(combinations, r_split=0.8, r_split_ft=0.01)\n",
    "\n",
    "\n",
    "print(f\"intervals.shape: {intervals.shape}\")\n",
    "\n",
    "# -------- #\n",
    "\n",
    "spikes_dict = {\n",
    "    \"ID\": data['spikes'],\n",
    "    \"Frames\": data['stimulus'],\n",
    "    \"Interval\": intervals,\n",
    "    \"dt\": config.resolution.dt,\n",
    "    \"id_block_size\": config.block_size.id,\n",
    "    \"prev_id_block_size\": config.block_size.prev_id,\n",
    "    \"frame_block_size\": config.block_size.frame,\n",
    "    \"window\": config.window.curr,\n",
    "    \"window_prev\": config.window.prev,\n",
    "    \"frame_window\": config.window.frame,\n",
    "}\n",
    "\n",
    "\"\"\" structure:\n",
    "{\n",
    "    type_of_modality:\n",
    "        {name of modality: {'data':data, 'dt': dt, 'predict': True/False},\n",
    "        ...\n",
    "        }\n",
    "    ...\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def visnav_callback(frames, frame_idx, n_frames, **kwargs):\n",
    "    if isinstance(frames, np.ndarray):\n",
    "        frames = torch.from_numpy(frames)\n",
    "    f_idx_0 = max(0, frame_idx - n_frames)\n",
    "    f_idx_1 = f_idx_0 + n_frames\n",
    "    chosen_frames = frames[f_idx_0:f_idx_1].type(torch.float32).unsqueeze(0)\n",
    "    return chosen_frames\n",
    "\n",
    "def combo3_V1AL_callback(frames, frame_idx, n_frames, **kwargs):\n",
    "    \"\"\"\n",
    "    Shape of stimulus: [3, 640, 64, 112]\n",
    "    \"\"\"\n",
    "    trial = kwargs['trial']\n",
    "    if trial <= 20: n_stim = 0\n",
    "    elif trial <= 40: n_stim = 1\n",
    "    elif trial <= 60: n_stim = 2\n",
    "    if isinstance(frames, np.ndarray):\n",
    "        frames = torch.from_numpy(frames)\n",
    "    f_idx_0 = max(0, frame_idx - n_frames)\n",
    "    f_idx_1 = f_idx_0 + n_frames\n",
    "    chosen_frames = frames[n_stim, f_idx_0:f_idx_1].type(torch.float32).unsqueeze(0)\n",
    "    return chosen_frames\n",
    "\n",
    "\n",
    "frames = {'feats': stimulus, 'callback': combo3_V1AL_callback, 'window': config.window.frame, 'dt': config.resolution.dt}\n",
    "modalities = create_modalities_dict(data, config.modalities) if get_attr(config, 'modalities', None) else None\n",
    "\n",
    "max_window = max(config.window.curr, config.window.prev)\n",
    "dt_range = math.ceil(max_window / dt) + 1\n",
    "n_dt = [round_n(x, dt) for x in np.arange(0, max_window + dt, dt)]\n",
    "\n",
    "token_types = {\n",
    "    'ID': {'tokens': list(np.arange(0, data['spikes'][1].shape[0]))},\n",
    "    'dt': {'tokens': n_dt, 'resolution': dt},\n",
    "}\n",
    "tokenizer = Tokenizer(token_types, max_window, dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Interval: 0.2\n",
      "Intervals:  29760\n",
      "Window:  0.05\n",
      "Window Prev:  0.15\n",
      "Population Size:  518\n",
      "ID Population Size:  518\n",
      "DT Population Size:  19\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.2\n",
      "Intervals:  29760\n",
      "Window:  0.05\n",
      "Window Prev:  0.15\n",
      "Population Size:  518\n",
      "ID Population Size:  518\n",
      "DT Population Size:  19\n",
      "Using explicitly passed intervals\n",
      "Min Interval: 0.2\n",
      "Intervals:  297\n",
      "Window:  0.05\n",
      "Window Prev:  0.15\n",
      "Population Size:  518\n",
      "ID Population Size:  518\n",
      "DT Population Size:  19\n",
      "Using explicitly passed intervals\n",
      "tensor([515, 516, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517, 517,\n",
      "        517, 517])\n",
      "tensor([ 0., 17., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "        18., 18.])\n",
      "id_prev torch.Size([100]) torch.int64\n",
      "dt_prev torch.Size([100]) torch.float32\n",
      "pad_prev torch.Size([]) torch.int64\n",
      "id torch.Size([100]) torch.int64\n",
      "dt torch.Size([100]) torch.float32\n",
      "pad torch.Size([]) torch.int64\n",
      "interval torch.Size([]) torch.float32\n",
      "trial torch.Size([]) torch.int64\n",
      "cid torch.Size([2]) torch.float32\n",
      "pid torch.Size([2]) torch.float32\n",
      "256 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/11/2023 14:49:52 - INFO - neuroformer.model_neuroformer_2 -   number of parameters: 2.412288e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id torch.Size([2, 100]) torch.int64\n",
      "dt torch.Size([2, 100]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from neuroformer.DataUtils import NFDataloader\n",
    "\n",
    "train_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=DATASET, \n",
    "                             frames=frames, intervals=train_intervals, modalities=modalities)\n",
    "test_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=DATASET, \n",
    "                            frames=frames, intervals=test_intervals, modalities=modalities)\n",
    "finetune_dataset = NFDataloader(spikes_dict, tokenizer, config, dataset=DATASET, \n",
    "                                frames=frames, intervals=finetune_intervals, modalities=modalities)\n",
    "\n",
    "    \n",
    "# print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')\n",
    "iterable = iter(train_dataset)\n",
    "x, y = next(iterable)\n",
    "print(x['id'])\n",
    "print(x['dt'])\n",
    "recursive_print(x)\n",
    "\n",
    "# update config\n",
    "# updated_config = update_config(config, modalities, tokenizer, x, y, 2)\n",
    "# updated_dict_object = dict_to_object(updated_config)\n",
    "# config = updated_dict_object\n",
    "\n",
    "# Update the config\n",
    "config.id_vocab_size = tokenizer.ID_vocab_size\n",
    "model = GPT(config, tokenizer)\n",
    "\n",
    "# Create a DataLoader\n",
    "loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "iterable = iter(loader)\n",
    "x, y = next(iterable)\n",
    "recursive_print(y)\n",
    "preds, features, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3788853/3451947718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mCKPT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCKPT_PATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"namespace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mneuroformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparam_sweep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_sweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"-- SWEEP_ID -- {args.sweep_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set training parameters\n",
    "MAX_EPOCHS = 200\n",
    "BATCH_SIZE = 32 * 5\n",
    "SHUFFLE = True\n",
    "\n",
    "if config.gru_only:\n",
    "    model_name = \"GRU\"\n",
    "elif config.mlp_only:\n",
    "    model_name = \"MLP\"\n",
    "elif config.gru2_only:\n",
    "    model_name = \"GRU_2.0\"\n",
    "else:\n",
    "    model_name = \"Neuroformer\"\n",
    "\n",
    "CKPT_PATH = f\"/share/edc/home/antonis/neuroformer/models/NF.15/Visnav_VR_Expt/{DATASET}/{model_name}/{TITLE}/{str(config.layers)}/{SEED}\"\n",
    "CKPT_PATH = CKPT_PATH.replace(\"namespace\", \"\").replace(\" \", \"_\")\n",
    "\n",
    "if args.sweep_id is not None:\n",
    "    from neuroformer.hparam_sweep import train_sweep\n",
    "    print(f\"-- SWEEP_ID -- {args.sweep_id}\")\n",
    "    wandb.agent(args.sweep_id, function=train_sweep)\n",
    "else:\n",
    "    # Create a TrainerConfig and Trainer\n",
    "    tconf = TrainerConfig(max_epochs=MAX_EPOCHS, batch_size=BATCH_SIZE, learning_rate=1e-4, \n",
    "                          num_workers=16, lr_decay=True, patience=3, warmup_tokens=8e7, \n",
    "                          decay_weights=True, weight_decay=1.0, shuffle=SHUFFLE,\n",
    "                          final_tokens=len(train_dataset)*(config.block_size.id) * (MAX_EPOCHS),\n",
    "                          clip_norm=1.0, grad_norm_clip=1.0,\n",
    "                          show_grads=False,\n",
    "                          ckpt_path=CKPT_PATH, no_pbar=False, \n",
    "                          dist=DIST, save_every=0, eval_every=5, min_eval_epoch=50,\n",
    "                          use_wandb=True, wandb_project=\"neuroformer\", wandb_group=f\"1.5.1_visnav_{DATASET}\")\n",
    "\n",
    "    trainer = Trainer(model, train_dataset, test_dataset, tconf, config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
