{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "from torch.utils import data\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as FeatureAlphaDropout\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from scipy import io as scipyio\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from utils import print_full\n",
    "\n",
    "import os\n",
    "import glob\n",
    "parent_path = os.path.dirname(os.path.dirname(os.getcwd())) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "set_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R3D: (3 x T x H x W)\n",
    "\n",
    "from SpikeVidUtils import image_dataset\n",
    "\n",
    "train_path = parent_path + \"code/data/OneCombo3/stimuli/\"\n",
    "video_stack = [skimage.io.imread(vid) for vid in glob.glob(train_path + '/*.tif')][::-1]\n",
    "print(glob.glob(train_path + '/*.tif')[::-1])\n",
    "video_stack = np.concatenate(video_stack, axis=0, dtype=np.float32)\n",
    "\n",
    "# video_stack = skimage.io.imread(\"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/OneCombo3/stimuli/Combined Stimuli 3-grating.tif\")\n",
    "# video_stack = image_dataset(video_stack)\n",
    "# video_stack = video_stack[::3]  # convert from 60 to 20 fps\n",
    "# video_stack = video_stack.view(1, video_stack.shape[0], video_stack.shape[1], video_stack.shape[2], video_stack.shape[3])\n",
    "\n",
    "video_stack = image_dataset(video_stack)\n",
    "video_stack = video_stack[::3]  # convert from 60 to 20 fps\n",
    "video_stack = video_stack.view(3, video_stack.shape[0] // 3, video_stack.shape[1], video_stack.shape[2], video_stack.shape[3])\n",
    "# video_stack = video_stack.transpose(-1, -2)\n",
    "\n",
    "# rearrange(video_stack[0, 0:2].transpose(0,1), 'c t (h p1) (w p2) -> (t h w) (p1 p2 c)', p1=16, p2=16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(video_stack[0, 1].permute(1, 2, 0))\n",
    "plt.figure()\n",
    "plt.imshow(video_stack[1, 1].permute(1, 2, 0))\n",
    "plt.figure()\n",
    "plt.imshow(video_stack[2, 1].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_path = \"/home/antonis/projects/slab/git/slab/transformer_exp/code/data/SImNew3D/neural/NatureMoviePart1-A\" # \"code/data/SImIm/simNeu_3D_WithNorm__Combo3.mat\" \n",
    "from SpikeVidUtils import trial_df_combo3\n",
    "\n",
    "spike_data = scipyio.loadmat(parent_path + \"code/data/OneCombo3/spiketrain.mat\")\n",
    "spike_data = np.squeeze(spike_data['spiketrain'].T, axis=-1)\n",
    "spike_data = [trial_df_combo3(spike_data, n_stim) for n_stim in range(3)]\n",
    "spike_data = pd.concat(spike_data, axis=0)\n",
    "\n",
    "spike_data['Trial'] = spike_data['Trial'] + 1\n",
    "spike_data['Time'] = spike_data['Time'] * 0.0751\n",
    "spike_data = spike_data[(spike_data['Time'] > 0) & (spike_data['Time'] <= 32)]\n",
    "\n",
    "# vid_duration = [len(vid) * 1/20 for vid in vid_list]\n",
    "\n",
    "df = spike_data\n",
    "del spike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Trial'] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(parent_path + \"code/data/OneCombo3/Combo3_all_stim.csv\")\n",
    "window = 0.5\n",
    "dt = 0.01\n",
    "\n",
    "from SpikeVidUtils import make_intervals\n",
    "\n",
    "df['Interval'] = make_intervals(df, window)\n",
    "df['Interval_dt'] = make_intervals(df, dt)\n",
    "df['Interval_dt'] = (df['Interval_dt'] - df['Interval'] + window).round(2)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dt = sorted((df['Interval_dt'].unique()).round(3)) # add last interval for EOS'\n",
    "\n",
    "df['Time'] = df['Time'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Interval', 'Trial']).size().plot.bar()\n",
    "# df.groupby(['Interval', 'Trial']).agg(['nunique'])\n",
    "df.groupby(['Interval', 'Trial']).size().nlargest(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData\n",
    "\n",
    "## qv-vae feats\n",
    "# frames = torch.load(parent_path + \"code/data/SImNew3D/stimulus/vq-vae_code_feats-24-05-4x4x4.pt\").numpy() + 2\n",
    "# frame_feats = torch.load(parent_path + \"code/data/SImNew3D/stimulus/vq-vae_embed_feats-24-05-4x4x4.pt\").numpy()\n",
    "# frame_block_size = frames.shape[-1] - 1\n",
    "\n",
    "## resnet3d feats\n",
    "frame_feats = video_stack.transpose(1, 2)\n",
    "\n",
    "frame_block_size = 560\n",
    "prev_id_block_size = 30\n",
    "id_block_size = 30 * 2    # 95\n",
    "block_size = frame_block_size + id_block_size + prev_id_block_size # frame_block_size * 2  # small window for faster training\n",
    "frame_memory = 20   # how many frames back does model see\n",
    "window = window\n",
    "\n",
    "neurons = sorted(list(set(df['ID'])))\n",
    "id_stoi = { ch:i for i,ch in enumerate(neurons) }\n",
    "id_itos = { i:ch for i,ch in enumerate(neurons) }\n",
    "\n",
    "# translate neural embeddings to separate them from ID embeddings\n",
    "# frames = frames + [*id_stoi.keys()][-1] \n",
    "neurons = [i for i in range(df['ID'].min(), df['ID'].max() + 1)]\n",
    "# pixels = sorted(np.unique(frames).tolist())\n",
    "feat_encodings = neurons + ['SOS'] + ['EOS'] + ['PAD']  # + pixels \n",
    "stoi = { ch:i for i,ch in enumerate(feat_encodings) }\n",
    "itos = { i:ch for i,ch in enumerate(feat_encodings) }\n",
    "stoi_dt = { ch:i for i,ch in enumerate(n_dt) }\n",
    "itos_dt = { i:ch for i,ch in enumerate(n_dt) }\n",
    "max(list(itos_dt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = round(len(df)*(4/5))\n",
    "# test_len = round(len(df) - train_len)\n",
    "\n",
    "# train_data = df[:train_len]\n",
    "# test_data = df[train_len:train_len + test_len].reset_index().drop(['index'], axis=1)\n",
    "\n",
    "n = []\n",
    "for n_stim in range(3):\n",
    "    n_trial = [3, 15, 5, 18]\n",
    "    for n_trial in n_trial:\n",
    "        trial = (n_stim + 1) * 20 - n_trial\n",
    "        n.append(trial)\n",
    "train_data = df[~df['Trial'].isin(n)].reset_index(drop=True)\n",
    "test_data = df[df['Trial'].isin(n)].reset_index(drop=True)\n",
    "small_data = df[df['Trial'].isin([5])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData2\n",
    "\n",
    "# train_dat1aset = spikeTimeData(spikes, block_size, dt, stoi, itos)\n",
    "\n",
    "train_dataset = SpikeTimeVidData2(train_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
    "test_dataset = SpikeTimeVidData2(test_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
    "# dataset = SpikeTimeVidData(df, frames, frame_feats, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos)\n",
    "# single_batch = SpikeTimeVidData(df[df['Trial'].isin([5])], None, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats)\n",
    "small_dataset = SpikeTimeVidData2(small_data, None, block_size, id_block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, neurons, stoi_dt, itos_dt, frame_feats, pred=False)\n",
    "\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_class_weights(df, population_size):\n",
    "#     class_freq = df.groupby(['ID']).size().nlargest(2)\n",
    "#     class_freq_pad = np.array(class_freq.tolist() + [class_freq.max()]*(population_size - len(class_freq)), dtype=np.float32)\n",
    "#     return torch.tensor(np.reciprocal(class_freq_pad) * class_freq.max(), dtype=torch.float32) / class_freq.max()\n",
    "\n",
    "def get_class_weights(df, population_size):\n",
    "    len_data = len(train_data.drop_duplicates(subset=['Interval', 'Trial'])[['Interval', 'Trial']])\n",
    "    id_freq = [len(df[df['ID'] == id]) for id in range(neurons[-1] + 1)]\n",
    "    sos_freq = [len_data * 2]\n",
    "    eos_freq = [len_data * 1]\n",
    "    pad_freq = [(len_data * (id_block_size + prev_id_block_size)) - len(df)]\n",
    "    class_freq = np.array(id_freq + sos_freq + eos_freq + pad_freq, dtype=np.float32)\n",
    "    class_freq = torch.tensor(np.reciprocal(class_freq) * class_freq.max(), dtype=torch.float32) / class_freq.max()\n",
    "    return torch.nan_to_num(class_freq, 1)\n",
    "\n",
    "class_weights = get_class_weights(df, train_dataset.id_population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_class_weights(df, population_size):\n",
    "#     class_freq = df.groupby(['ID']).size().nlargest(2)\n",
    "#     class_freq_pad = np.array(class_freq.tolist() + [class_freq.max()]*(population_size - len(class_freq)), dtype=np.float32)\n",
    "#     return torch.tensor(np.reciprocal(class_freq_pad) * class_freq.max(), dtype=torch.float32) / class_freq.max()\n",
    "\n",
    "def get_class_weights(df, population_size):\n",
    "    len_data = len(train_data.drop_duplicates(subset=['Interval', 'Trial'])[['Interval', 'Trial']])\n",
    "    id_freq = [len(df[df['ID'] == id]) for id in range(neurons[-1] + 1)]\n",
    "    sos_freq = [len_data * 2]\n",
    "    eos_freq = [len_data * 1]\n",
    "    pad_freq = [(len_data * (id_block_size + prev_id_block_size)) - len(df)]\n",
    "    class_freq = np.array(id_freq + sos_freq + eos_freq + pad_freq, dtype=np.float32)\n",
    "    class_freq = torch.tensor(np.reciprocal(class_freq) * class_freq.max(), dtype=torch.float32) / class_freq.max()\n",
    "    return torch.nan_to_num(class_freq, 1)\n",
    "\n",
    "class_weights = get_class_weights(df, train_dataset.id_population_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(split):\n",
    "    is_train = split == 'train'\n",
    "    print(is_train)\n",
    "\n",
    "run_epoch('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_perceiver import GPT, GPTConfig, neuralGPTConfig, Decoder\n",
    "# initialize config class and model (holds hyperparameters)\n",
    "mconf = GPTConfig(train_dataset.population_size, block_size,    # frame_block_size\n",
    "                        id_vocab_size=train_dataset.id_population_size,\n",
    "                        frame_block_size=frame_block_size,\n",
    "                        id_block_size=id_block_size,  # frame_block_size\n",
    "                        n_dt=len(n_dt),\n",
    "                        data_size=train_dataset.size,\n",
    "                        class_weights=class_weights,\n",
    "                        pretrain=True,\n",
    "                        n_layer=8, n_head=4, n_embd=256,\n",
    "                        temp_emb=True, pos_emb=True,\n",
    "                        id_drop=0.2, im_drop=0.2)\n",
    "model = GPT(mconf)\n",
    "# model.load_state_dict(torch.load(parent_path +  \"code/transformer_vid3/runs/models/12-08-21-00:35-e:211-b:272-l:5-h:2-ne:512-higher_order.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, TrainerConfig\n",
    "# model.load_state_dict(torch.load(parent_path +  \"code/transformer_vid3/runs/models/12-01-21-14:18-e:19-b:239-l:4-h:2-ne:512-higher_order.pt\"))\n",
    "# model.load_state_dict(torch.load(parent_path +  \"code/transformer_vid3/runs/models/12-14-21-23:44-e:17-b:650-l:8-h:4-ne:256-higher_order.pt\"))\n",
    "\n",
    "max_epochs = 400\n",
    "batch_size = 16\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=3e-5, \n",
    "                      num_workers=4, lr_decay=False, warmup_tokens=2e5, \n",
    "                      decay_weights=True,\n",
    "                      final_tokens=len(train_dataset)*(block_size // 8) * (max_epochs),\n",
    "                      clip_norm=3.0, grad_norm_clip=2.0,\n",
    "                      dataset='higher_order', mode='predict',\n",
    "                      block_size=train_dataset.block_size,\n",
    "                      id_block_size=train_dataset.id_block_size,\n",
    "                      show_grads=False, plot_raster=False,\n",
    "                      pretrain_ims=False, pretrain_ids=False)\n",
    "\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf, mconf)\n",
    "trainer.train()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(parent_path + \"code/transformer_vid3/model_cnn_78.pt\"))\n",
    "# torch.save(model.state_dict(), 'epoch_382_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Predict using TEST dataset \"\"\"\n",
    "\n",
    "from utils import predict_raster, predict_raster_resnet, predict_raster_enc_dec, predict_raster_recursive, predict_beam_search, predict_raster_recursive_time, predict_beam_search_time, predict_raster_hungarian\n",
    "%matplotlib inline\n",
    "\n",
    "loader = DataLoader(test_dataset, shuffle=False, pin_memory=False,\n",
    "                                  batch_size=1, num_workers=1)\n",
    "\n",
    "# device = torch.cuda.current_device()\n",
    "# model = model.to(device)\n",
    "# model.load_state_dict(torch.load(parent_path +  \"code/transformer_vid3/runs/models/12-14-21-11:49-e:1-b:650-l:4-h:4-ne:256-higher_order.pt\"))\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "To predict only neurons we pass <frame_end> so we see predictions only for Neurons \n",
    "If you want to also see frame_tokens, just pass <frame_end=0>\n",
    "\n",
    "NOTE: 512 ID is the <end-of-sequence-id>. Right now, makes no difference if I include\n",
    "it in loss, here it is included in loss and predictions.\n",
    "\n",
    "\"\"\"\n",
    "# true, predicted, true_timing, predicted_timing = predict_time_raster(model, loader, \n",
    "#                                                                     f_block_sz=frame_block_size, id_block_sz=frame_block_size, \n",
    "#                                                                     get_dt=True)\n",
    "\n",
    "# true, predicted, true_timing, predicted_timing = predict_time_raster(model, loader, \n",
    "#                                                                     f_block_sz=frame_block_size, id_block_sz=frame_block_size, \n",
    "#                                                                     get_dt=True)\n",
    "\n",
    "# true, predicted = predict_raster(model, loader)\n",
    "\n",
    "# true, predicted = predict_beam_search(model, loader, stoi, frame_end=frame_block_size)\n",
    "true, predicted, true_timing = predict_raster_recursive(model, loader, stoi, sample=True, top_k=15, gpu=True, frame_end=frame_block_size)\n",
    "# true, predicted = predict_raster_hungarian(model, loader)\n",
    "# true, predicted = predict_raster(model, loader, gpu=True)\n",
    "\n",
    "true_df = pd.DataFrame(true.numpy())\n",
    "predicted_df = pd.DataFrame(predicted.numpy())\n",
    "print(len(true_df[true_df[0] == 512]), len(predicted_df[predicted_df[0] == 512])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(parent_path + \"code/transformer_vid3/runs/models/12-10-21-18:16-e:18-b:635-l:3-h:4-ne:256-higher_order.pt\"))\n",
    "torch.save(model.state_dict(), 'epoch_400_modelGPT.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DataLoader(train_dataset, shuffle=False, pin_memory=False,\n",
    "#                                   batch_size=1, num_workers=1)\n",
    "\n",
    "# true_train, predicted_train, true_timing_train = predict_raster_recursive(model, loader, stoi, sample=None, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(true.numpy())\n",
    "predicted_df = pd.DataFrame(predicted.numpy())\n",
    "print(len(true_df[true_df[0] >= 512]), len(predicted_df[predicted_df[0] >= 512])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_this(true_df, predicted_df):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    n_min = 165\n",
    "    freq_true = true_df[true_df[0] < n_min].groupby([0]).size()\n",
    "    print(freq_true)\n",
    "    freq_pred = predicted_df[predicted_df[0] < n_min].groupby([0]).size()\n",
    "    plt.bar(freq_pred.index, freq_pred, label='predicted', alpha=0.5)\n",
    "    plt.bar(freq_true.index, freq_true, label='true', alpha=0.5)\n",
    "    plt.title('Neuron Firing Distribution (PSTH Loss)', fontsize=40)\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.show()\n",
    "\n",
    "plot_this(pd.DataFrame(true.numpy()), pd.DataFrame(predicted.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Trial'][df['Trial'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_this(true_df, predicted_df):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    n_min = 512\n",
    "    freq_true = true_df.groupby(['ID']).size()\n",
    "    freq_pred = predicted_df.groupby(['ID']).size()\n",
    "    plt.bar(freq_pred.index, freq_pred, label='Trial 5', alpha=0.5)\n",
    "    plt.bar(freq_true.index, freq_true, label='Trial 10', alpha=0.5)\n",
    "    plt.title('Neuron Firing Distribution (PSTH Loss)', fontsize=40)\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.show()\n",
    "\n",
    "plot_this(df[df['Trial'] == 5], df[df['Trial'] == 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_pred = len(true)\n",
    "# len_pred = 1000\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title('Pixel / Spike Raster', size=50)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.scatter(np.arange(len_pred), true[:len_pred], alpha=0.6, label='true', marker='o')\n",
    "plt.scatter(np.arange(len_pred), predicted[:len_pred], alpha=0.6, label='predicted', marker='x')\n",
    "plt.legend(fontsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(true.numpy())\n",
    "predicted_df = pd.DataFrame(predicted.numpy())\n",
    "print(len(true_df[true_df[0] == 512]), len(predicted_df[predicted_df[0] == 512])) \n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "n_min = 10000\n",
    "freq_true = df[(df['ID'] < n_min) & (df['Trial'] == 4)].groupby(['ID']).size()\n",
    "freq_pred = predicted_df[predicted_df[0] < n_min].groupby([0]).size()\n",
    "plt.bar(freq_true.index, freq_true, label='true', alpha=0.3)\n",
    "# plt.bar(freq_pred.index, freq_pred, label='predicted', alpha=0.3)\n",
    "plt.title('Neuron Firing Distribution (PSTH Loss)', fontsize=40)\n",
    "plt.legend(fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'True':true, 'Predicted':predicted, \n",
    "                   })\n",
    "\n",
    "# df_pred = pd.DataFrame({'True':true, 'Predicted':predicted, 'Time':true_timing / 100})\n",
    "\n",
    "df.to_csv('GPT-one_combo_73-train.csv', index=False)\n",
    "\n",
    "# df_pred = pd.read_csv(parent_path + \"/transformer_vid3/analysis/cs-k25_2-simNeu_3D_WithNorm__Combo3-train.csv\")\n",
    "# df_pred = df_pred.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "146 + 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.id_block_size + train_dataset.id_prev_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.id_prev_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(test_dataset, shuffle=True, pin_memory=False,\n",
    "                                  batch_size=2, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['frames'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt_prev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['Interval'] == x['interval'][0]) & (df['Trial'] == x['interval'][1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "for key, value in x.items():\n",
    "    x[key] = x[key].to(device)\n",
    "for key, value in y.items():\n",
    "    y[key] = y[key].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cuda()\n",
    "model = model.cpu()\n",
    "model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['dt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'][:, :x['id'].shape[-1] - x['pad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id'][:, :x['id'].shape[-1] - x['pad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x['frames'][0, :, -1].permute(1, 2, 0), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['interval'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Interval'] >= (x['interval'][0] - 1)) & (df['Interval'] <= x['interval'][0]) & (df['Trial'] == x['interval'][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id_prev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt_prev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_s = id_block_size + prev_id_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id'][:, :id_s - x['pad'] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.ceil((20 + 21) // 20 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, features, loss = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['logits'][:, frame_block_size: frame_block_size + x[\"pad_prev\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['dt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x['dt'].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [xx[n + 1] - xx[n] for n in range(len(xx) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_block_size + id_block_size + prev_id_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['interval'] = x['interval'].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = x['interval'][0]\n",
    "trial = x['interval'][1]\n",
    "prev_int = interval - 1\n",
    "prev_int = prev_int if prev_int > 0 else 0  \n",
    "prev_id_interval = prev_int, interval\n",
    "data_prev = df[(df['Interval'] >= prev_id_interval[0]) & \n",
    "                        (df['Interval'] < prev_id_interval[1]) &\n",
    "                        (df['Trial'] == trial)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[(df['Interval'] == x['interval'][0]) & (df['Trial'] == x['interval'][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.index[(df['Interval'] == x['interval'][0]) & (df['Trial'] == x['interval'][1])].item()\n",
    "df[(df['Interval'] == x['interval'][0]) & (df['Trial'] == x['interval'][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x['interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'], x['id_prev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[idx - 10:idx + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['frames'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = x['frames'][0, :, 10]\n",
    "frame = frame.transpose(0, -1)\n",
    "plt.imshow(frame, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Interval'] == 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt_prev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_perceiver import VideoFeaturesExtractor\n",
    "\n",
    "vid = VideoFeaturesExtractor()\n",
    "vid(x['frames']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in x.items():\n",
    "    x[key] = x[key].cuda()\n",
    "for key, value in y.items():\n",
    "    y[key] = y[key].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['frames'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'][:, :t - x['pad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id'][:, :t - x['pad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cpu')\n",
    "model = model.cuda()\n",
    "preds, features, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = x['id'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = x['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(t - pad):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'id' : 2}\n",
    "def yes(x):\n",
    "    print(x['id'])\n",
    "    x['id'] -= 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'][:, :21 - x['pad']]\n",
    "y['id'][:, :21 - x['pad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'][:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = x['id'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t - x['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor([512])\n",
    "\n",
    "torch.cat((x['id'], tt[None, ...]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "preds, features, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['logits'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict_raster, predict_time_raster, predict_raster_enc_dec\n",
    "%matplotlib inline\n",
    "from utils import set_plot_params\n",
    "set_plot_params()\n",
    "# model.load_state_dict(torch.load(parent_path + \"code/transformer_vid3/runs/models/10-20-21-18:40-e:9-b:166-l:4-h:4-ne:512-higher_order.pt\"))\n",
    "loader = DataLoader(test_dataset, shuffle=False, pin_memory=False,\n",
    "                                  batch_size=1, num_workers=4)\n",
    "# device = torch.cuda.current_device()\n",
    "# model = model.to(device)\n",
    "\n",
    "# true, predicted, true_timing, predicted_timing = predict_time_raster(model, loader, frame_block_size, train_dataset.id_block_size)\n",
    "true, predicted, timing = predict_raster_enc_dec(model, loader, frame_block_size, get_dt=True)\n",
    "\n",
    "true_df = pd.DataFrame(true.numpy())\n",
    "predicted_df = pd.DataFrame(predicted.numpy())\n",
    "print(len(true_df[true_df[0] < 512]), len(predicted_df[predicted_df[0] < 512])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_plot_params\n",
    "set_plot_params()\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 45\n",
    "plt.rcParams['ytick.labelsize'] = 45\n",
    "plt.rcParams['axes.labelsize'] = 45\n",
    "plt.rcParams['figure.titlesize'] = 1000\n",
    "plt.rcParams['axes.labelpad'] = 17\n",
    "\n",
    "len_pred = len(true) # len(true)\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title('Pixel / Spike Raster', size=50)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.scatter(np.arange(len_pred), true, alpha=0.6, label='true', marker='o') # true[len_pred:2 * len_pred], alpha=0.6, label='true', marker='o')\n",
    "plt.scatter(np.arange(len_pred), predicted, alpha=0.6, label='predicted', marker='x') # predicted[len_pred: 2 * len_pred], alpha=0.6, label='predicted', marker='x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_id = lambda data, id_: np.where(data <= 512, data, None)\n",
    "\n",
    "idn = 174\n",
    "id_true = get_id(true, idn)\n",
    "id_predicted = get_id(predicted, idn)\n",
    "len_pred = len(true)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.title(f'Neuron ID {idn}', size=20)\n",
    "plt.xlabel('Time', size=20)\n",
    "plt.ylabel('Response', size=20)\n",
    "plt.scatter(np.arange(len(id_true[:len_pred])), id_true[:len_pred], alpha=0.7, label='true', s=75)\n",
    "plt.scatter(np.arange(len(id_predicted[:len_pred])), id_predicted[:len_pred], alpha=0.6, label='predicted', marker='x', s=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_time_seq(time_list):\n",
    "    times = []\n",
    "    current_time = 0\n",
    "    for dt in time_list:\n",
    "        if dt == 0:\n",
    "            dt = current_time\n",
    "        times.append(dt)\n",
    "    return times\n",
    "\n",
    "predicted_time = build_time_seq(predicted_timing)\n",
    "true_time = build_time_seq(true_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_plot_params\n",
    "set_plot_params()\n",
    "\n",
    "len_pred = 2000 # len(true)\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title('Pixel / Spike Raster', size=50)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.scatter(true_time[:len_pred], true[:len_pred], alpha=0.6, label='true', marker='o')\n",
    "plt.scatter(predicted_time[:len_pred], predicted[:len_pred], alpha=0.6, label='predicted', marker='x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_plot_params\n",
    "set_plot_params()\n",
    "\n",
    "len_pred = 2000 # len(true)\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title('Pixel / Spike Raster', size=50)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.scatter(np.arange(len_pred), true_time[:len_pred], alpha=0.6, label='true', marker='o')\n",
    "plt.scatter(np.arange(len_pred), predicted_time[:len_pred], alpha=0.6, label='predicted', marker='x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, shuffle=False, pin_memory=False,\n",
    "                                  batch_size=1, num_workers=1)\n",
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "x, y = next(iterable)\n",
    "T = train_dataset.id_block_size\n",
    "frame_end = 0\n",
    "logits, features, _ = model(x)\n",
    "PAD = x['pad']\n",
    "logits = logits[:, frame_end:T - PAD, :]    # get last unpadded token (-x['pad'])\n",
    "# take logits of final step and apply softmax\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "# choose highest topk (1) sample\n",
    "_, ix = torch.topk(probs, k=1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.generate_padding_mask(x['pad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(mconf)\n",
    "decoder(model.tok_emb(x['id']), x['frames'], x['pad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ix.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:, frame_end:T - x['pad']].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_under1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_id = lambda data, id_: np.where(data <= 512, data, None)\n",
    "\n",
    "idn = 174\n",
    "id_true = get_id(true, idn)\n",
    "id_predicted = get_id(predicted, idn)\n",
    "len_pred = len(true)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.title(f'Neuron ID {idn}', size=20)\n",
    "plt.xlabel('Time', size=20)\n",
    "plt.ylabel('Response', size=20)\n",
    "plt.scatter(np.arange(len(id_true[:len_pred])), id_true[:len_pred], alpha=0.4, label='true', s=75)\n",
    "plt.scatter(np.arange(len(id_predicted[:len_pred])), id_predicted[:len_pred], alpha=0.4, label='predicted', marker='x', s=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpikeVidUtils import SpikeTimeVidData\n",
    "\n",
    "# train_dat1aset = spikeTim/eData(spikes, block_size, dt, stoi, itos)\n",
    "\n",
    "train_dataset = SpikeTimeVidData(train_data, frames,  block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, frame_feats)\n",
    "test_dataset = SpikeTimeVidData(test_data, frames, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, frame_feats)\n",
    "# dataset = SpikeTimeVidData(df, frames, frame_feats, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos)\n",
    "single_batch = SpikeTimeVidData(df[df['Trial'].isin([5])], frames, block_size, frame_block_size, prev_id_block_size, window, frame_memory, stoi, itos, frame_feats)\n",
    "\n",
    "\n",
    "print(f'train: {len(train_dataset)}, test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, shuffle=False, pin_memory=False,\n",
    "                                  batch_size=2, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, features, _ = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = torch.rand(2, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "logits, features, loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['frames'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(torch.ones((block_size, block_size))\n",
    "                                     ).view(1, 1, block_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[:, :, :, 3:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df[(df['Interval'] == 238.5) & (df['Trial'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval_prev = 238.5 - window*5\n",
    "# data_prev = df[(df['Interval'] > 3) & \n",
    "# (df['Interval'] < 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "memory = torch.rand(10, 32, 512)\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "out = transformer_decoder(tgt, memory)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2683124566c33f2788b1fa113b378a9613e61e7f3943773cfd75a439017539ba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('transformer_exp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
