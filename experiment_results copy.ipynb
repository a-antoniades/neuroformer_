{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.visualize import set_research_params\n",
    "# set_research_params()\n",
    "\n",
    "# exp_pth = \"./models/tensorboard/visnav_lateral/behavior_pred_exp/classification/ablations_1\"\n",
    "# exp_pth = \"./models/tensorboard/visnav_lateral/behavior_pred_exp/classification/ablations_69\"\n",
    "exp_pth = \"./models/tensorboard/visnav_lateral/behavior_pred_exp/classification/ablations_1\"\n",
    "model_dirs = list(pathlib.Path(exp_pth).glob('*'))\n",
    "\n",
    "n_scale = 5\n",
    "plt.figure(figsize=(2.5 * n_scale, 2.5 * n_scale))\n",
    "file_paths = []\n",
    "for model_dir in model_dirs:\n",
    "    # file_paths += list(model_dir.glob('**/scores_scikit__top_p0_.json'))\n",
    "    file_paths += list(model_dir.glob('**/scores_scikit_.json'))\n",
    "# open json files\n",
    "json_files = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_files.append(json.load(f))\n",
    "\n",
    "# model_names = list([\"State\", \"+ Past State\", \"+ Video\", \"+ Behavior\", \"+ Constrastive\"])\n",
    "model_names = [\"State\", \"+ Past State\", \"+ Video\", \"+ Behavior\", \"+ Contrastive\"]\n",
    "model_colors = [\"#adb5bd\", \"#6c757d\", \"#679436\", \"#dc3545\", \"#6f42c1\"]\n",
    "f1_results = [json_file['F1'] for json_file in json_files]\n",
    "\n",
    "# save to json inside experiment folder\n",
    "with open(os.path.join(exp_pth, 'f1_results.json'), 'w') as f:\n",
    "    json.dump(f1_results, f)\n",
    "\n",
    "f1_results = [json_file['F1'] for json_file in json_files]\n",
    "# save results to csv\n",
    "df = pd.DataFrame({'model': model_names, 'f1': f1_results})\n",
    "\n",
    "# df.to_csv(os.path.join(exp_pth, 'f1_results.csv'), index=False)\n",
    "# bars = plt.bar(model_names, f1_results, color=model_colors)\n",
    "\n",
    "# add legend inside the bar plot\n",
    "# plt.legend(bars, model_names, loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# turn of x ticks\n",
    "plt.xticks([])\n",
    "plt.grid()\n",
    "# keep grid behind the bars\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "# turn off top and left axis\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# save_path\n",
    "# plt.savefig(os.path.join(exp_pth, 'f1_results.pdf'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_pth = \"./models/tensorboard/visnav_lateral/behavior_pred_exp/classification/ablations_69\"\n",
    "model_dirs = reversed(list(pathlib.Path(experiment_pth).glob('*')))\n",
    "file_paths = []\n",
    "for model_dir in model_dirs:\n",
    "    file_paths += list(model_dir.glob('**/df_pred_.csv'))\n",
    "\n",
    "# open csv files\n",
    "csv_files = []\n",
    "for file_path in file_paths:\n",
    "    csv_files.append(pd.read_csv(file_path))\n",
    "\n",
    "# print files lengths\n",
    "print([len(csv_file) for csv_file in csv_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroformer.visualize import set_research_params\n",
    "set_research_params()\n",
    "\n",
    "experiment_pth = \"./models/tensorboard/visnav_lateral/behavior_pred_exp/classification/ablations_1\"\n",
    "# experiment_pth = \"./models/tensorboard/visnav_medial/behavior_pred_exp/classification/1\"\n",
    "experiment_pth = \"./models/tensorboard/Combo3_V1AL/interval_correction/downstream_exp/ablations_2\"\n",
    "model_dirs = list(pathlib.Path(experiment_pth).glob('*'))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "file_paths = []\n",
    "for model_dir in model_dirs:\n",
    "    file_paths += list(model_dir.glob('**/scores_11_top:0.9_1.0_0.9_1.0.json'))\n",
    "# open json files\n",
    "json_files = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_files.append(json.load(f))\n",
    "\n",
    "# model_names = list([\"State\", \"+ Past State\", \"+ Video\", \"+ Behavior\", \"+ Constrastive\"])\n",
    "model_names = [\"State\", \"+ Past State\", \"+ Video\", \"+ Contrastive\"]\n",
    "model_colors = [\"#adb5bd\", \"#6c757d\", \"#679436\", \"#dc3545\", \"#6f42c1\"]\n",
    "f1_results = [json_file['pred']['F1'] for json_file in json_files]\n",
    "\n",
    "\n",
    "# save to json inside experiment folder\n",
    "with open(os.path.join(experiment_pth, 'f1_results.json'), 'w') as f:\n",
    "    json.dump(f1_results, f)\n",
    "\n",
    "# save results to csv\n",
    "f1_results = [json_file['pred']['F1'] for json_file in json_files]\n",
    "df = pd.DataFrame({'model': model_names, 'f1': f1_results})\n",
    "df.to_csv(os.path.join(experiment_pth, 'f1_results.csv'), index=False)\n",
    "bars = plt.bar(model_names, f1_results, color=model_colors)\n",
    "# add legend inside the bar plot\n",
    "plt.legend(bars, model_names, loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# turn of x ticks\n",
    "plt.xticks([])\n",
    "plt.grid()\n",
    "# keep grid behind the bars\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "# turn off top and left axis\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# save_path\n",
    "plt.savefig(os.path.join(experiment_pth, 'f1_results.pdf'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(model_names, [json_file['F1'] for json_file in json_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expirement_pth = \"./models/tensorboard/Combo3_V1AL/interval_correction/downstream_exp/fourth\"\n",
    "model_dirs = list(pathlib.Path(expirement_pth).glob('*'))\n",
    "\n",
    "file_paths = []\n",
    "for model_dir in model_dirs:\n",
    "    file_paths += list(model_dir.glob('**/scores__top_p0_.json'))\n",
    "# open json files\n",
    "json_files = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_files.append(json.load(f))\n",
    "\n",
    "model_names = list(reversed([\"State\", \"+ Past State\", \"+ Video\", \"+ Behavior\", \"+ Constrastive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/tensorboard/visnav_medial/behavior_pred_exp/classification/1/f1_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1305402/1784105899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load your datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_pth_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_path_med\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_path_v1al\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuroformer/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/tensorboard/visnav_medial/behavior_pred_exp/classification/1/f1_results.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "exp_pth_lat = \"./models/tensorboard/visnav_lateral/behavior_pred_exp/classification/ablations_1\"\n",
    "exp_path_med = \"./models/tensorboard/visnav_medial/behavior_pred_exp/classification/1\"\n",
    "exp_path_v1al = \"./models/tensorboard/Combo3_V1AL/interval_correction/downstream_exp/ablations_2\"\n",
    "\n",
    "# Load your datasets\n",
    "df1 = pd.read_csv(os.path.join(exp_pth_lat, 'f1_results.csv'))\n",
    "df2 = pd.read_csv(os.path.join(exp_path_med, 'f1_results.csv'))\n",
    "df3 = pd.read_csv(os.path.join(exp_path_v1al, 'f1_results.csv'))\n",
    "\n",
    "# set colors\n",
    "model_colors = [\"#4285F4\", \"#FBBC05\", \"#34A853\", \"#EA4335\", \"#9C27B0\"]\n",
    "\n",
    "# # Make sure your dataframes are sorted by model_name to align bars correctly\n",
    "# df1 = df1.sort_values('model', ascending=False)\n",
    "# df2 = df2.sort_values('model', ascending=False)\n",
    "# df3 = df3.sort_values('model', ascending=False)\n",
    "\n",
    "# Define the bar width\n",
    "bar_width = 0.3\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "r1 = np.arange(len(df1))\n",
    "r2 = np.arange(len(df2)) + bar_width\n",
    "r3 = np.arange(len(df3)) + (2 * bar_width)\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "bars = plt.bar(r1, df1['f1'], color=model_colors, width=bar_width, edgecolor='grey', label='Dataset1', hatch='/')\n",
    "plt.bar(r2, df2['f1'], color=model_colors, width=bar_width, edgecolor='grey', label='Dataset2', hatch='\\\\')\n",
    "plt.bar(r3, df3['f1'], color=model_colors, width=bar_width, edgecolor='grey', label='Dataset3', hatch='-')\n",
    "\n",
    "# Add xticks on the middle of the grouped bars\n",
    "plt.xlabel('Components')\n",
    "plt.xticks([r + bar_width for r in range(len(df1))], df1['model']) # rotation=45)\n",
    "\n",
    "# Add xticks on the middle of the grouped bars\n",
    "plt.xlabel('Components')\n",
    "plt.xticks([r + bar_width for r in range(len(df1))], df1['model'])#  rotation=45)\n",
    "# add Yticks\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Ablation Study Results', fontweight='bold')\n",
    "\n",
    "# add grid and send back\n",
    "plt.grid(axis='y', linewidth=0.5)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "# Create a legend and show the plot\n",
    "# hatch_handles = [plt.Rectangle((2,2),2,2, fill=False, edgecolor='grey', hatch=pattern, linewidth=0.5) for pattern in ['/', '\\\\', '-']]\n",
    "# Increase the thickness of hatch patterns\n",
    "plt.rcParams['hatch.linewidth'] = 0.5  # previous default was 1.0\n",
    "hatch_handles = [plt.Rectangle((0,0),15,1, fill=False, edgecolor='grey', hatch=pattern) for pattern in ['/', '\\\\', '-']]\n",
    "\n",
    "\n",
    "# Add legends for colors and hatches\n",
    "hatch_labels = ['Visnav, Medial', 'Visnav, Lateral', 'Naturalistic, V1, AL']\n",
    "plt.legend(handles=hatch_handles, labels=hatch_labels, loc='upper left',\n",
    "           handlelength=3, handleheight=2.0, title='Dataset', fontsize=5)\n",
    "# how to change the title size of the legend\n",
    "plt.setp(plt.gca().get_legend().get_title(), fontsize=6)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# make background non-transparent\n",
    "plt.savefig(\"f1_results.pdf\", bbox_inches='tight', pad_inches=0, dpi=500)\n",
    "plt.savefig(\"f1_results.png\", bbox_inches='tight', pad_inches=0, dpi=500)\n",
    "\n",
    "# turn upper and right axis off\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
